{
  "modelName": "demo-task",
  "modelVersion": "1.0",
  "runtime": "python",
  "minWorkers": 1,
  "maxWorkers": 4,
  "batchSize": 8,
  "maxBatchDelay": 100,
  "responseTimeout": 120,
  "deviceType": "cpu",
  "parallelType": "pp",
  "handler": {
    "module": "inference",
    "class": "TextInferenceEngine"
  },
  "metrics": {
    "enable": true,
    "port": 8082,
    "mode": "prometheus"
  }
}