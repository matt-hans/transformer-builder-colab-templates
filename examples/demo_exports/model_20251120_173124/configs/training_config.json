{
  "random_seed": 42,
  "deterministic": false,
  "learning_rate": 5e-05,
  "batch_size": 4,
  "epochs": 10,
  "warmup_ratio": 0.1,
  "weight_decay": 0.01,
  "max_grad_norm": 1.0,
  "use_amp": true,
  "gradient_accumulation_steps": 1,
  "early_stopping_patience": 5,
  "validation_split": 0.1,
  "compile_mode": null,
  "compile_fullgraph": false,
  "compile_dynamic": true,
  "strategy": "auto",
  "devices": "auto",
  "num_nodes": 1,
  "accumulate_grad_batches": 1,
  "precision": "bf16-mixed",
  "model_name": "custom-transformer",
  "model_type": "gpt",
  "vocab_size": 50257,
  "max_seq_len": 128,
  "d_model": 768,
  "num_layers": 12,
  "num_heads": 12,
  "d_ff": 3072,
  "dropout": 0.1,
  "task_name": "lm_tiny",
  "eval_dataset_id": null,
  "resume_from_checkpoint": null,
  "dataset_name": "wikitext-103-v1",
  "dataset_split": "train",
  "dataset_subset": null,
  "max_train_samples": null,
  "max_val_samples": null,
  "checkpoint_dir": "/content/drive/MyDrive/transformer-checkpoints",
  "save_every_n_epochs": 5,
  "keep_best_only": false,
  "wandb_project": "transformer-builder-training",
  "wandb_entity": null,
  "run_name": null,
  "export_bundle": true,
  "export_formats": [
    "pytorch"
  ],
  "export_dir": "exports",
  "created_at": "2025-11-20T17:31:24.533557",
  "config_version": "1.0",
  "notes": ""
}