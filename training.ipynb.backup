{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \ud83d\ude80 Transformer Builder - Training Utilities\n",
    "\n",
    "This notebook provides training and optimization utilities for your custom transformer.\n",
    "\n",
    "**Prerequisites:**\n",
    "- \u2705 You've already run `template.ipynb` and your model passed Tier 1 validation\n",
    "- \u2705 You have your Gist ID from Transformer Builder\n",
    "\n",
    "**What's included:**\n",
    "- \ud83c\udf93 **Fine-Tuning:** Training loop with loss tracking and gradient monitoring\n",
    "- \ud83d\udd27 **Hyperparameter Search:** Automated optimization using Optuna\n",
    "- \ud83d\udcca **Benchmark Comparison:** Compare against production baselines\n",
    "\n",
    "**Estimated time:** 10-20 minutes (GPU recommended)\n",
    "\n",
    "---\n",
    "\n",
    "## \u26a0\ufe0f Important: Fresh Runtime Required\n",
    "\n",
    "This notebook installs `pytorch-lightning` and `optuna`, which require NumPy version changes.\n",
    "\n",
    "**Before running:**\n",
    "1. **Runtime \u2192 Restart runtime** (ensures clean environment)\n",
    "2. **Run all cells** in order\n",
    "\n",
    "**Note:** Do NOT try to run this in the same runtime as `template.ipynb` - you'll get NumPy corruption errors.\n",
    "\n",
    "---\n",
    "\n",
    "**Source:** Generated from [Transformer Builder](https://transformer-builder.com)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \ud83d\udccb STEP 1: Paste Your Gist ID\n",
    "\n",
    "Same Gist ID you used in `template.ipynb`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# GIST ID INPUT - Paste the ID from Transformer Builder\n",
    "# ==============================================================================\n",
    "\n",
    "#@title \ud83d\udce5 **Paste Your Gist ID Here**\n",
    "GIST_ID = \"\"  #@param {type:\"string\"}\n",
    "\n",
    "#@markdown ---\n",
    "#@markdown **Where to find your Gist ID:**\n",
    "#@markdown 1. Use the same Gist ID from template.ipynb\n",
    "#@markdown 2. Or go to Transformer Builder \u2192 Export to Colab \u2192 Copy Gist ID\n",
    "\n",
    "if not GIST_ID or not GIST_ID.strip():\n",
    "    print(\"=\" * 70)\n",
    "    print(\"\u26a0\ufe0f  NO GIST ID PROVIDED\")\n",
    "    print(\"=\" * 70)\n",
    "    print()\n",
    "    print(\"Please paste your Gist ID in the field above and re-run this cell.\")\n",
    "    print()\n",
    "    raise ValueError(\"Gist ID is required\")\n",
    "else:\n",
    "    import re\n",
    "    if not re.fullmatch(r\"[A-Za-z0-9]+\", GIST_ID.strip()):\n",
    "        print(\"=\" * 70)\n",
    "        print(\"\u26a0\ufe0f  INVALID GIST ID FORMAT\")\n",
    "        print(\"=\" * 70)\n",
    "        print()\n",
    "        print(f\"The Gist ID you entered: {GIST_ID!r}\")\n",
    "        print()\n",
    "        raise ValueError(\"Invalid Gist ID format\")\n",
    "    \n",
    "    GIST_ID = GIST_ID.strip()\n",
    "    \n",
    "    print(\"=\" * 70)\n",
    "    print(\"\u2705 GIST ID SAVED\")\n",
    "    print(\"=\" * 70)\n",
    "    print()\n",
    "    print(f\"Gist ID: {GIST_ID}\")\n",
    "    print()\n",
    "    print(\"Continue to next cell to install training dependencies...\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \ud83d\udce6 STEP 2: Install Training Dependencies\n",
    "\n",
    "This cell installs:\n",
    "- `pytorch-lightning` (training framework)\n",
    "- `optuna` (hyperparameter optimization)\n",
    "- `torchmetrics` (evaluation metrics)\n",
    "\n",
    "**Note:** This will reinstall NumPy to a compatible version. This is why we need a fresh runtime separate from `template.ipynb`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# INSTALL TRAINING DEPENDENCIES\n",
    "# ==============================================================================\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"\ud83d\udce6 INSTALLING TRAINING DEPENDENCIES\")\n",
    "print(\"=\" * 70)\n",
    "print()\n",
    "print(\"This will install:\")\n",
    "print(\"  \u2022 pytorch-lightning (training utilities)\")\n",
    "print(\"  \u2022 optuna (hyperparameter optimization)\")\n",
    "print(\"  \u2022 torchmetrics (evaluation metrics)\")\n",
    "print()\n",
    "print(\"\u23f3 This may take 30-60 seconds...\")\n",
    "print()\n",
    "\n",
    "# Install with standard pip (no --no-deps, we want proper dependencies)\n",
    "!pip install -q pytorch-lightning optuna torchmetrics\n",
    "\n",
    "print()\n",
    "print(\"=\" * 70)\n",
    "print(\"\u2705 INSTALLATION COMPLETE\")\n",
    "print(\"=\" * 70)\n",
    "print()\n",
    "\n",
    "# Verify installation\n",
    "try:\n",
    "    import pytorch_lightning as pl\n",
    "    import optuna\n",
    "    import torchmetrics\n",
    "    import torch\n",
    "    import numpy as np\n",
    "    \n",
    "    print(f\"\u2705 pytorch-lightning: {pl.__version__}\")\n",
    "    print(f\"\u2705 optuna: {optuna.__version__}\")\n",
    "    print(f\"\u2705 torchmetrics: {torchmetrics.__version__}\")\n",
    "    print(f\"\u2705 torch: {torch.__version__}\")\n",
    "    print(f\"\u2705 numpy: {np.__version__}\")\n",
    "    print()\n",
    "    print(\"\u2705 All training dependencies ready!\")\n",
    "    print()\n",
    "    \n",
    "except ImportError as e:\n",
    "    print(f\"\u274c Import failed: {e}\")\n",
    "    print()\n",
    "    print(\"Please restart runtime and try again.\")\n",
    "    print()\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \ud83d\udce5 STEP 3: Download Utils Package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# DOWNLOAD UTILS PACKAGE\n",
    "# ==============================================================================\n",
    "\n",
    "print(\"\ud83d\udce6 Downloading test utilities package...\")\n",
    "\n",
    "# Remove old utils directory if exists\n",
    "!rm -rf utils/\n",
    "\n",
    "# Download complete utils package from GitHub\n",
    "!git clone --depth 1 --branch main https://github.com/matt-hans/transformer-builder-colab-templates.git temp_repo 2>/dev/null\n",
    "\n",
    "# Copy utils directory\n",
    "!cp -r temp_repo/utils ./\n",
    "\n",
    "# Cleanup\n",
    "!rm -rf temp_repo\n",
    "\n",
    "# Verify package structure\n",
    "import sys\n",
    "import os\n",
    "\n",
    "if './' not in sys.path:\n",
    "    sys.path.insert(0, './')\n",
    "\n",
    "try:\n",
    "    import utils\n",
    "    print(f\"\u2705 Utils package loaded (version {utils.__version__})\")\n",
    "    \n",
    "    # Test importing training functions\n",
    "    from utils import (\n",
    "        test_fine_tuning,\n",
    "        test_hyperparameter_search,\n",
    "        test_benchmark_comparison\n",
    "    )\n",
    "    print(\"\u2705 Training test functions importable\")\n",
    "    print()\n",
    "    print(\"\u2705 Utils package ready!\")\n",
    "    print()\n",
    "    \n",
    "except ImportError as e:\n",
    "    print(f\"\u274c Failed to import utils package: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \ud83d\udcc2 STEP 4: Load Model from Gist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# LOAD CUSTOM MODEL FROM GIST\n",
    "# ==============================================================================\n",
    "\n",
    "import os, re, json, urllib.request, urllib.error\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"MODEL LOADING\")\n",
    "print(\"=\" * 70)\n",
    "print()\n",
    "\n",
    "if 'GIST_ID' not in globals() or not GIST_ID:\n",
    "    raise ValueError(\"Gist ID required - please run Cell 1 first\")\n",
    "\n",
    "gist_id = GIST_ID\n",
    "model_name = \"Model\"\n",
    "\n",
    "print(f\"\ud83d\udce5 Loading model from GitHub Gist: {gist_id}\")\n",
    "print()\n",
    "\n",
    "def _fetch_gist(gid: str) -> dict:\n",
    "    url = f\"https://api.github.com/gists/{gid}\"\n",
    "    req = urllib.request.Request(url, headers={\n",
    "        \"Accept\": \"application/vnd.github+json\",\n",
    "        \"User-Agent\": \"transformer-builder-training\"\n",
    "    })\n",
    "    try:\n",
    "        with urllib.request.urlopen(req, timeout=20) as resp:\n",
    "            return json.loads(resp.read().decode(\"utf-8\"))\n",
    "    except urllib.error.HTTPError as e:\n",
    "        detail = f\"HTTP {e.code}\"\n",
    "        if e.code == 404:\n",
    "            detail += \" - Gist not found\"\n",
    "        raise RuntimeError(f\"GitHub API error: {detail}\") from e\n",
    "\n",
    "def _write(path: str, text: str):\n",
    "    with open(path, \"w\") as f:\n",
    "        f.write(text)\n",
    "\n",
    "try:\n",
    "    gist_data = _fetch_gist(gist_id)\n",
    "    files = gist_data.get(\"files\") or {}\n",
    "    \n",
    "    if \"model.py\" not in files or \"config.json\" not in files:\n",
    "        raise RuntimeError(\"Gist missing model.py or config.json\")\n",
    "    \n",
    "    model_code = files[\"model.py\"].get(\"content\", \"\")\n",
    "    config_json = files[\"config.json\"].get(\"content\", \"\")\n",
    "    \n",
    "    if not model_code or not config_json:\n",
    "        raise RuntimeError(\"Empty content in model files\")\n",
    "    \n",
    "    _write(\"custom_transformer.py\", model_code)\n",
    "    _write(\"config.json\", config_json)\n",
    "    \n",
    "    print(f\"\u2705 Model loaded successfully!\")\n",
    "    print(f\"\u2705 Model code: {len(model_code):,} bytes\")\n",
    "    print(f\"\u2705 Config: {len(config_json):,} bytes\")\n",
    "    print()\n",
    "    \n",
    "    # Parse model name\n",
    "    try:\n",
    "        config_dict = json.loads(config_json)\n",
    "        if 'model_name' in config_dict:\n",
    "            model_name = config_dict['model_name']\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"\u274c Failed to load model: {e}\")\n",
    "    raise\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"\u2705 MODEL LOADING COMPLETE\")\n",
    "print(\"=\" * 70)\n",
    "print()\n",
    "\n",
    "params = {\"name\": model_name}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \ud83d\udd27 STEP 5: Instantiate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import inspect\n",
    "\n",
    "# Import the custom model\n",
    "exec(open('custom_transformer.py').read())\n",
    "\n",
    "# Load config\n",
    "with open('config.json') as f:\n",
    "    config_dict = json.load(f)\n",
    "\n",
    "# Find the model class\n",
    "model_class = None\n",
    "for name, obj in list(globals().items()):\n",
    "    if isinstance(obj, type) and issubclass(obj, nn.Module) and obj is not nn.Module:\n",
    "        if name == params['name']:\n",
    "            model_class = obj\n",
    "            break\n",
    "\n",
    "if model_class is None:\n",
    "    for name, obj in list(globals().items()):\n",
    "        if isinstance(obj, type) and issubclass(obj, nn.Module) and obj is not nn.Module:\n",
    "            model_class = obj\n",
    "            break\n",
    "\n",
    "if model_class:\n",
    "    try:\n",
    "        sig = inspect.signature(model_class.__init__)\n",
    "        params_list = [p for p in sig.parameters.values() if p.name != 'self']\n",
    "        \n",
    "        if len(params_list) == 0:\n",
    "            model = model_class()\n",
    "        else:\n",
    "            model = model_class(**config_dict)\n",
    "        \n",
    "        model.eval()\n",
    "        \n",
    "        total_params = sum(p.numel() for p in model.parameters())\n",
    "        trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "        \n",
    "        print(f\"\u2705 Model instantiated: {model_class.__name__}\")\n",
    "        print(f\"\u2705 Total parameters: {total_params:,}\")\n",
    "        print(f\"\u2705 Trainable parameters: {trainable_params:,}\")\n",
    "        \n",
    "        # Move to GPU if available\n",
    "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        model = model.to(device)\n",
    "        print(f\"\u2705 Device: {device}\")\n",
    "        print()\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\u274c Failed to instantiate model: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        raise\n",
    "else:\n",
    "    raise RuntimeError(f\"Could not find model class '{params['name']}'\")\n",
    "\n",
    "# Create config object\n",
    "class ModelConfig:\n",
    "    def __init__(self, **kwargs):\n",
    "        self.vocab_size = 50257\n",
    "        self.max_seq_len = 512\n",
    "        self.max_batch_size = 8\n",
    "        \n",
    "        if 'nodes' in kwargs:\n",
    "            for node in kwargs['nodes']:\n",
    "                node_params = node.get('params', {})\n",
    "                if 'vocab_size' in node_params:\n",
    "                    self.vocab_size = node_params['vocab_size']\n",
    "                if 'max_seq_len' in node_params or 'seq_length' in node_params:\n",
    "                    self.max_seq_len = node_params.get('max_seq_len') or node_params.get('seq_length', 512)\n",
    "        \n",
    "        for key, value in kwargs.items():\n",
    "            if key not in ['nodes', 'version', 'model_name']:\n",
    "                setattr(self, key, value)\n",
    "\n",
    "config = ModelConfig(**config_dict)\n",
    "print(f\"\u2705 Config prepared (vocab_size={config.vocab_size}, max_seq_len={config.max_seq_len})\")\n",
    "print(\"\u2705 Ready for training tests!\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# \ud83d\ude80 Training Tests\n",
    "\n",
    "Now we'll run the Tier 3 training utilities on your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Tier 3 training utilities\n",
    "from utils.test_functions import (\n",
    "    test_fine_tuning,\n",
    "    test_hyperparameter_search,\n",
    "    test_benchmark_comparison\n",
    ")\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"TIER 3: TRAINING & PRODUCTION UTILITIES\")\n",
    "print(\"=\" * 80)\n",
    "print()\n",
    "\n",
    "# Test 1: Fine-Tuning\n",
    "print(\"Test 1/3: Fine-Tuning Demo\")\n",
    "print(\"-\" * 80)\n",
    "print(\"Running 3 epochs of fine-tuning with synthetic data...\")\n",
    "try:\n",
    "    fine_tune_results = test_fine_tuning(\n",
    "        model, \n",
    "        config, \n",
    "        num_epochs=3,\n",
    "        batch_size=2,\n",
    "        learning_rate=5e-5\n",
    "    )\n",
    "    print(f\"\\nFinal Loss: {fine_tune_results['final_loss']:.4f}\")\n",
    "    print(f\"Best Loss: {fine_tune_results['best_loss']:.4f}\")\n",
    "    print(\"\u2705 Fine-tuning complete\")\n",
    "except Exception as e:\n",
    "    print(f\"\u26a0\ufe0f Fine-tuning failed: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "print()\n",
    "\n",
    "# Test 2: Hyperparameter Search (OPTIONAL)\n",
    "print(\"Test 2/3: Hyperparameter Optimization\")\n",
    "print(\"-\" * 80)\n",
    "print(\"\u26a0\ufe0f Skipping hyperparameter search (compute-intensive)\")\n",
    "print(\"To enable: uncomment the code block below\")\n",
    "print()\n",
    "# Uncomment to run:\n",
    "# try:\n",
    "#     hp_results = test_hyperparameter_search(\n",
    "#         model,\n",
    "#         config,\n",
    "#         n_trials=5,\n",
    "#         epochs_per_trial=2\n",
    "#     )\n",
    "#     print(\"\\nBest Parameters:\")\n",
    "#     for param, value in hp_results['best_params'].items():\n",
    "#         print(f\"  {param}: {value}\")\n",
    "#     print(\"\u2705 Hyperparameter search complete\")\n",
    "# except Exception as e:\n",
    "#     print(f\"\u26a0\ufe0f Hyperparameter search failed: {e}\")\n",
    "\n",
    "# Test 3: Benchmark Comparison\n",
    "print(\"Test 3/3: Benchmark Against Baseline\")\n",
    "print(\"-\" * 80)\n",
    "print(\"Comparing against distilgpt2 baseline...\")\n",
    "try:\n",
    "    benchmark_results = test_benchmark_comparison(\n",
    "        model,\n",
    "        config,\n",
    "        baseline_model=\"distilgpt2\",\n",
    "        n_samples=10\n",
    "    )\n",
    "    if benchmark_results is not None:\n",
    "        display(benchmark_results)\n",
    "    print(\"\u2705 Benchmark comparison complete\")\n",
    "except Exception as e:\n",
    "    print(f\"\u26a0\ufe0f Benchmark comparison failed: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "print()\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"\u2705 TRAINING UTILITIES COMPLETE\")\n",
    "print(\"=\" * 80)\n",
    "print()\n",
    "print(\"\ud83c\udf89 All training tests complete!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}