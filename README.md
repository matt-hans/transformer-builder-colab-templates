# Transformer Builder - Colab Testing Templates

Advanced testing and training infrastructure for transformer models built with [Transformer Builder](https://transformer-builder.com).

## Quick Start (v3.4.0)

### Step 1: Model Validation
1. Build a transformer in [Transformer Builder](https://transformer-builder.com)
2. Click "Open in Colab" in the export panel
3. The notebook automatically loads your model and runs validation tests

**Zero installation required** - uses only pre-installed Colab packages!

### Step 2: Training (Optional)
1. Open `training.ipynb` in Colab
2. Restart runtime (Runtime â†’ Restart runtime)
3. Paste your same Gist ID
4. Run training and optimization tests

**Why two notebooks?** Training dependencies (pytorch-lightning, optuna) require NumPy version changes. Separating them prevents dependency conflicts and keeps validation fast.

## What's Included

### ðŸ““ template.ipynb - Tier 1 & 2 Tests

#### Tier 1: Critical Validation (~1 minute)
- âœ… Multi-input shape verification across edge cases
- âœ… Gradient flow analysis (detect vanishing/exploding gradients)
- âœ… Numerical stability checks (NaN/Inf detection)
- âœ… Parameter initialization validation
- âœ… Memory footprint profiling
- âœ… Inference speed benchmarks

#### Tier 2: Advanced Analysis (~3 minutes)
- ðŸ”¬ Attention pattern analysis (multi-head attention support)
- ðŸ”¬ Robustness testing under input perturbations

### ðŸ““ training.ipynb - Tier 3 Training

#### Tier 3: Training & Fine-Tuning (10-20 minutes)
- ðŸš€ Fine-tuning loop with loss tracking
- ðŸš€ Hyperparameter optimization using Optuna
- ðŸš€ Benchmark comparison against baselines

## Repository Structure

```
transformer-builder-colab-templates/
â”œâ”€â”€ template.ipynb                 # Testing & validation (Tier 1 + 2)
â”œâ”€â”€ training.ipynb                 # Training utilities (Tier 3) + modes/sweeps
â”œâ”€â”€ cli/                           # CLI entrypoints (run_tiers, run_training)
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ run_tiers.py
â”‚   â””â”€â”€ run_training.py
â”œâ”€â”€ docs/                          # Platform docs (v4.0.0)
â”‚   â”œâ”€â”€ ARCHITECTURE_OVERVIEW_v4.0.0.md
â”‚   â”œâ”€â”€ USAGE_GUIDE_COLAB_AND_CLI.md
â”‚   â””â”€â”€ DEVELOPER_GUIDE_TASKS_EVAL.md
â”œâ”€â”€ examples/
â”‚   â””â”€â”€ datasets/                  # Tiny datasets for quick eval
â”‚       â”œâ”€â”€ lm_tiny.txt
â”‚       â”œâ”€â”€ cls_tiny.csv
â”‚       â””â”€â”€ seq2seq_tiny.jsonl
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ test_functions.py          # Unified test facade
â”‚   â”œâ”€â”€ tier1_critical_validation.py
â”‚   â”œâ”€â”€ tier2_advanced_analysis.py
â”‚   â”œâ”€â”€ tier3_training_utilities.py
â”‚   â”œâ”€â”€ adapters/                  # Model introspection + ModelAdapter + gist_loader
â”‚   â”œâ”€â”€ tokenization/              # BPE training & validation
â”‚   â”œâ”€â”€ training/                  # Dataset, checkpoints, eval_runner, export, sweeps, ExperimentDB
â”‚   â””â”€â”€ ui/                        # Setup wizard & mode presets
â”œâ”€â”€ requirements-colab.txt         # Dependency documentation
â””â”€â”€ README.md
```

## Manual Usage

If you have model code outside Transformer Builder:

1. Open `template.ipynb` in Colab
2. Modify Cell 3 to include your model code
3. Update config in Cell 4
4. Run all cells

## Requirements

- Google account (Colab free tier is sufficient)
- Generated model must be a PyTorch `nn.Module`

## Examples

See `examples/` directory for pre-populated notebooks demonstrating common architectures.

## Docs (v4.0.0)

- Architecture overview: `docs/ARCHITECTURE_OVERVIEW_v4.0.0.md`
- Usage guide (Colab + CLI): `docs/USAGE_GUIDE_COLAB_AND_CLI.md`
- Developer guide (Tasks/Adapters/Eval): `docs/DEVELOPER_GUIDE_TASKS_EVAL.md`

## CLI Quick Start

Run quick validation (Tier 1) with a tiny stub model:

```
python -m cli.run_tiers --config configs/example_tiers.json  # optional config
```

Run training + tiny evaluation:

```
python -m cli.run_training --config configs/example_train.json
```

Example training config JSON:

```
{
  "task_name": "lm_tiny",
  "epochs": 1,
  "batch_size": 2,
  "vocab_size": 101,
  "max_seq_len": 16,
  "learning_rate": 0.0005,
  "model_file": "./path/to/model.py",  // or: "gist_id": "...", "gist_revision": "..."
  "eval": {"dataset_id": "lm_tiny_v1", "batch_size": 2},
  "log_to_db": true,
  "run_name": "cli-run-01"
}
```

Notes:
- `model_file` can be a directory (containing `model.py`) or a file path; the CLI tries `build_model()` then `Model` class.
- If `gist_id` is provided, the CLI fetches the gist (best effort in restricted environments) and tries to import `model.py`.
- Without a model provided, the CLI uses a tiny LM stub with the requested `vocab_size`.

## Support

Issues? Report at [transformer-builder/issues](https://github.com/your-org/transformer-builder/issues)

## License

MIT License - see LICENSE file
