---
id: T004
title: "W&B Artifacts - Checkpoint and Dataset Versioning"
status: pending
priority: P2
dependencies: [T002]
tags: [mlops, experiment-tracking, wandb, phase-1]
estimated_tokens: 12000
actual_tokens: 0
created_at: "2025-01-15"
updated_at: "2025-01-15"
---

## Description

Implement W&B Artifacts for versioning model checkpoints, datasets, and tokenizers. Enables reproducible training by tracking exact data and model versions used in each experiment.

## Business Context

**Problem**: Users lose track of which dataset version produced which model. Checkpoints scattered across Google Drive with unclear provenance. Hard to reproduce results from successful experiments.

**Value**: Full lineage tracking from dataset â†’ training run â†’ model checkpoint. One-click reproduction of any experiment. Automatic deduplication saves storage.

**User Story**: As an ML practitioner, I want W&B to track my dataset and checkpoint versions so that I can reproduce any training run months later and understand exactly what data produced my best model.

## Acceptance Criteria

1. [ ] Log datasets as W&B artifacts with versioning
2. [ ] Log model checkpoints as artifacts (best model, final model)
3. [ ] Link artifacts to training runs (dataset used, checkpoints produced)
4. [ ] Add artifact metadata (num_examples, vocab_size, model_params)
5. [ ] Implement artifact download in notebook (load dataset/checkpoint from registry)
6. [ ] Add dataset fingerprinting (hash) to detect changes
7. [ ] Log tokenizer artifacts if using custom tokenizer
8. [ ] Create artifact lineage graph (dataset â†’ run â†’ checkpoint)
9. [ ] Document artifact usage in markdown cells
10. [ ] Test cross-session artifact loading (download checkpoint from previous run)

## Test Scenarios

### Scenario 1: Dataset Artifact Creation
```
Given: Training with wikitext-103 dataset (183M tokens)
When: Dataset loaded and artifact logged to W&B
Then: Artifact "wikitext-103:v0" appears in W&B registry
  And: Metadata shows num_examples=183M, source="huggingface/wikitext-103"
  And: Artifact has unique hash fingerprint
```

### Scenario 2: Checkpoint Artifact Versioning
```
Given: Training run saves checkpoints at epoch 5, 10, 15 (best at epoch 10)
When: Checkpoints logged as artifacts
Then: Three artifact versions exist: "model-checkpoint:v0", "v1", "v2"
  And: Best model tagged with "best" alias
  And: Each artifact linked to parent run
  And: Metadata includes validation_loss, perplexity, epoch
```

### Scenario 3: Artifact Lineage Tracking
```
Given: Dataset "wikitext-103:v2" used in run "sunny-frog-42"
When: Run completes and saves checkpoint "model:v5"
Then: W&B lineage graph shows: wikitext-103:v2 â†’ sunny-frog-42 â†’ model:v5
  And: Clicking dataset artifact shows all runs that used it
  And: Clicking checkpoint shows parent run and training data
```

### Scenario 4: Cross-Session Artifact Loading
```
Given: Previous run "stellar-mountain-17" saved best checkpoint as artifact
When: New Colab session downloads artifact by alias "model:best"
Then: Checkpoint downloaded to local filesystem
  And: Model state_dict loaded successfully
  And: Config metadata preserved (vocab_size, architecture, hyperparams)
```

### Scenario 5: Dataset Deduplication
```
Given: User runs training 5 times with same wikitext-103 dataset
When: Dataset logged as artifact each time
Then: Only one copy stored in W&B (deduplicated by hash)
  And: All 5 runs reference same dataset artifact
  And: Storage quota not exceeded
```

## Technical Implementation

### File Changes

**training.ipynb**:
- Add dataset artifact logging after data loading
- Add checkpoint artifact logging in training loop
- Add artifact download cell for loading previous experiments

### Code Structure

```python
# Dataset Artifact Logging

def log_dataset_artifact(dataset, dataset_name, run):
    """
    Log dataset as W&B artifact with versioning.

    Args:
        dataset: HuggingFace Dataset or custom dataset object
        dataset_name: str, name for artifact (e.g., "wikitext-103")
        run: wandb.Run object
    """
    # Create artifact
    dataset_artifact = wandb.Artifact(
        name=f"{dataset_name}-dataset",
        type="dataset",
        description=f"Training dataset: {dataset_name}",
        metadata={
            "num_examples": len(dataset),
            "num_tokens": sum(len(ex['input_ids']) for ex in dataset) if 'input_ids' in dataset[0] else None,
            "source": dataset.info.dataset_name if hasattr(dataset, 'info') else "custom",
            "split": "train",
        }
    )

    # Add dataset files to artifact
    # Option 1: If dataset is saved locally
    if os.path.exists(f"./data/{dataset_name}"):
        dataset_artifact.add_dir(f"./data/{dataset_name}")

    # Option 2: If dataset is HuggingFace, save first then add
    else:
        dataset.save_to_disk(f"./temp_dataset_{dataset_name}")
        dataset_artifact.add_dir(f"./temp_dataset_{dataset_name}")

    # Log artifact to run
    run.log_artifact(dataset_artifact)
    print(f"âœ… Dataset artifact logged: {dataset_name}-dataset:v{dataset_artifact.version}")

    return dataset_artifact


# Checkpoint Artifact Logging

def save_checkpoint_artifact(model, optimizer, epoch, metrics, run, is_best=False):
    """
    Save model checkpoint as W&B artifact.

    Args:
        model: PyTorch model
        optimizer: PyTorch optimizer
        epoch: Current epoch number
        metrics: dict of validation metrics
        run: wandb.Run object
        is_best: bool, whether this is the best checkpoint so far
    """
    # Create checkpoint directory
    checkpoint_dir = f"./checkpoints/epoch_{epoch}"
    os.makedirs(checkpoint_dir, exist_ok=True)

    # Save checkpoint
    checkpoint_path = f"{checkpoint_dir}/checkpoint.pt"
    torch.save({
        'epoch': epoch,
        'model_state_dict': model.state_dict(),
        'optimizer_state_dict': optimizer.state_dict(),
        'metrics': metrics,
    }, checkpoint_path)

    # Save config separately for easy inspection
    config_path = f"{checkpoint_dir}/config.json"
    config_dict = {
        'vocab_size': getattr(model.config, 'vocab_size', 50257),
        'max_seq_len': getattr(model.config, 'max_seq_len', 128),
        'model_type': model.__class__.__name__,
        'total_params': sum(p.numel() for p in model.parameters()),
    }
    with open(config_path, 'w') as f:
        json.dump(config_dict, f, indent=2)

    # Create artifact
    artifact_name = f"{run.name}-checkpoint"
    checkpoint_artifact = wandb.Artifact(
        name=artifact_name,
        type="model",
        description=f"Model checkpoint at epoch {epoch}",
        metadata={
            'epoch': epoch,
            'val_loss': metrics.get('val_loss'),
            'val_perplexity': metrics.get('val_perplexity'),
            'train_loss': metrics.get('train_loss'),
            'total_params': config_dict['total_params'],
        }
    )

    # Add checkpoint files
    checkpoint_artifact.add_dir(checkpoint_dir)

    # Add aliases
    aliases = [f"epoch_{epoch}"]
    if is_best:
        aliases.append("best")
    if epoch == run.config.get('epochs'):  # Last epoch
        aliases.append("latest")

    # Log artifact
    run.log_artifact(checkpoint_artifact, aliases=aliases)
    print(f"âœ… Checkpoint artifact logged: {artifact_name}:v{checkpoint_artifact.version} (aliases: {aliases})")

    return checkpoint_artifact


# Artifact Download and Loading

def load_checkpoint_from_artifact(artifact_name, alias="best"):
    """
    Download and load checkpoint from W&B artifact registry.

    Args:
        artifact_name: str, full artifact name (e.g., "username/project/model-checkpoint")
        alias: str, version alias to load ("best", "latest", or "v0", "v1", etc.)

    Returns:
        checkpoint: dict with model_state_dict, optimizer_state_dict, metrics
        config: dict with model configuration
    """
    import wandb

    # Initialize W&B API
    api = wandb.Api()

    # Download artifact
    artifact_path = f"{artifact_name}:{alias}"
    print(f"ðŸ“¥ Downloading artifact: {artifact_path}...")
    artifact = api.artifact(artifact_path, type='model')
    artifact_dir = artifact.download()

    # Load checkpoint
    checkpoint_path = f"{artifact_dir}/checkpoint.pt"
    checkpoint = torch.load(checkpoint_path, map_location='cpu')

    # Load config
    config_path = f"{artifact_dir}/config.json"
    with open(config_path, 'r') as f:
        config = json.load(f)

    print(f"âœ… Checkpoint loaded from epoch {checkpoint['epoch']}")
    print(f"   Val Loss: {checkpoint['metrics'].get('val_loss'):.4f}")
    print(f"   Val Perplexity: {checkpoint['metrics'].get('val_perplexity'):.2f}")

    return checkpoint, config


# Tokenizer Artifact Logging (if using custom tokenizer)

def log_tokenizer_artifact(tokenizer, run):
    """Log custom tokenizer as W&B artifact."""

    # Save tokenizer locally
    tokenizer_dir = "./tokenizer"
    tokenizer.save_pretrained(tokenizer_dir)

    # Create artifact
    tokenizer_artifact = wandb.Artifact(
        name=f"{run.name}-tokenizer",
        type="tokenizer",
        description="Custom tokenizer for transformer model",
        metadata={
            'vocab_size': tokenizer.vocab_size,
            'model_max_length': tokenizer.model_max_length,
            'tokenizer_type': tokenizer.__class__.__name__,
        }
    )

    # Add tokenizer files
    tokenizer_artifact.add_dir(tokenizer_dir)

    # Log artifact
    run.log_artifact(tokenizer_artifact)
    print(f"âœ… Tokenizer artifact logged: {run.name}-tokenizer:v{tokenizer_artifact.version}")

    return tokenizer_artifact
```

### Integration in Training Loop

```python
# In training.ipynb main training cell

# After loading dataset
dataset_artifact = log_dataset_artifact(train_dataset, "wikitext-103", wandb.run)

# In training loop, save checkpoint every N epochs
if epoch % save_interval == 0 or epoch == num_epochs:
    is_best = val_loss < best_val_loss
    if is_best:
        best_val_loss = val_loss

    save_checkpoint_artifact(
        model=model,
        optimizer=optimizer,
        epoch=epoch,
        metrics={'val_loss': val_loss, 'val_perplexity': val_perplexity, 'train_loss': train_loss},
        run=wandb.run,
        is_best=is_best
    )
```

## Dependencies

- **T002**: W&B Metrics Logging (requires active wandb.run)

## Design Decisions

**Decision 1**: Log checkpoints as artifacts (not just state_dict to GDrive)
- **Rationale**: W&B provides versioning, lineage, deduplication automatically
- **Alternative considered**: Manual checkpoint management in GDrive (harder to track)
- **Trade-off**: Requires W&B quota, but free tier (100GB) sufficient for most users

**Decision 2**: Use aliases ("best", "latest") instead of manual version tracking
- **Rationale**: Easier to reference ("load best model") without knowing version number
- **Alternative considered**: Manually track v0, v1, v2... (error-prone)
- **Trade-off**: Aliases can be reassigned, but that's often desired behavior

**Decision 3**: Include config.json in checkpoint artifact
- **Rationale**: Enables loading model without access to original code
- **Alternative considered**: Store config only in W&B metadata (less portable)
- **Trade-off**: Slight duplication, but critical for reproducibility

## Risks & Mitigations

### Risk 1: Artifact Upload Slowdown
- **Impact**: MEDIUM - Large checkpoints take time to upload
- **Likelihood**: HIGH - 100M+ param models = 400MB+ checkpoints
- **Mitigation**: Upload asynchronously (W&B default), only log best/final checkpoints, compress if needed

### Risk 2: Storage Quota Exceeded
- **Impact**: MEDIUM - Free tier has 100GB limit
- **Likelihood**: LOW - Deduplication helps, most users won't hit limit
- **Mitigation**: Document cleanup best practices, only keep top-K checkpoints

### Risk 3: Artifact Download Failure
- **Impact**: LOW - User can't resume training from checkpoint
- **Likelihood**: LOW - W&B has good reliability
- **Mitigation**: Fallback to local checkpoint if artifact download fails, log checkpoints to GDrive as backup

## Progress Log

- [ ] Created task specification (this file)
- [ ] Implemented dataset artifact logging
- [ ] Implemented checkpoint artifact logging with versioning
- [ ] Added artifact download functionality
- [ ] Tested artifact lineage graph in W&B UI
- [ ] Documented artifact usage in notebook
- [ ] Committed changes with message: "feat(mlops): add W&B artifacts for checkpoint and dataset versioning"

## Completion Checklist

- [ ] All acceptance criteria met (10/10 checked)
- [ ] All test scenarios pass (5/5 verified)
- [ ] Code follows style guide
- [ ] Documentation complete
- [ ] No regressions
- [ ] Tested in Colab
- [ ] Git committed
