{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# üß™ Transformer Builder - Advanced Testing Lab\n\n**Welcome! This notebook tests your custom transformer architecture.**\n\n---\n\n## üöÄ **Quick Start (3 Steps)**\n\n### **STEP 1:** Paste Your Gist ID\n‚Üì Scroll down to Cell 3 and paste the Gist ID you received from Transformer Builder\n\n### **STEP 2:** Run All Cells  \nClick **Runtime ‚Üí Run all** (or run cells one-by-one)\n\n### **STEP 3:** Review Test Results\nYour model will be validated through 3 testing tiers\n\n---\n\n## üìã **What's Included:**\n\n- ‚úÖ **Tier 1:** Critical validation (shape, gradients, numerical stability)\n- üî¨ **Tier 2:** Advanced analysis (attention patterns, robustness, profiling)\n- üöÄ **Tier 3:** Training utilities (fine-tuning, hyperparameter sweeps, benchmarks)\n\n---\n\n## ‚ö†Ô∏è **First Time Setup:**\n\nIf this is your first time OR you're continuing from a previous session:\n\n1. **Runtime** ‚Üí **Restart runtime** (takes 5 seconds)\n2. **Edit** ‚Üí **Clear all outputs** (optional, cleans up UI)\n3. **Scroll down to Cell 3** ‚Üí Paste your Gist ID\n4. **Runtime** ‚Üí **Run all**\n\nThis ensures a clean environment and prevents dependency conflicts.\n\n---\n\n**Source:** Generated from [Transformer Builder](https://transformer-builder.com)"
  },
  {
   "cell_type": "markdown",
   "source": "# üß™ Transformer Builder - Advanced Testing Lab\n\nWelcome! This notebook provides comprehensive testing and training capabilities for your custom transformer architecture.\n\n**What's included:**\n- ‚úÖ **Tier 1:** Critical validation (shape, gradients, numerical stability)\n- üî¨ **Tier 2:** Advanced analysis (attention patterns, robustness, profiling)\n- üöÄ **Tier 3:** Training utilities (fine-tuning, hyperparameter sweeps, benchmarks)\n\n**Quick Start:**\n1. Click \"Run all\" (Runtime ‚Üí Run all)\n2. Review Tier 1 results (should complete in ~1 minute)\n3. Explore Tier 2/3 sections as needed\n\n**Source:** Generated from [Transformer Builder](https://transformer-builder.com)\n\n---",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n\n## üìã **STEP 1: Paste Your Gist ID**\n\nWhen you exported from **Transformer Builder**, you received a **Gist ID**.\n\n**Paste it in the cell below and run it.**\n\nIf you don't have a Gist ID yet, go back to Transformer Builder and click **\"Export to Colab\"**."
  },
  {
   "cell_type": "code",
   "source": "# ==============================================================================\n# GIST ID INPUT - Paste the ID from Transformer Builder\n# ==============================================================================\n\n#@title üì• **Paste Your Gist ID Here**\nGIST_ID = \"\"  #@param {type:\"string\"}\n\n#@markdown ---\n#@markdown **Where to find your Gist ID:**\n#@markdown 1. Go to Transformer Builder\n#@markdown 2. Click \"Export to Colab\"\n#@markdown 3. Copy the Gist ID from the modal\n#@markdown 4. Paste it above and run this cell\n\nif not GIST_ID or not GIST_ID.strip():\n    print(\"=\" * 70)\n    print(\"‚ö†Ô∏è  NO GIST ID PROVIDED\")\n    print(\"=\" * 70)\n    print()\n    print(\"Please paste your Gist ID in the field above and re-run this cell.\")\n    print()\n    print(\"If you don't have a Gist ID:\")\n    print(\"  1. Go to Transformer Builder\")\n    print(\"  2. Click 'Export to Colab'\")\n    print(\"  3. Copy the Gist ID from the modal\")\n    print(\"  4. Come back here and paste it\")\n    print()\n    raise ValueError(\"Gist ID is required to load your custom model\")\nelse:\n    # Validate format\n    import re\n    if not re.fullmatch(r\"[A-Za-z0-9]+\", GIST_ID.strip()):\n        print(\"=\" * 70)\n        print(\"‚ö†Ô∏è  INVALID GIST ID FORMAT\")\n        print(\"=\" * 70)\n        print()\n        print(f\"The Gist ID you entered: {GIST_ID!r}\")\n        print()\n        print(\"Gist IDs should be alphanumeric (e.g., 'abc123def456')\")\n        print(\"Please check and re-enter.\")\n        print()\n        raise ValueError(\"Invalid Gist ID format\")\n    \n    # Store for later use\n    GIST_ID = GIST_ID.strip()\n    \n    print(\"=\" * 70)\n    print(\"‚úÖ GIST ID SAVED\")\n    print(\"=\" * 70)\n    print()\n    print(f\"Gist ID: {GIST_ID}\")\n    print()\n    print(\"You can now proceed to run the cells below to:\")\n    print(\"  1. Install dependencies\")\n    print(\"  2. Load your custom model\")\n    print(\"  3. Run tests\")\n    print()\n    print(\"üí° Tip: Click 'Runtime ‚Üí Run all' to execute everything automatically\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# ==============================================================================\n# RUNTIME FRESHNESS DETECTION - Prevents reused runtimes with corrupted packages\n# ==============================================================================\n\nimport os\n\n# Check if this runtime was previously used\nRUNTIME_MARKER = \"/tmp/transformer_builder_runtime_used\"\n\nprint(\"=\" * 70)\nprint(\"üîç RUNTIME FRESHNESS CHECK\")\nprint(\"=\" * 70)\nprint()\n\nif os.path.exists(RUNTIME_MARKER):\n    print(\"‚ö†Ô∏è  WARNING: This runtime was previously used!\")\n    print()\n    print(\"Reusing runtimes can cause dependency conflicts.\")\n    print()\n    print(\"‚úÖ RECOMMENDED: Restart runtime for clean environment\")\n    print(\"   (Runtime ‚Üí Restart runtime ‚Üí Run all)\")\n    print()\n    print(\"=\" * 70)\n    \n    # Give user option to continue anyway (advanced users)\n    response = input(\"Continue with reused runtime anyway? [y/N]: \")\n    \n    if response.lower() != 'y':\n        print()\n        print(\"‚úÖ Good choice! Please restart the runtime and try again.\")\n        raise RuntimeError(\"Runtime restart recommended for clean environment\")\n    else:\n        print()\n        print(\"‚ö†Ô∏è  Proceeding with reused runtime...\")\n        print()\nelse:\n    # Mark runtime as used\n    with open(RUNTIME_MARKER, 'w') as f:\n        f.write(\"used\")\n    \n    print(\"‚úÖ Fresh runtime detected!\")\n    print()\n\nprint(\"üìå Version: v3.3.2 (2025-01-13)\")\nprint(\"üìå Fix: Proactive numpy repair + minimal dependencies\")\nprint()\nprint(\"=\" * 70)\nprint(\"‚úÖ Runtime check complete\")\nprint(\"=\" * 70)\nprint()",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ==============================================================================\n# DEPENDENCY INSTALLATION - v3.3.2 minimal dependencies (prevents corruption)\n# ==============================================================================\n\nfrom IPython.display import clear_output\nimport gc\n\nprint(\"üì¶ Installing core dependencies...\")\nprint()\n\n# ==============================================================================\n# INSTALLATION: Minimal safe dependencies\n# ==============================================================================\n\n# Step 1: Upgrade pip (silent)\n!pip install --upgrade pip -qq\n\n# Step 2: Install minimal safe dependencies (only torchinfo, pytest, pytest-cov)\n!wget -qq https://raw.githubusercontent.com/matt-hans/transformer-builder-colab-templates/main/requirements-colab.txt -O requirements-colab.txt\n!pip install -qq -r requirements-colab.txt\n\n# Step 3: Install pytorch-lightning with --no-deps (prevents dependency hell)\n!pip install -qq --no-deps 'pytorch-lightning>=2.4.0,<2.6.0'\n!pip install -qq --no-deps 'torchmetrics>=1.3.0,<2.0.0'\n!pip install -qq --no-deps 'lightning-utilities>=0.10.0'\n\n# Clear installation output to prevent console overflow\nclear_output(wait=True)\n\n# ==============================================================================\n# POST-INSTALLATION VERIFICATION: Ensure numpy still intact\n# ==============================================================================\n\ndef check_numpy_integrity():\n    try:\n        from numpy._core.umath import _center\n        return True\n    except ImportError:\n        return False\n\nif not check_numpy_integrity():\n    print(\"=\" * 70)\n    print(\"‚ùå UNEXPECTED: NumPy corrupted DURING installation!\")\n    print(\"=\" * 70)\n    print()\n    print(\"This should NOT happen with v3.3.2 minimal dependencies.\")\n    print()\n    print(\"üêõ PLEASE REPORT THIS BUG:\")\n    print(\"   GitHub: https://github.com/matt-hans/transformer-builder-colab-templates/issues\")\n    print(\"   Include: Screenshot + Colab version\")\n    print()\n    print(\"üîß WORKAROUND: Runtime ‚Üí Restart runtime ‚Üí Run all\")\n    print()\n    raise ImportError(\"NumPy corrupted during installation - critical bug!\")\n\n# ==============================================================================\n# VERIFICATION: Check all critical imports\n# ==============================================================================\n\nprint(\"=\" * 70)\nprint(\"INSTALLATION VERIFICATION\")\nprint(\"=\" * 70)\n\ntry:\n    import numpy as np\n    import torch\n    import pytorch_lightning as pl\n    from transformers import AutoTokenizer\n    import torchinfo\n    \n    print(f\"‚úÖ numpy: {np.__version__} (Colab pre-installed)\")\n    print(f\"‚úÖ torch: {torch.__version__} (Colab pre-installed)\")\n    print(f\"‚úÖ pytorch-lightning: {pl.__version__}\")\n    print(f\"‚úÖ transformers: (Colab pre-installed)\")\n    print(f\"‚úÖ torchinfo: {torchinfo.__version__}\")\n    print(f\"‚úÖ numpy C extensions: intact\")\n    \n    # Check for GPU\n    if torch.cuda.is_available():\n        print(f\"‚úÖ GPU: {torch.cuda.get_device_name(0)}\")\n        print(f\"‚úÖ CUDA: {torch.version.cuda}\")\n    else:\n        print(\"‚ö†Ô∏è  GPU: Not available (CPU mode)\")\n    \n    # Cleanup memory\n    gc.collect()\n    \n    print()\n    print(\"=\" * 70)\n    print(\"‚úÖ INSTALLATION COMPLETE - All core dependencies ready!\")\n    print(\"=\" * 70)\n    print()\n    print(\"üìù Note: Tier 1 tests work immediately.\")\n    print(\"   Tier 2/3 require optional packages (see cells before those tiers).\")\n    \nexcept ImportError as e:\n    print(f\"‚ùå Import error: {e}\")\n    print()\n    print(\"üîß Troubleshooting:\")\n    print(\"   1. Runtime ‚Üí Restart runtime\")\n    print(\"   2. Run all cells from beginning\")\n    print(\"   3. If persists, report as bug\")\n    raise"
  },
  {
   "cell_type": "code",
   "source": "# ==============================================================================\n# DOWNLOAD UTILS PACKAGE\n# ==============================================================================\n\nprint(\"üì¶ Downloading test utilities package...\")\n\n# Remove old utils directory if exists\n!rm -rf utils/\n\n# Download complete utils package from GitHub\n!git clone --depth 1 --branch main https://github.com/matt-hans/transformer-builder-colab-templates.git temp_repo 2>/dev/null\n\n# Copy utils directory\n!cp -r temp_repo/utils ./\n\n# Cleanup\n!rm -rf temp_repo\n\n# Verify package structure\nimport sys\nimport os\n\n# Add current directory to Python path\nif './' not in sys.path:\n    sys.path.insert(0, './')\n\n# Verify utils package is importable\ntry:\n    import utils\n    print(f\"‚úÖ Utils package loaded (version {utils.__version__})\")\n    \n    # Verify package structure\n    utils_path = os.path.join(os.getcwd(), 'utils')\n    subdirs = ['adapters', 'tokenization', 'training', 'ui']\n    \n    for subdir in subdirs:\n        subdir_path = os.path.join(utils_path, subdir)\n        if os.path.exists(subdir_path):\n            print(f\"‚úÖ {subdir}/ directory found\")\n        else:\n            print(f\"‚ö†Ô∏è  {subdir}/ directory missing\")\n    \n    # Test importing test functions (backward compatibility)\n    from utils import (\n        test_shape_robustness,\n        test_gradient_flow,\n        test_output_stability,\n        run_all_tier1_tests\n    )\n    print(\"‚úÖ Test functions importable\")\n    \n    print(\"\\n‚úÖ Utils package ready!\")\n    \nexcept ImportError as e:\n    print(f\"‚ùå Failed to import utils package: {e}\")\n    print(\"Falling back to direct file download...\")\n    # Fallback: download test_functions.py directly\n    !wget -q https://raw.githubusercontent.com/matt-hans/transformer-builder-colab-templates/main/utils/test_functions.py",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "# ==============================================================================\n# LOAD CUSTOM MODEL - v3.4.0 (Simple Modal Approach)\n# ==============================================================================\n\nimport os, re, json, urllib.request, urllib.error\n\nprint(\"=\" * 70)\nprint(\"MODEL LOADING\")\nprint(\"=\" * 70)\nprint()\n\n# ==============================================================================\n# VERIFY GIST ID WAS PROVIDED\n# ==============================================================================\n\nif 'GIST_ID' not in globals() or not GIST_ID:\n    print(\"‚ùå ERROR: No Gist ID found!\")\n    print()\n    print(\"=\" * 70)\n    print(\"üîô GO BACK TO CELL 3\")\n    print(\"=\" * 70)\n    print()\n    print(\"You must run Cell 3 first to provide your Gist ID.\")\n    print()\n    print(\"Steps:\")\n    print(\"  1. Scroll up to Cell 3\")\n    print(\"  2. Paste your Gist ID from Transformer Builder\")\n    print(\"  3. Run Cell 3\")\n    print(\"  4. Come back and run this cell\")\n    print()\n    raise ValueError(\"Gist ID required - please run Cell 3 first\")\n\ngist_id = GIST_ID\nmodel_name = \"Model\"  # Default name, will be overridden from config\n\nprint(f\"üì• Loading model from GitHub Gist: {gist_id}\")\nprint()\n\n# ==============================================================================\n# FETCH GIST AND LOAD MODEL FILES\n# ==============================================================================\n\ndef _fetch_gist(gid: str) -> dict:\n    \"\"\"Fetch Gist data from GitHub API.\"\"\"\n    url = f\"https://api.github.com/gists/{gid}\"\n    req = urllib.request.Request(url, headers={\n        \"Accept\": \"application/vnd.github+json\",\n        \"User-Agent\": \"transformer-builder-colab\"\n    })\n    try:\n        with urllib.request.urlopen(req, timeout=20) as resp:\n            return json.loads(resp.read().decode(\"utf-8\"))\n    except urllib.error.HTTPError as e:\n        detail = f\"HTTP {e.code}\"\n        try:\n            body = e.read().decode(\"utf-8\")\n            if \"rate limit\" in body.lower():\n                detail += \" - GitHub API rate limit (try again in an hour)\"\n            elif e.code == 404:\n                detail += \" - Gist not found (check your Gist ID)\"\n        except:\n            pass\n        raise RuntimeError(f\"GitHub API error: {detail}\") from e\n    except Exception as e:\n        raise RuntimeError(f\"Network error: {e}\") from e\n\ndef _write(path: str, text: str):\n    \"\"\"Write text to file.\"\"\"\n    with open(path, \"w\") as f:\n        f.write(text)\n\n# Fetch Gist\ntry:\n    gist_data = _fetch_gist(gist_id)\n    files = gist_data.get(\"files\") or {}\n    \n    # Check for required files\n    if \"model.py\" not in files:\n        raise RuntimeError(\"Gist is missing 'model.py' - please re-export from Transformer Builder\")\n    if \"config.json\" not in files:\n        raise RuntimeError(\"Gist is missing 'config.json' - please re-export from Transformer Builder\")\n    \n    model_code = files[\"model.py\"].get(\"content\", \"\")\n    config_json = files[\"config.json\"].get(\"content\", \"\")\n    \n    if not model_code or not config_json:\n        raise RuntimeError(\"Empty content in model.py or config.json\")\n    \n    # Write to files\n    _write(\"custom_transformer.py\", model_code)\n    _write(\"config.json\", config_json)\n    \n    print(f\"‚úÖ Model loaded successfully!\")\n    print(f\"‚úÖ Gist URL: {gist_data.get('html_url', 'N/A')}\")\n    print(f\"‚úÖ Model code: {len(model_code):,} bytes\")\n    print(f\"‚úÖ Config: {len(config_json):,} bytes\")\n    print()\n    \n    # Parse model name from config if available\n    try:\n        config_dict = json.loads(config_json)\n        if 'model_name' in config_dict:\n            model_name = config_dict['model_name']\n            print(f\"‚úÖ Model name: {model_name}\")\n            print()\n    except:\n        pass\n\nexcept Exception as e:\n    print(f\"‚ùå Failed to load model from Gist!\")\n    print()\n    print(f\"Error: {e}\")\n    print()\n    print(\"=\" * 70)\n    print(\"TROUBLESHOOTING\")\n    print(\"=\" * 70)\n    print()\n    print(\"Common issues:\")\n    print(\"  1. Check your Gist ID is correct (go back to Cell 3)\")\n    print(\"  2. Ensure you exported from Transformer Builder successfully\")\n    print(\"  3. Check you're not hitting GitHub rate limit (60 requests/hour)\")\n    print(\"  4. Try re-exporting from Transformer Builder\")\n    print()\n    print(\"If the problem persists:\")\n    print(f\"  ‚Ä¢ Gist URL: https://gist.github.com/{gist_id}\")\n    print(\"  ‚Ä¢ Verify the Gist contains model.py and config.json\")\n    print()\n    raise\n\nprint(\"=\" * 70)\nprint(\"‚úÖ MODEL LOADING COMPLETE\")\nprint(\"=\" * 70)\nprint()\nprint(\"Next: Continue to model instantiation and testing below!\")\nprint()\n\n# Store model_name for next cell\nparams = {\"name\": model_name}"
  },
  {
   "cell_type": "markdown",
   "source": "## üìÑ View Loaded Model Code\n\nThis cell displays the Python code that was loaded from your Transformer Builder export. You can review the architecture before running tests.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Display the loaded model code for transparency\nprint(\"=\" * 80)\nprint(\"üìÑ LOADED MODEL CODE (custom_transformer.py)\")\nprint(\"=\" * 80)\nprint()\n\nwith open('custom_transformer.py', 'r') as f:\n    model_code_display = f.read()\n\n# Use syntax highlighting\nfrom IPython.display import Code\ndisplay(Code(model_code_display, language='python'))\n\nprint()\nprint(\"=\" * 80)\nprint(\"üìã MODEL CONFIGURATION (config.json)\")\nprint(\"=\" * 80)\nprint()\n\nwith open('config.json', 'r') as f:\n    config_display = json.load(f)\n\n# Pretty print JSON\nprint(json.dumps(config_display, indent=2))\nprint()\nprint(\"‚úÖ You can now proceed to run the model instantiation and tests below!\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dynamic Dependency Detection\n",
    "\n",
    "Automatically detect and install any custom dependencies your model needs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "# Parse imports from generated code\n",
    "with open('custom_transformer.py', 'r') as f:\n",
    "    source_code = f.read()\n",
    "    tree = ast.parse(source_code)\n",
    "\n",
    "# Extract all imports\n",
    "imports = set()\n",
    "for node in ast.walk(tree):\n",
    "    if isinstance(node, ast.Import):\n",
    "        for alias in node.names:\n",
    "            imports.add(alias.name.split('.')[0])\n",
    "    elif isinstance(node, ast.ImportFrom):\n",
    "        if node.module:\n",
    "            imports.add(node.module.split('.')[0])\n",
    "\n",
    "print(f\"Detected imports: {', '.join(sorted(imports))}\")\n",
    "\n",
    "# Standard library modules (don't need pip install)\n",
    "stdlib_modules = {\n",
    "    'abc', 'collections', 'dataclasses', 'functools', 'json', 'math',\n",
    "    'typing', 'warnings', 'os', 'sys', 're', 'time', 'copy'\n",
    "}\n",
    "\n",
    "# Already installed\n",
    "installed_modules = {\n",
    "    'torch', 'transformers', 'numpy', 'scipy', 'matplotlib',\n",
    "    'pandas', 'seaborn', 'tqdm', 'torchinfo', 'captum', 'optuna'\n",
    "}\n",
    "\n",
    "# Find missing packages\n",
    "missing = imports - stdlib_modules - installed_modules\n",
    "\n",
    "if missing:\n",
    "    print(f\"\\nInstalling additional dependencies: {', '.join(missing)}\")\n",
    "    for package in missing:\n",
    "        try:\n",
    "            subprocess.check_call(\n",
    "                [sys.executable, '-m', 'pip', 'install', '-q', package],\n",
    "                stdout=subprocess.DEVNULL,\n",
    "                stderr=subprocess.DEVNULL\n",
    "            )\n",
    "            print(f\"  ‚úÖ Installed {package}\")\n",
    "        except subprocess.CalledProcessError:\n",
    "            print(f\"  ‚ö†Ô∏è Failed to install {package} (may not be a pip package)\")\n",
    "else:\n",
    "    print(\"\\n‚úÖ All dependencies already installed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import and Instantiate Model\n",
    "\n",
    "Load your custom transformer and prepare for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchinfo import summary\n",
    "\n",
    "# Import the custom model\n",
    "exec(open('custom_transformer.py').read())\n",
    "\n",
    "# Load config\n",
    "with open('config.json') as f:\n",
    "    config_dict = json.load(f)\n",
    "\n",
    "# Find the model class\n",
    "model_class = None\n",
    "for name, obj in list(globals().items()):\n",
    "    if isinstance(obj, type) and issubclass(obj, nn.Module) and obj is not nn.Module:\n",
    "        if name == params['name']:\n",
    "            model_class = obj\n",
    "            break\n",
    "\n",
    "if model_class is None:\n",
    "    # Fallback: find any nn.Module subclass\n",
    "    for name, obj in list(globals().items()):\n",
    "        if isinstance(obj, type) and issubclass(obj, nn.Module) and obj is not nn.Module:\n",
    "            model_class = obj\n",
    "            print(f\"‚ö†Ô∏è Using {name} (expected {params['name']})\")\n",
    "            break\n",
    "\n",
    "if model_class:\n",
    "    # Instantiate model\n",
    "    try:\n",
    "        model = model_class(**config_dict)\n",
    "        model.eval()\n",
    "        \n",
    "        total_params = sum(p.numel() for p in model.parameters())\n",
    "        trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "        \n",
    "        print(f\"‚úÖ Model instantiated: {model_class.__name__}\")\n",
    "        print(f\"‚úÖ Total parameters: {total_params:,}\")\n",
    "        print(f\"‚úÖ Trainable parameters: {trainable_params:,}\")\n",
    "        \n",
    "        # Move to GPU if available\n",
    "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        model = model.to(device)\n",
    "        print(f\"‚úÖ Device: {device}\")\n",
    "        \n",
    "        # Display model summary\n",
    "        print(\"\\n--- Model Summary ---\")\n",
    "        try:\n",
    "            # Create dummy input based on config\n",
    "            vocab_size = config_dict.get('vocab_size', 50257)\n",
    "            dummy_input = torch.randint(0, vocab_size, (1, 32)).to(device)\n",
    "            summary(model, input_data=dummy_input, depth=3)\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Could not generate summary: {e}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Failed to instantiate model: {e}\")\n",
    "        raise\n",
    "else:\n",
    "    raise RuntimeError(f\"Could not find model class '{params['name']}' in generated code\")\n",
    "\n",
    "# Create config object for test functions\n",
    "class ModelConfig:\n",
    "    def __init__(self, **kwargs):\n",
    "        for key, value in kwargs.items():\n",
    "            setattr(self, key, value)\n",
    "\n",
    "config = ModelConfig(**config_dict)\n",
    "print(\"\\n‚úÖ Ready for testing!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": "---\n\n# üîç Tier 1: Critical Validation\n\nThese tests verify your model is mathematically sound and ready for training.\n\n**Estimated time:** ~1 minute\n\n**What's tested:**\n- ‚úÖ Shape validation across edge cases\n- ‚úÖ Gradient flow (detect vanishing/exploding gradients)\n- ‚úÖ Numerical stability (NaN/Inf detection)\n- ‚úÖ Parameter initialization quality\n- ‚úÖ Memory footprint scaling\n- ‚úÖ Inference speed benchmarks",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Import test utilities from the cloned utils package\nfrom utils.test_functions import (\n    test_shape_robustness,\n    test_gradient_flow,\n    test_output_stability,\n    test_parameter_initialization,\n    test_memory_footprint,\n    test_inference_speed\n)\n\nprint(\"‚úÖ Test functions loaded from utils package\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "print(\"=\" * 80)\nprint(\"TIER 1: CRITICAL VALIDATION\")\nprint(\"=\" * 80)\nprint()\n\n# Test 1: Shape Robustness\nprint(\"Test 1/6: Shape Validation\")\nprint(\"-\" * 80)\nshape_results = test_shape_robustness(model, config)\ndisplay(shape_results)\nprint()\n\n# Test 2: Gradient Flow\nprint(\"Test 2/6: Gradient Flow Analysis\")\nprint(\"-\" * 80)\ngrad_results = test_gradient_flow(model, config)\ndisplay(grad_results)\nprint()\n\n# Test 3: Output Stability\nprint(\"Test 3/6: Numerical Stability\")\nprint(\"-\" * 80)\nstability_stats = test_output_stability(model, config, n_samples=100)\nprint()\n\n# Test 4: Parameter Initialization\nprint(\"Test 4/6: Parameter Initialization\")\nprint(\"-\" * 80)\nparam_results = test_parameter_initialization(model)\ndisplay(param_results)\nprint()\n\n# Test 5: Memory Footprint\nprint(\"Test 5/6: Memory Footprint Analysis\")\nprint(\"-\" * 80)\nmemory_results = test_memory_footprint(model, config)\ndisplay(memory_results)\nprint()\n\n# Test 6: Inference Speed\nprint(\"Test 6/6: Inference Speed Benchmark\")\nprint(\"-\" * 80)\nspeed_stats = test_inference_speed(model, config, n_trials=50)\nprint()\n\nprint(\"=\" * 80)\nprint(\"‚úÖ TIER 1 VALIDATION COMPLETE\")\nprint(\"=\" * 80)\nprint()\nprint(\"All critical tests passed! Your model is mathematically sound.\")\nprint()\nprint(\"üìù Next steps:\")\nprint(\"   ‚Ä¢ Tier 2: Advanced analysis (attention patterns, attribution)\")\nprint(\"     ‚Üí Install optional dependencies in the cell before Tier 2\")\nprint(\"     ‚Üí Then run Tier 2 tests\")\nprint()\nprint(\"   ‚Ä¢ Tier 3: Training utilities (fine-tuning, hyperparameter search)\")\nprint(\"     ‚Üí Install optional dependencies in the cell before Tier 3\")\nprint(\"     ‚Üí Then run Tier 3 tests\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "---\n\n# üî¨ Tier 2: Advanced Analysis\n\nDeep dive into model behavior with advanced diagnostic tools.\n\n**Estimated time:** ~3-5 minutes\n\n**What's tested:**\n- üéØ **Attention Patterns:** Visualize attention weights, detect collapsed attention, analyze head specialization\n- üîç **Attribution Analysis:** Identify which input tokens contribute most to predictions (using Captum)\n- üõ°Ô∏è **Robustness Testing:** Measure stability under input perturbations and noise\n\n**Note:** These tests are optional but highly recommended for understanding model behavior.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# ==============================================================================\n# TIER 2 OPTIONAL DEPENDENCIES - Run this cell to enable advanced analysis\n# ==============================================================================\n\nprint(\"üì¶ Installing Tier 2 dependencies (captum for attribution analysis)...\")\nprint()\nprint(\"‚è≥ This may take 10-15 seconds...\")\nprint()\n\n# Install captum (for feature attribution analysis)\n# Using --no-deps to prevent numpy corruption\n!pip install -qq --no-deps captum\n\n# Verify installation\ntry:\n    import captum\n    from captum.attr import IntegratedGradients\n    print(f\"‚úÖ captum: {captum.__version__} (attribution analysis)\")\n    print()\n    print(\"=\" * 70)\n    print(\"‚úÖ Tier 2 dependencies installed successfully!\")\n    print(\"=\" * 70)\n    print()\n    print(\"You can now run all Tier 2 tests below.\")\nexcept ImportError as e:\n    print(f\"‚ö†Ô∏è  Installation incomplete: {e}\")\n    print(\"Tier 2 tests will skip features requiring captum.\")\nprint()",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## üì¶ Optional: Install Tier 2 Dependencies\n\n**Note:** Tier 2 tests use lazy imports - they will skip gracefully if dependencies are missing.\n\n**To enable all Tier 2 functionality, run the cell below:**",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# ==============================================================================\n# TIER 3 OPTIONAL DEPENDENCIES - Run this cell to enable training utilities\n# ==============================================================================\n\nprint(\"üì¶ Installing Tier 3 dependencies (optuna for hyperparameter search)...\")\nprint()\nprint(\"‚è≥ This may take 20-30 seconds...\")\nprint()\n\n# Install optuna (for hyperparameter optimization)\n# Using --no-deps to prevent numpy corruption\n!pip install -qq --no-deps optuna\n\n# Install optuna's critical dependencies separately (avoids scipy conflicts)\n!pip install -qq alembic colorlog sqlalchemy\n\n# Optionally install datasets if needed for fine-tuning with real data\n# !pip install -qq --no-deps datasets\n# !pip install -qq pyarrow dill xxhash multiprocess\n\n# Verify installation\ntry:\n    import optuna\n    print(f\"‚úÖ optuna: {optuna.__version__} (hyperparameter optimization)\")\n    print()\n    print(\"=\" * 70)\n    print(\"‚úÖ Tier 3 dependencies installed successfully!\")\n    print(\"=\" * 70)\n    print()\n    print(\"You can now run all Tier 3 tests below.\")\n    print()\n    print(\"üí° Tip: Uncomment the 'datasets' installation lines above if you need\")\n    print(\"   to fine-tune with real datasets (currently uses synthetic data).\")\nexcept ImportError as e:\n    print(f\"‚ö†Ô∏è  Installation incomplete: {e}\")\n    print(\"Tier 3 tests will skip features requiring optuna.\")\nprint()",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## üì¶ Optional: Install Tier 3 Dependencies\n\n**Note:** Tier 3 tests use lazy imports - they will skip gracefully if dependencies are missing.\n\n**To enable all Tier 3 functionality, run the cell below:**\n\n‚ö†Ô∏è **Warning:** These dependencies are more complex and may take longer to install.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Import Tier 2 test functions\nfrom utils.test_functions import (\n    test_attention_patterns,\n    test_attribution_analysis,\n    test_robustness\n)\n\nprint(\"=\" * 80)\nprint(\"TIER 2: ADVANCED ANALYSIS\")\nprint(\"=\" * 80)\nprint()\n\n# Test 1: Attention Patterns\nprint(\"Test 1/3: Attention Pattern Analysis\")\nprint(\"-\" * 80)\ntry:\n    attention_results = test_attention_patterns(model, config)\n    if attention_results is not None:\n        display(attention_results)\n    print(\"‚úÖ Attention analysis complete\")\nexcept Exception as e:\n    print(f\"‚ö†Ô∏è Attention analysis skipped: {e}\")\nprint()\n\n# Test 2: Attribution Analysis\nprint(\"Test 2/3: Input Attribution Analysis\")\nprint(\"-\" * 80)\ntry:\n    attribution_results = test_attribution_analysis(model, config)\n    if attribution_results is not None:\n        print(\"\\nTop Contributing Tokens:\")\n        for token, score in attribution_results.get(\"top_tokens\", []):\n            print(f\"  {token:20s}: {score:+.4f}\")\n    print(\"‚úÖ Attribution analysis complete\")\nexcept Exception as e:\n    print(f\"‚ö†Ô∏è Attribution analysis skipped: {e}\")\nprint()\n\n# Test 3: Robustness Testing\nprint(\"Test 3/3: Robustness Under Noise\")\nprint(\"-\" * 80)\ntry:\n    robustness_results = test_robustness(model, config, n_samples=20)\n    if robustness_results is not None:\n        display(robustness_results)\n    print(\"‚úÖ Robustness analysis complete\")\nexcept Exception as e:\n    print(f\"‚ö†Ô∏è Robustness analysis skipped: {e}\")\nprint()\n\nprint(\"=\" * 80)\nprint(\"‚úÖ TIER 2 ANALYSIS COMPLETE\")\nprint(\"=\" * 80)\nprint()\nprint(\"Next: Scroll down for Tier 3 (Training & Fine-Tuning)\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "---\n\n# üöÄ Tier 3: Training & Production Utilities\n\nAdvanced utilities for fine-tuning, hyperparameter optimization, and production benchmarking.\n\n**Estimated time:** ~10-20 minutes (depends on training iterations)\n\n**What's included:**\n- üéì **Fine-Tuning:** Basic training loop with loss tracking and gradient monitoring\n- üîß **Hyperparameter Search:** Automated optimization using Optuna (learning rate, batch size, warmup)\n- üìä **Benchmark Comparison:** Compare your model against production baselines (distilgpt2, bert-base, etc.)\n\n**Note:** These are compute-intensive operations. Consider using GPU runtime for faster execution.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Import Tier 3 training utilities\nfrom utils.test_functions import (\n    test_fine_tuning,\n    test_hyperparameter_search,\n    test_benchmark_comparison\n)\n\nprint(\"=\" * 80)\nprint(\"TIER 3: TRAINING & PRODUCTION UTILITIES\")\nprint(\"=\" * 80)\nprint()\n\n# Test 1: Fine-Tuning\nprint(\"Test 1/3: Fine-Tuning Demo\")\nprint(\"-\" * 80)\nprint(\"Running 3 epochs of fine-tuning with synthetic data...\")\ntry:\n    fine_tune_results = test_fine_tuning(\n        model, \n        config, \n        num_epochs=3,\n        batch_size=2,\n        learning_rate=5e-5\n    )\n    print(f\"\\nFinal Loss: {fine_tune_results['final_loss']:.4f}\")\n    print(f\"Best Loss: {fine_tune_results['best_loss']:.4f}\")\n    print(\"‚úÖ Fine-tuning complete\")\nexcept Exception as e:\n    print(f\"‚ö†Ô∏è Fine-tuning skipped: {e}\")\nprint()\n\n# Test 2: Hyperparameter Search (OPTIONAL - Comment out to skip)\nprint(\"Test 2/3: Hyperparameter Optimization\")\nprint(\"-\" * 80)\nprint(\"‚ö†Ô∏è Skipping hyperparameter search (compute-intensive)\")\nprint(\"To enable: uncomment the code block below\")\nprint()\n# Uncomment to run:\n# try:\n#     hp_results = test_hyperparameter_search(\n#         model,\n#         config,\n#         n_trials=5,\n#         epochs_per_trial=2\n#     )\n#     print(\"\\nBest Parameters:\")\n#     for param, value in hp_results['best_params'].items():\n#         print(f\"  {param}: {value}\")\n#     print(\"‚úÖ Hyperparameter search complete\")\n# except Exception as e:\n#     print(f\"‚ö†Ô∏è Hyperparameter search failed: {e}\")\n\n# Test 3: Benchmark Comparison\nprint(\"Test 3/3: Benchmark Against Baseline\")\nprint(\"-\" * 80)\nprint(\"Comparing against distilgpt2 baseline...\")\ntry:\n    benchmark_results = test_benchmark_comparison(\n        model,\n        config,\n        baseline_model=\"distilgpt2\",\n        n_samples=10\n    )\n    if benchmark_results is not None:\n        display(benchmark_results)\n    print(\"‚úÖ Benchmark comparison complete\")\nexcept Exception as e:\n    print(f\"‚ö†Ô∏è Benchmark comparison skipped: {e}\")\nprint()\n\nprint(\"=\" * 80)\nprint(\"‚úÖ TIER 3 TRAINING UTILITIES COMPLETE\")\nprint(\"=\" * 80)\nprint()\nprint(\"üéâ All testing tiers complete! Your model is production-ready.\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}