{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üß™ Transformer Builder - Advanced Testing Lab\n",
    "\n",
    "Welcome! This notebook provides comprehensive testing and training capabilities for your custom transformer architecture.\n",
    "\n",
    "**What's included:**\n",
    "- ‚úÖ **Tier 1:** Critical validation (shape, gradients, numerical stability)\n",
    "- üî¨ **Tier 2:** Advanced analysis (attention patterns, robustness, profiling)\n",
    "- üöÄ **Tier 3:** Training utilities (fine-tuning, hyperparameter sweeps, benchmarks)\n",
    "\n",
    "**Quick Start:**\n",
    "1. Click \"Run all\" (Runtime ‚Üí Run all)\n",
    "2. Review Tier 1 results (should complete in ~1 minute)\n",
    "3. Explore Tier 2/3 sections as needed\n",
    "\n",
    "**Source:** Generated from [Transformer Builder](https://transformer-builder.com)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## ‚úÖ Notebook Version Check\n\n**Current Version**: v3.1.0 (2025-01-13)  \n**Changelog**: Surgical dependency install with --no-deps to prevent numpy corruption\n\n**‚ö†Ô∏è IMPORTANT**: This version uses --no-deps for pytorch-lightning!  \n**‚úÖ CORRECT**: Should show \"Step 3/3: Installing pytorch-lightning (without dependency resolution)...\"\n\n---\n\n## Setup: Install Dependencies\n\nThis may take 20-40 seconds."
  },
  {
   "cell_type": "code",
   "source": "# ==============================================================================\n# VERSION VERIFICATION - Run this cell first to confirm correct notebook version\n# ==============================================================================\n\nprint(\"=\" * 70)\nprint(\"üîç NOTEBOOK VERSION VERIFICATION\")\nprint(\"=\" * 70)\nprint()\nprint(\"üìå Expected Version: v3.1.0 (2025-01-13)\")\nprint(\"üìå Key Strategy:\")\nprint(\"   ‚Ä¢ Use --no-deps for pytorch-lightning\")\nprint(\"   ‚Ä¢ Prevents pip from corrupting Colab's numpy\")\nprint(\"   ‚Ä¢ 3-step installation process\")\nprint()\nprint(\"=\" * 70)\nprint(\"‚úÖ If you see '3 steps' with --no-deps, CORRECT version!\")\nprint(\"‚ùå If you see different steps, clear browser cache!\")\nprint(\"=\" * 70)\nprint()\nprint(\"Next: Run the cell below to install dependencies.\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ==============================================================================\n# DEPENDENCY INSTALLATION - Surgical approach to prevent numpy corruption\n# ==============================================================================\n\nprint(\"üì¶ Installing dependencies (surgical install to prevent numpy corruption)...\")\nprint()\n\n# Step 1: Upgrade pip\nprint(\"Step 1/3: Upgrading pip...\")\n!pip install --upgrade pip -q\nprint(\"‚úì pip upgraded\\n\")\n\n# Step 2: Install safe dependencies (no numpy conflicts)\nprint(\"Step 2/3: Installing safe dependencies...\")\n!wget -q https://raw.githubusercontent.com/matt-hans/transformer-builder-colab-templates/main/requirements-colab.txt -O requirements-colab.txt\n!pip install -q -r requirements-colab.txt\nprint(\"‚úì Safe dependencies installed\\n\")\n\n# Step 3: Install pytorch-lightning with --no-deps to prevent numpy corruption\nprint(\"Step 3/3: Installing pytorch-lightning (without dependency resolution)...\")\nprint(\"  (Using --no-deps to prevent pip from corrupting numpy)\")\n\n# Install ONLY the specific packages we need, without letting pip resolve deps\n!pip install -q --no-deps 'pytorch-lightning>=2.4.0,<2.6.0'\n!pip install -q --no-deps 'torchmetrics>=1.3.0,<2.0.0'\n!pip install -q --no-deps 'lightning-utilities>=0.10.0'\n\nprint(\"‚úì pytorch-lightning installed\\n\")\n\n# Verify critical imports (using Colab's pre-installed numpy and torch)\nprint(\"=\" * 60)\nprint(\"VERIFICATION\")\nprint(\"=\" * 60)\n\ntry:\n    import numpy as np\n    import torch\n    import pytorch_lightning as pl\n    from transformers import AutoTokenizer\n    \n    print(f\"‚úÖ numpy: {np.__version__} (Colab pre-installed)\")\n    print(f\"‚úÖ torch: {torch.__version__} (Colab pre-installed)\")\n    print(f\"‚úÖ pytorch-lightning: {pl.__version__} (installed with --no-deps)\")\n    print(f\"‚úÖ transformers: (Colab pre-installed)\")\n    \n    # Verify numpy is not corrupted\n    try:\n        from numpy import rec, core\n        from numpy._core import umath\n        print(f\"‚úÖ numpy C extensions: intact\")\n    except ImportError as e:\n        print(f\"‚ùå numpy C extensions: corrupted ({e})\")\n        raise\n    \n    # Check for GPU\n    if torch.cuda.is_available():\n        print(f\"‚úÖ GPU: {torch.cuda.get_device_name(0)}\")\n        print(f\"‚úÖ CUDA: {torch.version.cuda}\")\n    else:\n        print(\"‚ö†Ô∏è  GPU: Not available (CPU mode)\")\n    \n    print(\"\\n‚úÖ All dependencies verified and ready!\")\n    print(\"\\nüí° Strategy: Installed pytorch-lightning with --no-deps\")\n    print(\"   to prevent pip from corrupting Colab's numpy\")\n    \nexcept ImportError as e:\n    print(f\"‚ùå Import error: {e}\")\n    print(\"\\n‚ö†Ô∏è  If you see numpy corruption errors:\")\n    print(\"   1. Runtime ‚Üí Factory reset runtime\")\n    print(\"   2. Rerun all cells\")\n    print(\"   3. Report issue if persists\")\n    raise"
  },
  {
   "cell_type": "code",
   "source": "# ==============================================================================\n# DOWNLOAD UTILS PACKAGE\n# ==============================================================================\n\nprint(\"üì¶ Downloading test utilities package...\")\n\n# Remove old utils directory if exists\n!rm -rf utils/\n\n# Download complete utils package from GitHub\n!git clone --depth 1 --branch main https://github.com/matt-hans/transformer-builder-colab-templates.git temp_repo 2>/dev/null\n\n# Copy utils directory\n!cp -r temp_repo/utils ./\n\n# Cleanup\n!rm -rf temp_repo\n\n# Verify package structure\nimport sys\nimport os\n\n# Add current directory to Python path\nif './' not in sys.path:\n    sys.path.insert(0, './')\n\n# Verify utils package is importable\ntry:\n    import utils\n    print(f\"‚úÖ Utils package loaded (version {utils.__version__})\")\n    \n    # Verify package structure\n    utils_path = os.path.join(os.getcwd(), 'utils')\n    subdirs = ['adapters', 'tokenization', 'training', 'ui']\n    \n    for subdir in subdirs:\n        subdir_path = os.path.join(utils_path, subdir)\n        if os.path.exists(subdir_path):\n            print(f\"‚úÖ {subdir}/ directory found\")\n        else:\n            print(f\"‚ö†Ô∏è  {subdir}/ directory missing\")\n    \n    # Test importing test functions (backward compatibility)\n    from utils import (\n        test_shape_robustness,\n        test_gradient_flow,\n        test_output_stability,\n        run_all_tier1_tests\n    )\n    print(\"‚úÖ Test functions importable\")\n    \n    print(\"\\n‚úÖ Utils package ready!\")\n    \nexcept ImportError as e:\n    print(f\"‚ùå Failed to import utils package: {e}\")\n    print(\"Falling back to direct file download...\")\n    # Fallback: download test_functions.py directly\n    !wget -q https://raw.githubusercontent.com/matt-hans/transformer-builder-colab-templates/main/utils/test_functions.py",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Custom Model from URL\n",
    "\n",
    "This cell extracts your model code from the URL fragment (passed from Transformer Builder)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Load Custom Model from URL (robust)\nimport os\nimport re\nimport json\nimport urllib.request\nimport urllib.error\nfrom google.colab import output\n\n#@title Load Custom Model from Gist (fallback form)\ngist_id_form = \"\"  #@param {type:\"string\"}\nmodel_name_form = \"CustomTransformer\"  #@param {type:\"string\"}\n\ndef _try_eval_js_for_params():\n    js = r\"\"\"\n(() => {\n  try {\n    // Try top frame (can throw cross-origin), then fall back to referrer/baseURI.\n    let raw = null;\n    try { raw = (window.parent && window.parent.location && window.parent.location.href) || null; } catch (e) {}\n    if (!raw || typeof raw !== 'string' || raw === 'about:blank') {\n      raw = document.referrer || document.baseURI || '';\n    }\n    const url = new URL(raw, window.location.origin);\n    const fragment = url.hash.slice(1); // Remove leading '#'\n    const sp = new URLSearchParams(fragment);\n    return {\n      ok: true,\n      gist_id: sp.get('gist_id'),\n      name: sp.get('name'),\n      href: url.href\n    };\n  } catch (err) {\n    return { ok: false, error: String(err) };\n  }\n})();\n\"\"\"\n    try:\n        return output.eval_js(js)\n    except Exception as e:\n        return {\"ok\": False, \"error\": f\"JS eval failed: {type(e).__name__}: {e}\"}\n\ndef _validate_gist_id(gid: str):\n    # Allow typical gist IDs (hex or alnum). Relax if needed.\n    return bool(re.fullmatch(r\"[A-Za-z0-9]+\", gid or \"\"))\n\ndef _fetch_gist(gist_id: str) -> dict:\n    url = f\"https://api.github.com/gists/{gist_id}\"\n    req = urllib.request.Request(\n        url,\n        headers={\n            \"Accept\": \"application/vnd.github+json\",\n            \"User-Agent\": \"transformer-builder-colab\"\n        },\n    )\n    try:\n        with urllib.request.urlopen(req, timeout=20) as resp:\n            return json.loads(resp.read().decode(\"utf-8\"))\n    except urllib.error.HTTPError as e:\n        detail = f\"HTTP {e.code}\"\n        try:\n            body = e.read().decode(\"utf-8\")\n            if \"rate limit\" in body.lower():\n                detail += \" (GitHub API rate limit; try later or authenticate)\"\n        except Exception:\n            pass\n        raise RuntimeError(f\"GitHub API error for gist {gist_id}: {detail}\") from e\n    except Exception as e:\n        raise RuntimeError(f\"Network error fetching gist {gist_id}: {e}\") from e\n\ndef _write(path: str, text: str):\n    with open(path, \"w\") as f:\n        f.write(text)\n\n# 1) Primary: JS from page URL (parent/referrer)\njs_result = _try_eval_js_for_params()\n\ngist_id = None\nmodel_name = \"CustomTransformer\"\n\nif isinstance(js_result, dict) and js_result.get(\"ok\"):\n    gist_id = (js_result.get(\"gist_id\") or \"\").strip() or None\n    model_name = (js_result.get(\"name\") or model_name).strip() or model_name\nelif isinstance(js_result, dict) and not js_result.get(\"ok\"):\n    print(f\"‚ö†Ô∏è Could not read URL params via JS: {js_result.get('error')}\")\n\n# 2) Override with environment variable if present\nenv_gid = (os.environ.get(\"GIST_ID\") or \"\").strip()\nif env_gid:\n    gist_id = env_gid\n\n# 3) Fallback: user inputs (Colab form)\nif not gist_id and gist_id_form.strip():\n    gist_id = gist_id_form.strip()\nif model_name_form.strip():\n    model_name = model_name_form.strip() or model_name\n\n# 4) Validate gist_id\nif gist_id and not _validate_gist_id(gist_id):\n    print(f\"‚ö†Ô∏è Invalid gist_id format: {gist_id!r}. Ignoring it.\")\n    gist_id = None\n\nparams = {\"name\": model_name}\n\n# 5) Load from gist or fall back to example\nif gist_id:\n    print(f\"üì• Loading model from GitHub Gist: {gist_id} (name={model_name})\")\n    try:\n        gist_data = _fetch_gist(gist_id)\n        files = gist_data.get(\"files\") or {}\n        if \"model.py\" not in files or \"config.json\" not in files:\n            raise RuntimeError(\"Gist missing required files: model.py and/or config.json\")\n\n        model_code = files[\"model.py\"].get(\"content\", \"\")\n        config_json = files[\"config.json\"].get(\"content\", \"\")\n        if not model_code or not config_json:\n            raise RuntimeError(\"Empty content in model.py or config.json\")\n\n        _write(\"custom_transformer.py\", model_code)\n        _write(\"config.json\", config_json)\n\n        print(\"‚úÖ Model code loaded successfully\")\n        print(f\"‚úÖ Gist URL: {gist_data.get('html_url', 'N/A')}\")\n        print(f\"‚úÖ Code size: {len(model_code):,} bytes\")\n        print(f\"‚úÖ Config size: {len(config_json):,} bytes\")\n    except Exception as e:\n        print(f\"‚ùå Failed to load model from Gist: {e}\")\n        print(\"‚ö†Ô∏è Falling back to example model...\")\n        gist_id = None\n\nif not gist_id:\n    print(\"‚ö†Ô∏è No valid gist_id found. Loading example model for demonstration...\")\n    example_code = \"\"\"import torch\nimport torch.nn as nn\n\nclass ExampleTransformer(nn.Module):\n    def __init__(self, vocab_size=50257, d_model=512, nhead=8, num_layers=6):\n        super().__init__()\n        self.embedding = nn.Embedding(vocab_size, d_model)\n        encoder_layer = nn.TransformerEncoderLayer(d_model=d_model, nhead=nhead, batch_first=True)\n        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n        self.output_projection = nn.Linear(d_model, vocab_size)\n    \n    def forward(self, input_ids):\n        x = self.embedding(input_ids)\n        x = self.transformer(x)\n        return self.output_projection(x)\n\"\"\"\n    _write(\"custom_transformer.py\", example_code)\n    _write(\"config.json\", json.dumps({\n        \"vocab_size\": 50257,\n        \"d_model\": 512,\n        \"nhead\": 8,\n        \"num_layers\": 6,\n    }))\n    params[\"name\"] = \"ExampleTransformer\"\n    print(\"‚úÖ Example model loaded\")"
  },
  {
   "cell_type": "markdown",
   "source": "## üìÑ View Loaded Model Code\n\nThis cell displays the Python code that was loaded from your Transformer Builder export. You can review the architecture before running tests.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Display the loaded model code for transparency\nprint(\"=\" * 80)\nprint(\"üìÑ LOADED MODEL CODE (custom_transformer.py)\")\nprint(\"=\" * 80)\nprint()\n\nwith open('custom_transformer.py', 'r') as f:\n    model_code_display = f.read()\n\n# Use syntax highlighting\nfrom IPython.display import Code\ndisplay(Code(model_code_display, language='python'))\n\nprint()\nprint(\"=\" * 80)\nprint(\"üìã MODEL CONFIGURATION (config.json)\")\nprint(\"=\" * 80)\nprint()\n\nwith open('config.json', 'r') as f:\n    config_display = json.load(f)\n\n# Pretty print JSON\nprint(json.dumps(config_display, indent=2))\nprint()\nprint(\"‚úÖ You can now proceed to run the model instantiation and tests below!\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dynamic Dependency Detection\n",
    "\n",
    "Automatically detect and install any custom dependencies your model needs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "# Parse imports from generated code\n",
    "with open('custom_transformer.py', 'r') as f:\n",
    "    source_code = f.read()\n",
    "    tree = ast.parse(source_code)\n",
    "\n",
    "# Extract all imports\n",
    "imports = set()\n",
    "for node in ast.walk(tree):\n",
    "    if isinstance(node, ast.Import):\n",
    "        for alias in node.names:\n",
    "            imports.add(alias.name.split('.')[0])\n",
    "    elif isinstance(node, ast.ImportFrom):\n",
    "        if node.module:\n",
    "            imports.add(node.module.split('.')[0])\n",
    "\n",
    "print(f\"Detected imports: {', '.join(sorted(imports))}\")\n",
    "\n",
    "# Standard library modules (don't need pip install)\n",
    "stdlib_modules = {\n",
    "    'abc', 'collections', 'dataclasses', 'functools', 'json', 'math',\n",
    "    'typing', 'warnings', 'os', 'sys', 're', 'time', 'copy'\n",
    "}\n",
    "\n",
    "# Already installed\n",
    "installed_modules = {\n",
    "    'torch', 'transformers', 'numpy', 'scipy', 'matplotlib',\n",
    "    'pandas', 'seaborn', 'tqdm', 'torchinfo', 'captum', 'optuna'\n",
    "}\n",
    "\n",
    "# Find missing packages\n",
    "missing = imports - stdlib_modules - installed_modules\n",
    "\n",
    "if missing:\n",
    "    print(f\"\\nInstalling additional dependencies: {', '.join(missing)}\")\n",
    "    for package in missing:\n",
    "        try:\n",
    "            subprocess.check_call(\n",
    "                [sys.executable, '-m', 'pip', 'install', '-q', package],\n",
    "                stdout=subprocess.DEVNULL,\n",
    "                stderr=subprocess.DEVNULL\n",
    "            )\n",
    "            print(f\"  ‚úÖ Installed {package}\")\n",
    "        except subprocess.CalledProcessError:\n",
    "            print(f\"  ‚ö†Ô∏è Failed to install {package} (may not be a pip package)\")\n",
    "else:\n",
    "    print(\"\\n‚úÖ All dependencies already installed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import and Instantiate Model\n",
    "\n",
    "Load your custom transformer and prepare for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchinfo import summary\n",
    "\n",
    "# Import the custom model\n",
    "exec(open('custom_transformer.py').read())\n",
    "\n",
    "# Load config\n",
    "with open('config.json') as f:\n",
    "    config_dict = json.load(f)\n",
    "\n",
    "# Find the model class\n",
    "model_class = None\n",
    "for name, obj in list(globals().items()):\n",
    "    if isinstance(obj, type) and issubclass(obj, nn.Module) and obj is not nn.Module:\n",
    "        if name == params['name']:\n",
    "            model_class = obj\n",
    "            break\n",
    "\n",
    "if model_class is None:\n",
    "    # Fallback: find any nn.Module subclass\n",
    "    for name, obj in list(globals().items()):\n",
    "        if isinstance(obj, type) and issubclass(obj, nn.Module) and obj is not nn.Module:\n",
    "            model_class = obj\n",
    "            print(f\"‚ö†Ô∏è Using {name} (expected {params['name']})\")\n",
    "            break\n",
    "\n",
    "if model_class:\n",
    "    # Instantiate model\n",
    "    try:\n",
    "        model = model_class(**config_dict)\n",
    "        model.eval()\n",
    "        \n",
    "        total_params = sum(p.numel() for p in model.parameters())\n",
    "        trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "        \n",
    "        print(f\"‚úÖ Model instantiated: {model_class.__name__}\")\n",
    "        print(f\"‚úÖ Total parameters: {total_params:,}\")\n",
    "        print(f\"‚úÖ Trainable parameters: {trainable_params:,}\")\n",
    "        \n",
    "        # Move to GPU if available\n",
    "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        model = model.to(device)\n",
    "        print(f\"‚úÖ Device: {device}\")\n",
    "        \n",
    "        # Display model summary\n",
    "        print(\"\\n--- Model Summary ---\")\n",
    "        try:\n",
    "            # Create dummy input based on config\n",
    "            vocab_size = config_dict.get('vocab_size', 50257)\n",
    "            dummy_input = torch.randint(0, vocab_size, (1, 32)).to(device)\n",
    "            summary(model, input_data=dummy_input, depth=3)\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Could not generate summary: {e}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Failed to instantiate model: {e}\")\n",
    "        raise\n",
    "else:\n",
    "    raise RuntimeError(f\"Could not find model class '{params['name']}' in generated code\")\n",
    "\n",
    "# Create config object for test functions\n",
    "class ModelConfig:\n",
    "    def __init__(self, **kwargs):\n",
    "        for key, value in kwargs.items():\n",
    "            setattr(self, key, value)\n",
    "\n",
    "config = ModelConfig(**config_dict)\n",
    "print(\"\\n‚úÖ Ready for testing!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": "---\n\n# üîç Tier 1: Critical Validation\n\nThese tests verify your model is mathematically sound and ready for training.\n\n**Estimated time:** ~1 minute\n\n**What's tested:**\n- ‚úÖ Shape validation across edge cases\n- ‚úÖ Gradient flow (detect vanishing/exploding gradients)\n- ‚úÖ Numerical stability (NaN/Inf detection)\n- ‚úÖ Parameter initialization quality\n- ‚úÖ Memory footprint scaling\n- ‚úÖ Inference speed benchmarks",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Import test utilities from the cloned utils package\nfrom utils.test_functions import (\n    test_shape_robustness,\n    test_gradient_flow,\n    test_output_stability,\n    test_parameter_initialization,\n    test_memory_footprint,\n    test_inference_speed\n)\n\nprint(\"‚úÖ Test functions loaded from utils package\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "print(\"=\" * 80)\nprint(\"TIER 1: CRITICAL VALIDATION\")\nprint(\"=\" * 80)\nprint()\n\n# Test 1: Shape Robustness\nprint(\"Test 1/6: Shape Validation\")\nprint(\"-\" * 80)\nshape_results = test_shape_robustness(model, config)\ndisplay(shape_results)\nprint()\n\n# Test 2: Gradient Flow\nprint(\"Test 2/6: Gradient Flow Analysis\")\nprint(\"-\" * 80)\ngrad_results = test_gradient_flow(model, config)\ndisplay(grad_results)\nprint()\n\n# Test 3: Output Stability\nprint(\"Test 3/6: Numerical Stability\")\nprint(\"-\" * 80)\nstability_stats = test_output_stability(model, config, n_samples=100)\nprint()\n\n# Test 4: Parameter Initialization\nprint(\"Test 4/6: Parameter Initialization\")\nprint(\"-\" * 80)\nparam_results = test_parameter_initialization(model)\ndisplay(param_results)\nprint()\n\n# Test 5: Memory Footprint\nprint(\"Test 5/6: Memory Footprint Analysis\")\nprint(\"-\" * 80)\nmemory_results = test_memory_footprint(model, config)\ndisplay(memory_results)\nprint()\n\n# Test 6: Inference Speed\nprint(\"Test 6/6: Inference Speed Benchmark\")\nprint(\"-\" * 80)\nspeed_stats = test_inference_speed(model, config, n_trials=50)\nprint()\n\nprint(\"=\" * 80)\nprint(\"‚úÖ TIER 1 VALIDATION COMPLETE\")\nprint(\"=\" * 80)\nprint()\nprint(\"All critical tests passed! Your model is ready for advanced analysis.\")\nprint()\nprint(\"Next steps:\")\nprint(\"‚Ä¢ Scroll down for Tier 2 (Advanced Analysis)\")\nprint(\"‚Ä¢ Or jump to Tier 3 (Training & Fine-Tuning)\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "---\n\n# üî¨ Tier 2: Advanced Analysis\n\nDeep dive into model behavior with advanced diagnostic tools.\n\n**Estimated time:** ~3-5 minutes\n\n**What's tested:**\n- üéØ **Attention Patterns:** Visualize attention weights, detect collapsed attention, analyze head specialization\n- üîç **Attribution Analysis:** Identify which input tokens contribute most to predictions (using Captum)\n- üõ°Ô∏è **Robustness Testing:** Measure stability under input perturbations and noise\n\n**Note:** These tests are optional but highly recommended for understanding model behavior.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Import Tier 2 test functions\nfrom utils.test_functions import (\n    test_attention_patterns,\n    test_attribution_analysis,\n    test_robustness\n)\n\nprint(\"=\" * 80)\nprint(\"TIER 2: ADVANCED ANALYSIS\")\nprint(\"=\" * 80)\nprint()\n\n# Test 1: Attention Patterns\nprint(\"Test 1/3: Attention Pattern Analysis\")\nprint(\"-\" * 80)\ntry:\n    attention_results = test_attention_patterns(model, config)\n    if attention_results is not None:\n        display(attention_results)\n    print(\"‚úÖ Attention analysis complete\")\nexcept Exception as e:\n    print(f\"‚ö†Ô∏è Attention analysis skipped: {e}\")\nprint()\n\n# Test 2: Attribution Analysis\nprint(\"Test 2/3: Input Attribution Analysis\")\nprint(\"-\" * 80)\ntry:\n    attribution_results = test_attribution_analysis(model, config)\n    if attribution_results is not None:\n        print(\"\\nTop Contributing Tokens:\")\n        for token, score in attribution_results.get(\"top_tokens\", []):\n            print(f\"  {token:20s}: {score:+.4f}\")\n    print(\"‚úÖ Attribution analysis complete\")\nexcept Exception as e:\n    print(f\"‚ö†Ô∏è Attribution analysis skipped: {e}\")\nprint()\n\n# Test 3: Robustness Testing\nprint(\"Test 3/3: Robustness Under Noise\")\nprint(\"-\" * 80)\ntry:\n    robustness_results = test_robustness(model, config, n_samples=20)\n    if robustness_results is not None:\n        display(robustness_results)\n    print(\"‚úÖ Robustness analysis complete\")\nexcept Exception as e:\n    print(f\"‚ö†Ô∏è Robustness analysis skipped: {e}\")\nprint()\n\nprint(\"=\" * 80)\nprint(\"‚úÖ TIER 2 ANALYSIS COMPLETE\")\nprint(\"=\" * 80)\nprint()\nprint(\"Next: Scroll down for Tier 3 (Training & Fine-Tuning)\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "---\n\n# üöÄ Tier 3: Training & Production Utilities\n\nAdvanced utilities for fine-tuning, hyperparameter optimization, and production benchmarking.\n\n**Estimated time:** ~10-20 minutes (depends on training iterations)\n\n**What's included:**\n- üéì **Fine-Tuning:** Basic training loop with loss tracking and gradient monitoring\n- üîß **Hyperparameter Search:** Automated optimization using Optuna (learning rate, batch size, warmup)\n- üìä **Benchmark Comparison:** Compare your model against production baselines (distilgpt2, bert-base, etc.)\n\n**Note:** These are compute-intensive operations. Consider using GPU runtime for faster execution.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Import Tier 3 training utilities\nfrom utils.test_functions import (\n    test_fine_tuning,\n    test_hyperparameter_search,\n    test_benchmark_comparison\n)\n\nprint(\"=\" * 80)\nprint(\"TIER 3: TRAINING & PRODUCTION UTILITIES\")\nprint(\"=\" * 80)\nprint()\n\n# Test 1: Fine-Tuning\nprint(\"Test 1/3: Fine-Tuning Demo\")\nprint(\"-\" * 80)\nprint(\"Running 3 epochs of fine-tuning with synthetic data...\")\ntry:\n    fine_tune_results = test_fine_tuning(\n        model, \n        config, \n        num_epochs=3,\n        batch_size=2,\n        learning_rate=5e-5\n    )\n    print(f\"\\nFinal Loss: {fine_tune_results['final_loss']:.4f}\")\n    print(f\"Best Loss: {fine_tune_results['best_loss']:.4f}\")\n    print(\"‚úÖ Fine-tuning complete\")\nexcept Exception as e:\n    print(f\"‚ö†Ô∏è Fine-tuning skipped: {e}\")\nprint()\n\n# Test 2: Hyperparameter Search (OPTIONAL - Comment out to skip)\nprint(\"Test 2/3: Hyperparameter Optimization\")\nprint(\"-\" * 80)\nprint(\"‚ö†Ô∏è Skipping hyperparameter search (compute-intensive)\")\nprint(\"To enable: uncomment the code block below\")\nprint()\n# Uncomment to run:\n# try:\n#     hp_results = test_hyperparameter_search(\n#         model,\n#         config,\n#         n_trials=5,\n#         epochs_per_trial=2\n#     )\n#     print(\"\\nBest Parameters:\")\n#     for param, value in hp_results['best_params'].items():\n#         print(f\"  {param}: {value}\")\n#     print(\"‚úÖ Hyperparameter search complete\")\n# except Exception as e:\n#     print(f\"‚ö†Ô∏è Hyperparameter search failed: {e}\")\n\n# Test 3: Benchmark Comparison\nprint(\"Test 3/3: Benchmark Against Baseline\")\nprint(\"-\" * 80)\nprint(\"Comparing against distilgpt2 baseline...\")\ntry:\n    benchmark_results = test_benchmark_comparison(\n        model,\n        config,\n        baseline_model=\"distilgpt2\",\n        n_samples=10\n    )\n    if benchmark_results is not None:\n        display(benchmark_results)\n    print(\"‚úÖ Benchmark comparison complete\")\nexcept Exception as e:\n    print(f\"‚ö†Ô∏è Benchmark comparison skipped: {e}\")\nprint()\n\nprint(\"=\" * 80)\nprint(\"‚úÖ TIER 3 TRAINING UTILITIES COMPLETE\")\nprint(\"=\" * 80)\nprint()\nprint(\"üéâ All testing tiers complete! Your model is production-ready.\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}