{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "error-handling-setup"
   },
   "outputs": [],
   "source": "# ==============================================================================\n# ERROR HANDLING SETUP ‚Äî Full Tracebacks and Formatting\n# ==============================================================================\nimport sys, traceback\nsys.tracebacklimit = 50  # show up to 50 frames\n\ndef format_exception(e: Exception, context_lines: int = 5) -> str:\n    \"\"\"Format exception with full traceback.\n\n    Args:\n        e: Exception instance\n        context_lines: Unused placeholder for future code context.\n    Returns: String with full traceback.\n    \"\"\"\n    tb_lines = traceback.format_exception(type(e), e, e.__traceback__)\n    return ''.join(tb_lines)\n\n# Install IPython custom exception handler to avoid truncation\ntry:\n    from IPython import get_ipython\n    ip = get_ipython()\n    if ip is not None:\n        def _custom_exc(shell, etype, evalue, tb, tb_offset=None):\n            print('‚ùå Exception occurred')\n            print('=' * 60)\n            print(''.join(traceback.format_exception(etype, evalue, tb)))\n            print('=' * 60)\n            # Return None to let IPython handle the exception normally after printing\n            return None\n        ip.set_custom_exc((Exception,), _custom_exc)\nexcept Exception:\n    pass\n\n# ==============================================================================\n# NETWORK RETRY MONKEY-PATCH ‚Äî urllib.urlopen with retries (GitHub/HF)\n# ==============================================================================\ntry:\n    import urllib.request as _ur, urllib.error as _ue, time as _t, random as _r\n    _orig_urlopen = _ur.urlopen\n    def _retrying_urlopen(req, timeout=20, max_retries=5, backoff=1.0):\n        attempt = 0\n        while True:\n            try:\n                return _orig_urlopen(req, timeout=timeout)\n            except _ue.HTTPError as e:\n                code = getattr(e, 'code', None)\n                if code == 404:\n                    raise\n                if code in (429, 500, 502, 503, 504, 403):\n                    attempt += 1\n                    if attempt > max_retries:\n                        raise\n                    ra = getattr(e, 'headers', {}).get('Retry-After') if hasattr(e, 'headers') else None\n                    try:\n                        ra_val = float(ra) if ra is not None else None\n                    except Exception:\n                        ra_val = None\n                    sleep_for = ra_val if ra_val is not None else backoff * (2 ** (attempt - 1))\n                    sleep_for += _r.random() * 0.25 * sleep_for\n                    print(f\"‚è≥ Network retry {attempt}/{max_retries} in {sleep_for:.1f}s (HTTP {code})\")\n                    _t.sleep(min(sleep_for, 30.0))\n                    continue\n                raise\n            except Exception:\n                attempt += 1\n                if attempt > max_retries:\n                    raise\n                sleep_for = backoff * (2 ** (attempt - 1))\n                sleep_for += _r.random() * 0.25 * sleep_for\n                print(f\"‚è≥ Network retry {attempt}/{max_retries} in {sleep_for:.1f}s\")\n                _t.sleep(min(sleep_for, 30.0))\n    def urlopen_with_retry(req, timeout=20):\n        return _retrying_urlopen(req, timeout=timeout)\n    _ur.urlopen = urlopen_with_retry\nexcept Exception:\n    pass"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "troubleshooting"
   },
   "source": "---\n\n### üõ†Ô∏è Troubleshooting\n\n- This notebook shows full Python tracebacks (up to 50 frames).\n- When an error occurs, you'll see the complete stack to the root cause.\n- If a model load fails, check ImportError messages and missing packages.\n\nTip: You can also call `print(format_exception(e))` inside your own try/except blocks to display a full traceback."
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# üß™ Transformer Builder - Advanced Testing Lab\n\n**Welcome! This notebook tests your custom transformer architecture.**\n\n---\n\n## üöÄ **Quick Start (3 Steps)**\n\n### **STEP 1:** Paste Your Gist ID\n‚Üì Scroll down to Cell 3 and paste the Gist ID you received from Transformer Builder\n\n### **STEP 2:** Run All Cells  \nClick **Runtime ‚Üí Run all** (or run cells one-by-one)\n\n### **STEP 3:** Review Test Results\nYour model will be validated through 3 testing tiers\n\n---\n\n## üìã **What's Included:**\n\n- ‚úÖ **Tier 1:** Critical validation (shape, gradients, numerical stability)\n- üî¨ **Tier 2:** Advanced analysis (attention patterns, robustness, profiling)\n- üöÄ **Tier 3:** Training utilities (fine-tuning, hyperparameter sweeps, benchmarks)\n\n---\n\n## ‚ö†Ô∏è **First Time Setup:**\n\nIf this is your first time OR you're continuing from a previous session:\n\n1. **Runtime** ‚Üí **Restart runtime** (takes 5 seconds)\n2. **Edit** ‚Üí **Clear all outputs** (optional, cleans up UI)\n3. **Scroll down to Cell 3** ‚Üí Paste your Gist ID\n4. **Runtime** ‚Üí **Run all**\n\nThis ensures a clean environment and prevents dependency conflicts.\n\n---\n\n**Source:** Generated from [Transformer Builder](https://transformer-builder.com)"
  },
  {
   "cell_type": "markdown",
   "source": "# üß™ Transformer Builder - Advanced Testing Lab\n\nWelcome! This notebook provides comprehensive testing and training capabilities for your custom transformer architecture.\n\n**What's included:**\n- ‚úÖ **Tier 1:** Critical validation (shape, gradients, numerical stability)\n- üî¨ **Tier 2:** Advanced analysis (attention patterns, robustness, profiling)\n- üöÄ **Tier 3:** Training utilities (fine-tuning, hyperparameter sweeps, benchmarks)\n\n**Quick Start:**\n1. Click \"Run all\" (Runtime ‚Üí Run all)\n2. Review Tier 1 results (should complete in ~1 minute)\n3. Explore Tier 2/3 sections as needed\n\n**Source:** Generated from [Transformer Builder](https://transformer-builder.com)\n\n---",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n\n## üìã **STEP 1: Paste Your Gist ID**\n\nWhen you exported from **Transformer Builder**, you received a **Gist ID**.\n\n**Paste it in the cell below and run it.**\n\nIf you don't have a Gist ID yet, go back to Transformer Builder and click **\"Export to Colab\"**."
  },
  {
   "cell_type": "code",
   "source": "# ==============================================================================\n# GIST ID CONFIGURATION - Auto-detect from URL or manual input\n# ==============================================================================\n\n#@title üì• **Gist ID Configuration** { display-mode: \"form\" }\n\nimport os\nimport re\nimport time\n\n# ==============================================================================\n# Step 1: Try to extract gist_id from URL\n# ==============================================================================\n\ngist_id_from_url = ''\n\n# JavaScript that extracts gist_id and returns it synchronously\njs_extraction_code = \"\"\"\n(function() {\n    let gist_id = '';\n    \n    try {\n        // Method 1: Check URL query parameters\n        const url = new URL(window.location.href);\n        gist_id = url.searchParams.get('gist_id') || '';\n        \n        // Method 2: Try parent window\n        if (!gist_id) {\n            try {\n                const parentUrl = new URL(window.parent.location.href);\n                gist_id = parentUrl.searchParams.get('gist_id') || '';\n            } catch (e) {}\n        }\n        \n        // Method 3: Check document.referrer\n        if (!gist_id && document.referrer) {\n            try {\n                const refUrl = new URL(document.referrer);\n                gist_id = refUrl.searchParams.get('gist_id') || '';\n            } catch (e) {}\n        }\n        \n        // Method 4: Check hash params\n        if (!gist_id) {\n            const hash = window.location.hash || '';\n            if (hash.includes('gist_id')) {\n                const hashParams = new URLSearchParams(hash.substring(1));\n                gist_id = hashParams.get('gist_id') || '';\n            }\n        }\n    } catch (e) {\n        console.log('URL extraction error:', e.message);\n    }\n    \n    return gist_id || '';\n})();\n\"\"\"\n\n# Try extraction with Colab's output.eval_js (synchronous)\ntry:\n    from google.colab import output\n    \n    # Multiple attempts with delays (Colab can be slow to initialize)\n    for attempt in range(3):\n        try:\n            result = output.eval_js(js_extraction_code)\n            if result and isinstance(result, str) and result.strip():\n                gist_id_from_url = result.strip()\n                print(f\"‚úÖ Auto-detected Gist ID from URL: {gist_id_from_url}\")\n                break\n        except Exception as e:\n            if attempt < 2:\n                time.sleep(0.3)  # Brief delay between attempts\n            \nexcept ImportError:\n    print(\"‚ÑπÔ∏è  Not running in Google Colab - URL auto-detection skipped\")\nexcept Exception as e:\n    print(f\"‚ÑπÔ∏è  URL auto-detection unavailable: {type(e).__name__}\")\n\n# ==============================================================================\n# Step 2: Manual input (primary method if auto-detect fails)\n# ==============================================================================\n\n#@markdown ---\n#@markdown **Enter Your Gist ID:**\nGIST_ID_MANUAL = \"\"  #@param {type:\"string\"}\n\n#@markdown ---\n#@markdown **How to get your Gist ID:**\n#@markdown 1. Go to Transformer Builder\n#@markdown 2. Click \"Export to Colab\"\n#@markdown 3. Copy the Gist ID shown in the modal\n#@markdown 4. Paste it in the field above\n\n# ==============================================================================\n# Step 3: Environment variable fallback\n# ==============================================================================\n\ngist_id_env = os.getenv('GIST_ID', '')\n\n# ==============================================================================\n# Step 4: Determine final value\n# ==============================================================================\n\nGIST_ID = gist_id_from_url or GIST_ID_MANUAL.strip() or gist_id_env\n\n# ==============================================================================\n# Status display\n# ==============================================================================\n\nprint()\nprint(\"=\" * 70)\n\nif not GIST_ID:\n    print(\"‚è≥ GIST ID NEEDED\")\n    print(\"=\" * 70)\n    print()\n    print(\"URL auto-detection did not find a Gist ID.\")\n    print()\n    print(\"üìù TO CONTINUE:\")\n    print(\"   1. Enter your Gist ID in the 'GIST_ID_MANUAL' field above\")\n    print(\"   2. Re-run this cell (click the play button or Ctrl+Enter)\")\n    print()\n    print(\"Don't have a Gist ID?\")\n    print(\"   ‚Üí Go to Transformer Builder ‚Üí Click 'Export to Colab'\")\n    print()\n    # Don't raise error - let user fill in the field and re-run\n    GIST_ID = None  # Explicitly set to None for downstream checks\n\nelse:\n    # Validate format\n    if not re.fullmatch(r\"[A-Za-z0-9]+\", GIST_ID):\n        print(\"‚ö†Ô∏è  INVALID GIST ID FORMAT\")\n        print(\"=\" * 70)\n        print()\n        print(f\"The value entered: {GIST_ID!r}\")\n        print(\"Gist IDs should be alphanumeric (e.g., 'abc123def456')\")\n        raise ValueError(\"Invalid Gist ID format - please check and re-enter\")\n    \n    # Show success\n    if gist_id_from_url:\n        source = \"URL (auto-detected)\"\n    elif GIST_ID_MANUAL.strip():\n        source = \"Manual input\"\n    else:\n        source = \"Environment variable\"\n    \n    print(\"‚úÖ GIST ID CONFIGURED\")\n    print(\"=\" * 70)\n    print()\n    print(f\"Gist ID: {GIST_ID}\")\n    print(f\"Source:  {source}\")\n    print()\n    print(\"Ready to load your model! Continue to the next cells.\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================",
    "# DEPENDENCY VERIFICATION - v3.4.0 (Zero Installation Strategy)",
    "# ==============================================================================",
    "",
    "print(\"=\" * 70)",
    "print(\"üì¶ DEPENDENCY VERIFICATION\")",
    "print(\"=\" * 70)",
    "print()",
    "print(\"Strategy: Use Colab pre-installed packages (no pip install)\")",
    "print(\"This prevents NumPy corruption caused by package reinstallation.\")",
    "print()",
    "",
    "# ==============================================================================",
    "# VERIFY CORE DEPENDENCIES (All pre-installed in Google Colab 2025)",
    "# ==============================================================================",
    "",
    "required = {",
    "    'torch': '2.6+',",
    "    'numpy': '2.3+',",
    "    'pandas': '1.5+',",
    "    'matplotlib': '3.7+',",
    "    'seaborn': '0.12+',",
    "}",
    "",
    "print(\"Checking pre-installed packages...\")",
    "print()",
    "",
    "all_good = True",
    "for package, min_version in required.items():",
    "    try:",
    "        module = __import__(package)",
    "        version = getattr(module, '__version__', 'unknown')",
    "        print(f\"  ‚úÖ {package:15s} {version:10s} (required: {min_version})\")",
    "    except ImportError:",
    "        print(f\"  ‚ùå {package:15s} NOT FOUND (should be pre-installed!)\")",
    "        all_good = False",
    "",
    "print()",
    "",
    "# ==============================================================================",
    "# NUMPY INTEGRITY CHECK",
    "# ==============================================================================",
    "",
    "print(\"Checking NumPy integrity...\")",
    "try:",
    "    from numpy._core.umath import _center",
    "    print(\"  ‚úÖ NumPy C extensions intact\")",
    "except ImportError as e:",
    "    print(\"  ‚ùå NumPy corrupted!\")",
    "    print()",
    "    print(\"=\" * 70)",
    "    print(\"ERROR: NumPy corruption detected\")",
    "    print(\"=\" * 70)",
    "    print()",
    "    print(\"This usually happens if you:\")",
    "    print(\"  1. Ran this notebook before without restarting runtime\")",
    "    print(\"  2. Manually installed packages that corrupted NumPy\")",
    "    print()",
    "    print(\"FIX: Runtime ‚Üí Restart runtime, then run all cells again\")",
    "    print()",
    "    raise ImportError(\"NumPy corrupted - please restart runtime\") from e",
    "",
    "print()",
    "",
    "if not all_good:",
    "    print(\"=\" * 70)",
    "    print(\"ERROR: Missing required packages\")",
    "    print(\"=\" * 70)",
    "    print()",
    "    print(\"This shouldn't happen in Google Colab.\")",
    "    print(\"Are you running this notebook in a different environment?\")",
    "    print()",
    "    raise RuntimeError(\"Required packages not found\")",
    "",
    "print(\"=\" * 70)",
    "print(\"‚úÖ ALL DEPENDENCIES VERIFIED\")",
    "print(\"=\" * 70)",
    "print()",
    "print(\"‚úÖ No installation needed - using Colab pre-installed packages\")",
    "print(\"‚úÖ NumPy corruption risk: ELIMINATED\")",
    "print()",
    "print(\"Note: Advanced features (Tier 2/3) will install packages on-demand\")",
    "print()",
    ""
   ]
  },
  {
   "cell_type": "code",
   "source": "# ==============================================================================\n# DOWNLOAD UTILS PACKAGE\n# ==============================================================================\n\nprint(\"üì¶ Downloading test utilities package...\")\n\n# Remove old utils directory if exists\n!rm -rf utils/\n\n# Download complete utils package from GitHub\n!git clone --depth 1 --branch main https://github.com/matt-hans/transformer-builder-colab-templates.git temp_repo 2>/dev/null\n\n# Copy utils directory\n!cp -r temp_repo/utils ./\n\n# Cleanup\n!rm -rf temp_repo\n\n# Verify package structure\nimport sys\nimport os\n\n# Add current directory to Python path\nif './' not in sys.path:\n    sys.path.insert(0, './')\n\n# Verify utils package is importable\ntry:\n    import utils\n    print(f\"‚úÖ Utils package loaded (version {utils.__version__})\")\n    \n    # Verify package structure\n    utils_path = os.path.join(os.getcwd(), 'utils')\n    subdirs = ['adapters', 'tokenization', 'training', 'ui']\n    \n    for subdir in subdirs:\n        subdir_path = os.path.join(utils_path, subdir)\n        if os.path.exists(subdir_path):\n            print(f\"‚úÖ {subdir}/ directory found\")\n        else:\n            print(f\"‚ö†Ô∏è  {subdir}/ directory missing\")\n    \n    # Test importing test functions (backward compatibility)\n    from utils import (\n        test_shape_robustness,\n        test_gradient_flow,\n        test_output_stability,\n        run_all_tier1_tests\n    )\n    print(\"‚úÖ Test functions importable\")\n    \n    print(\"\\n‚úÖ Utils package ready!\")\n    \nexcept ImportError as e:\n    print(f\"‚ùå Failed to import utils package: {e}\")\n    print(\"Falling back to direct file download...\")\n    # Fallback: download test_functions.py directly\n    !wget -q https://raw.githubusercontent.com/matt-hans/transformer-builder-colab-templates/main/utils/test_functions.py",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "# ==============================================================================\n# LOAD CUSTOM MODEL FROM GIST\n# ==============================================================================\n\nimport os, re, json, urllib.request, urllib.error\n\nprint(\"=\" * 70)\nprint(\"MODEL LOADING\")\nprint(\"=\" * 70)\nprint()\n\n# ==============================================================================\n# VERIFY GIST ID WAS PROVIDED\n# ==============================================================================\n\nif 'GIST_ID' not in globals() or not GIST_ID:\n    print(\"‚ùå NO GIST ID CONFIGURED\")\n    print()\n    print(\"=\" * 70)\n    print(\"üîô ACTION REQUIRED\")\n    print(\"=\" * 70)\n    print()\n    print(\"Please go back and configure your Gist ID:\")\n    print()\n    print(\"  1. Scroll up to the 'üì• Gist ID Configuration' cell\")\n    print(\"  2. Enter your Gist ID in the 'GIST_ID_MANUAL' field\")\n    print(\"  3. Run that cell\")\n    print(\"  4. Then run this cell again\")\n    print()\n    print(\"If you don't have a Gist ID:\")\n    print(\"  ‚Üí Go to Transformer Builder ‚Üí Click 'Export to Colab'\")\n    print()\n    raise ValueError(\"Gist ID required - see instructions above\")\n\ngist_id = GIST_ID\nmodel_name = \"Model\"  # Default, will be overridden from config\n\nprint(f\"üì• Loading model from GitHub Gist: {gist_id}\")\nprint()\n\n# ==============================================================================\n# FETCH GIST AND LOAD MODEL FILES\n# ==============================================================================\n\ndef _fetch_gist(gid: str) -> dict:\n    \"\"\"Fetch Gist data from GitHub API.\"\"\"\n    url = f\"https://api.github.com/gists/{gid}\"\n    req = urllib.request.Request(url, headers={\n        \"Accept\": \"application/vnd.github+json\",\n        \"User-Agent\": \"transformer-builder-colab\"\n    })\n    try:\n        with urllib.request.urlopen(req, timeout=20) as resp:\n            return json.loads(resp.read().decode(\"utf-8\"))\n    except urllib.error.HTTPError as e:\n        detail = f\"HTTP {e.code}\"\n        try:\n            body = e.read().decode(\"utf-8\")\n            if \"rate limit\" in body.lower():\n                detail += \" - GitHub API rate limit (try again in an hour)\"\n            elif e.code == 404:\n                detail += \" - Gist not found (check your Gist ID)\"\n        except:\n            pass\n        raise RuntimeError(f\"GitHub API error: {detail}\") from e\n    except Exception as e:\n        raise RuntimeError(f\"Network error: {e}\") from e\n\ndef _write(path: str, text: str):\n    \"\"\"Write text to file.\"\"\"\n    with open(path, \"w\") as f:\n        f.write(text)\n\n# Fetch Gist\ntry:\n    gist_data = _fetch_gist(gist_id)\n    files = gist_data.get(\"files\") or {}\n    \n    # Check for required files\n    if \"model.py\" not in files:\n        raise RuntimeError(\"Gist is missing 'model.py' - please re-export from Transformer Builder\")\n    if \"config.json\" not in files:\n        raise RuntimeError(\"Gist is missing 'config.json' - please re-export from Transformer Builder\")\n    \n    model_code = files[\"model.py\"].get(\"content\", \"\")\n    config_json = files[\"config.json\"].get(\"content\", \"\")\n    \n    if not model_code or not config_json:\n        raise RuntimeError(\"Empty content in model.py or config.json\")\n    \n    # Write to files\n    _write(\"custom_transformer.py\", model_code)\n    _write(\"config.json\", config_json)\n    \n    print(f\"‚úÖ Model loaded successfully!\")\n    print(f\"‚úÖ Gist URL: {gist_data.get('html_url', 'N/A')}\")\n    print(f\"‚úÖ Model code: {len(model_code):,} bytes\")\n    print(f\"‚úÖ Config: {len(config_json):,} bytes\")\n    print()\n    \n    # Parse model name from config if available\n    try:\n        config_dict = json.loads(config_json)\n        if 'model_name' in config_dict:\n            model_name = config_dict['model_name']\n            print(f\"‚úÖ Model name: {model_name}\")\n            print()\n    except:\n        pass\n\nexcept Exception as e:\n    print(f\"‚ùå Failed to load model from Gist!\")\n    print()\n    print(f\"Error: {e}\")\n    print()\n    print(\"=\" * 70)\n    print(\"TROUBLESHOOTING\")\n    print(\"=\" * 70)\n    print()\n    print(\"Common issues:\")\n    print(f\"  1. Verify Gist ID is correct: {gist_id}\")\n    print(\"  2. Ensure you exported from Transformer Builder successfully\")\n    print(\"  3. Check you're not hitting GitHub rate limit (60 requests/hour)\")\n    print(\"  4. Try re-exporting from Transformer Builder\")\n    print()\n    print(\"Direct link to check:\")\n    print(f\"  ‚Üí https://gist.github.com/{gist_id}\")\n    print()\n    raise\n\nprint(\"=\" * 70)\nprint(\"‚úÖ MODEL LOADING COMPLETE\")\nprint(\"=\" * 70)\nprint()\nprint(\"Next: Continue to model instantiation and testing below!\")\nprint()\n\n# Store model_name for next cell\nparams = {\"name\": model_name}",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# ==============================================================================\n",
    "# DYNAMIC TRAINING LINK - Pass Gist ID to training.ipynb automatically\n",
    "# ==============================================================================\n",
    "\n",
    "from IPython.display import display, Javascript\n",
    "\n",
    "# Get current gist_id and model_name from Python variables\n",
    "# Note: model_name is defined earlier in cell 8 after loading config\n",
    "gist_id_for_js = GIST_ID\n",
    "model_name_for_js = model_name if 'model_name' in dir() else 'Model'\n",
    "\n",
    "js_code = f\"\"\"\n",
    "(function() {{\n",
    "    // Find all Colab badge links pointing to training.ipynb\n",
    "    const links = document.querySelectorAll('a[href*=\"training.ipynb\"]');\n",
    "    \n",
    "    links.forEach(link => {{\n",
    "        const baseUrl = link.href.split('#')[0];  // Remove existing hash if any\n",
    "        const gistId = '{gist_id_for_js}';\n",
    "        const modelName = '{model_name_for_js}';\n",
    "        \n",
    "        if (gistId && gistId.trim()) {{\n",
    "            // Append hash parameters for training.ipynb to read\n",
    "            link.href = baseUrl + '#gist_id=' + encodeURIComponent(gistId) + '&name=' + encodeURIComponent(modelName);\n",
    "            console.log('‚úÖ Updated training link:', link.href);\n",
    "        }}\n",
    "    }});\n",
    "}})()\n",
    "\"\"\"\n",
    "\n",
    "display(Javascript(js_code))\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"‚úÖ TRAINING LINK UPDATED\")\n",
    "print(\"=\" * 70)\n",
    "print()\n",
    "print(f\"Gist ID: {gist_id_for_js}\")\n",
    "print(f\"Model Name: {model_name_for_js}\")\n",
    "print()\n",
    "print(\"The 'Open Training Notebook' button will now automatically pass\")\n",
    "print(\"your Gist ID to training.ipynb - no need to enter it again!\")\n",
    "print()\n",
    "print(\"üí° Scroll down to the 'Tier 3' section and click the Colab badge\")\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## üìÑ View Loaded Model Code\n\nThis cell displays the Python code that was loaded from your Transformer Builder export. You can review the architecture before running tests.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Display the loaded model code for transparency\nprint(\"=\" * 80)\nprint(\"üìÑ LOADED MODEL CODE (custom_transformer.py)\")\nprint(\"=\" * 80)\nprint()\n\nwith open('custom_transformer.py', 'r') as f:\n    model_code_display = f.read()\n\n# Use syntax highlighting\nfrom IPython.display import Code\ndisplay(Code(model_code_display, language='python'))\n\nprint()\nprint(\"=\" * 80)\nprint(\"üìã MODEL CONFIGURATION (config.json)\")\nprint(\"=\" * 80)\nprint()\n\nwith open('config.json', 'r') as f:\n    config_display = json.load(f)\n\n# Pretty print JSON\nprint(json.dumps(config_display, indent=2))\nprint()\nprint(\"‚úÖ You can now proceed to run the model instantiation and tests below!\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import and Instantiate Model\n",
    "\n",
    "Load your custom transformer and prepare for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import inspect\n",
    "\n",
    "# Import the custom model\n",
    "exec(open('custom_transformer.py').read())\n",
    "\n",
    "# Load config\n",
    "with open('config.json') as f:\n",
    "    config_dict = json.load(f)\n",
    "\n",
    "# Find the model class\n",
    "model_class = None\n",
    "for name, obj in list(globals().items()):\n",
    "    if isinstance(obj, type) and issubclass(obj, nn.Module) and obj is not nn.Module:\n",
    "        if name == params['name']:\n",
    "            model_class = obj\n",
    "            break\n",
    "\n",
    "if model_class is None:\n",
    "    # Fallback: find any nn.Module subclass\n",
    "    for name, obj in list(globals().items()):\n",
    "        if isinstance(obj, type) and issubclass(obj, nn.Module) and obj is not nn.Module:\n",
    "            model_class = obj\n",
    "            print(f\"‚ö†Ô∏è Using {name} (expected {params['name']})\")\n",
    "            break\n",
    "\n",
    "if model_class:\n",
    "    # Instantiate model - try both parameterless and parameterized approaches\n",
    "    try:\n",
    "        # Check if __init__ accepts parameters (besides self)\n",
    "        sig = inspect.signature(model_class.__init__)\n",
    "        params_list = [p for p in sig.parameters.values() if p.name != 'self']\n",
    "        \n",
    "        if len(params_list) == 0:\n",
    "            # Parameterless constructor (Transformer Builder models)\n",
    "            print(\"‚ÑπÔ∏è  Model has parameterless constructor (Transformer Builder export)\")\n",
    "            model = model_class()\n",
    "        else:\n",
    "            # Parameterized constructor (traditional models)\n",
    "            print(f\"‚ÑπÔ∏è  Model accepts {len(params_list)} parameter(s)\")\n",
    "            model = model_class(**config_dict)\n",
    "        \n",
    "        model.eval()\n",
    "        \n",
    "        total_params = sum(p.numel() for p in model.parameters())\n",
    "        trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "        \n",
    "        print(f\"‚úÖ Model instantiated: {model_class.__name__}\")\n",
    "        print(f\"‚úÖ Total parameters: {total_params:,}\")\n",
    "        print(f\"‚úÖ Trainable parameters: {trainable_params:,}\")\n",
    "        \n",
    "        # Move to GPU if available\n",
    "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        model = model.to(device)\n",
    "        print(f\"‚úÖ Device: {device}\")\n",
    "        \n",
    "        # Display model summary (using native torch instead of torchinfo)\n",
    "        print()\n",
    "        print(\"=\" * 70)\n",
    "        print(\"MODEL SUMMARY\")\n",
    "        print(\"=\" * 70)\n",
    "        print()\n",
    "        print(model)\n",
    "        print()\n",
    "        print(\"=\" * 70)\n",
    "        print(f\"Total parameters:      {total_params:,}\")\n",
    "        print(f\"Trainable parameters:  {trainable_params:,}\")\n",
    "        print(f\"Non-trainable params:  {total_params - trainable_params:,}\")\n",
    "        \n",
    "        # Calculate model size\n",
    "        param_size = sum(p.numel() * p.element_size() for p in model.parameters())\n",
    "        buffer_size = sum(b.numel() * b.element_size() for b in model.buffers())\n",
    "        size_mb = (param_size + buffer_size) / 1024**2\n",
    "        print(f\"Model size:            {size_mb:.2f} MB\")\n",
    "        print(\"=\" * 70)\n",
    "        print()\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Failed to instantiate model: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        raise\n",
    "else:\n",
    "    raise RuntimeError(f\"Could not find model class '{params['name']}' in generated code\")\n",
    "\n",
    "# Create config object for test functions (with proper vocab_size)\n",
    "class ModelConfig:\n",
    "    def __init__(self, **kwargs):\n",
    "        # Set defaults\n",
    "        self.vocab_size = 50257\n",
    "        self.max_seq_len = 512\n",
    "        self.max_batch_size = 8\n",
    "        \n",
    "        # If nodes-based config, extract common params\n",
    "        if 'nodes' in kwargs:\n",
    "            for node in kwargs['nodes']:\n",
    "                node_params = node.get('params', {})\n",
    "                if 'vocab_size' in node_params:\n",
    "                    self.vocab_size = node_params['vocab_size']\n",
    "                if 'max_seq_len' in node_params or 'seq_length' in node_params:\n",
    "                    self.max_seq_len = node_params.get('max_seq_len') or node_params.get('seq_length', 512)\n",
    "        \n",
    "        # Override with flat params if present\n",
    "        for key, value in kwargs.items():\n",
    "            if key not in ['nodes', 'version', 'model_name']:\n",
    "                setattr(self, key, value)\n",
    "\n",
    "config = ModelConfig(**config_dict)\n",
    "print(f\"‚úÖ Config prepared (vocab_size={config.vocab_size}, max_seq_len={config.max_seq_len})\")\n",
    "print(\"‚úÖ Ready for testing!\")\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "source": "---\n\n# üîç Tier 1: Critical Validation\n\nThese tests verify your model is mathematically sound and ready for training.\n\n**Estimated time:** ~1 minute\n\n**What's tested:**\n- ‚úÖ Shape validation across edge cases\n- ‚úÖ Gradient flow (detect vanishing/exploding gradients)\n- ‚úÖ Numerical stability (NaN/Inf detection)\n- ‚úÖ Parameter initialization quality\n- ‚úÖ Memory footprint scaling\n- ‚úÖ Inference speed benchmarks",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Import test utilities from the cloned utils package\nfrom utils.test_functions import (\n    test_shape_robustness,\n    test_gradient_flow,\n    test_output_stability,\n    test_parameter_initialization,\n    test_memory_footprint,\n    test_inference_speed\n)\n\nprint(\"‚úÖ Test functions loaded from utils package\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "print(\"=\" * 80)\nprint(\"TIER 1: CRITICAL VALIDATION\")\nprint(\"=\" * 80)\nprint()\n\n# Test 1: Shape Robustness\nprint(\"Test 1/6: Shape Validation\")\nprint(\"-\" * 80)\nshape_results = test_shape_robustness(model, config)\ndisplay(shape_results)\nprint()\n\n# Test 2: Gradient Flow\nprint(\"Test 2/6: Gradient Flow Analysis\")\nprint(\"-\" * 80)\ngrad_results = test_gradient_flow(model, config)\ndisplay(grad_results)\nprint()\n\n# Test 3: Output Stability\nprint(\"Test 3/6: Numerical Stability\")\nprint(\"-\" * 80)\nstability_stats = test_output_stability(model, config, n_samples=100)\nprint()\n\n# Test 4: Parameter Initialization\nprint(\"Test 4/6: Parameter Initialization\")\nprint(\"-\" * 80)\nparam_results = test_parameter_initialization(model)\ndisplay(param_results)\nprint()\n\n# Test 5: Memory Footprint\nprint(\"Test 5/6: Memory Footprint Analysis\")\nprint(\"-\" * 80)\nmemory_results = test_memory_footprint(model, config)\ndisplay(memory_results)\nprint()\n\n# Test 6: Inference Speed\nprint(\"Test 6/6: Inference Speed Benchmark\")\nprint(\"-\" * 80)\nspeed_stats = test_inference_speed(model, config, n_trials=50)\nprint()\n\nprint(\"=\" * 80)\nprint(\"‚úÖ TIER 1 VALIDATION COMPLETE\")\nprint(\"=\" * 80)\nprint()\nprint(\"All critical tests passed! Your model is mathematically sound.\")\nprint()\nprint(\"üìù Next steps:\")\nprint(\"   ‚Ä¢ Tier 2: Advanced analysis (attention patterns, attribution)\")\nprint(\"     ‚Üí Install optional dependencies in the cell before Tier 2\")\nprint(\"     ‚Üí Then run Tier 2 tests\")\nprint()\nprint(\"   ‚Ä¢ Tier 3: Training utilities (fine-tuning, hyperparameter search)\")\nprint(\"     ‚Üí Install optional dependencies in the cell before Tier 3\")\nprint(\"     ‚Üí Then run Tier 3 tests\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "---\n\n# üî¨ Tier 2: Advanced Analysis\n\nDeep dive into model behavior with advanced diagnostic tools.\n\n**Estimated time:** ~3-5 minutes\n\n**What's tested:**\n- üéØ **Attention Patterns:** Visualize attention weights, detect collapsed attention, analyze head specialization\n- üîç **Attribution Analysis:** Identify which input tokens contribute most to predictions (using Captum)\n- üõ°Ô∏è **Robustness Testing:** Measure stability under input perturbations and noise\n\n**Note:** These tests are optional but highly recommended for understanding model behavior.",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Tier 2: Advanced Analysis\n",
    "\n",
    "**Note:** Tier 2 tests use only Colab pre-installed packages (no installation required).\n",
    "\n",
    "- Test 1: Attention Pattern Analysis (uses built-in PyTorch)\n",
    "- Test 2: Robustness Testing (uses numpy/torch)\n",
    "\n",
    "All tests run automatically in the cell below."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "# Import Tier 2 test functions\n",
    "from utils.test_functions import (\n",
    "    test_attention_patterns,\n",
    "    test_robustness\n",
    ")\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"TIER 2: ADVANCED ANALYSIS\")\n",
    "print(\"=\" * 80)\n",
    "print()\n",
    "\n",
    "# Test 1: Attention Patterns\n",
    "print(\"Test 1/2: Attention Pattern Analysis\")\n",
    "print(\"-\" * 80)\n",
    "try:\n",
    "    attention_results = test_attention_patterns(model, config)\n",
    "    if attention_results is not None:\n",
    "        display(attention_results)\n",
    "    print(\"‚úÖ Attention analysis complete\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è Attention analysis skipped: {e}\")\n",
    "print()\n",
    "\n",
    "# Test 2: Robustness Testing\n",
    "print(\"Test 2/2: Robustness Under Noise\")\n",
    "print(\"-\" * 80)\n",
    "try:\n",
    "    robustness_results = test_robustness(model, config, n_samples=20)\n",
    "    if robustness_results is not None:\n",
    "        display(robustness_results)\n",
    "    print(\"‚úÖ Robustness analysis complete\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è Robustness analysis skipped: {e}\")\n",
    "print()\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"‚úÖ TIER 2 ANALYSIS COMPLETE\")\n",
    "print(\"=\" * 80)\n",
    "print()\n",
    "print(\"Next: Scroll down for Tier 3 (Training & Fine-Tuning)\")"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# üöÄ Tier 3: Training & Production Utilities\n",
    "\n",
    "**Training utilities have been moved to a separate notebook to prevent dependency conflicts.**\n",
    "\n",
    "## üìì Continue to Training Notebook\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/matt-hans/transformer-builder-colab-templates/blob/main/training.ipynb)\n",
    "\n",
    "**Click the button above to open the training notebook in Colab.**\n",
    "\n",
    "### What's included in training.ipynb:\n",
    "- üéì **Fine-Tuning:** Training loop with loss tracking and gradient monitoring\n",
    "- üîß **Hyperparameter Search:** Automated optimization using Optuna\n",
    "- üìä **Benchmark Comparison:** Compare against production baselines (distilgpt2, bert-base)\n",
    "\n",
    "### Before running training.ipynb:\n",
    "1. **Runtime ‚Üí Restart runtime** (fresh environment required)\n",
    "2. **Paste your same Gist ID** from Cell 3 above\n",
    "3. **Run all cells** - dependencies will install automatically\n",
    "\n",
    "**Estimated time:** 10-20 minutes (GPU recommended)\n",
    "\n",
    "---\n",
    "\n",
    "### Why separate notebooks?\n",
    "\n",
    "Training utilities require `pytorch-lightning` and `optuna`, which have NumPy version requirements that conflict with the zero-installation strategy used in this testing notebook.\n",
    "\n",
    "Running them in separate runtimes ensures:\n",
    "- ‚úÖ Testing notebook (this one) stays fast and dependency-free\n",
    "- ‚úÖ Training notebook has all the tools it needs without corruption\n",
    "- ‚úÖ Clear separation between validation and training workflows\n",
    "\n",
    "---\n",
    "\n",
    "**Repository:** [transformer-builder-colab-templates](https://github.com/matt-hans/transformer-builder-colab-templates)\n",
    "\n",
    "**Source:** Generated from [Transformer Builder](https://transformer-builder.com)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Mode selection and config preview (v4.0.0)\n",
    "from utils.ui.presets import build_configs_for_mode\n",
    "\n",
    "# Choose a mode: FAST_DEV, STANDARD_EXPERIMENT, ABLATION_SWEEP\n",
    "mode = 'FAST_DEV'\n",
    "training_cfg, task_spec, eval_cfg = build_configs_for_mode(mode)\n",
    "\n",
    "print('Mode:', mode)\n",
    "print('TrainingConfig:', training_cfg)\n",
    "print('TaskSpec:', task_spec)\n",
    "print('EvalConfig:', eval_cfg)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Load model from GitHub Gist (with revision pinning)\n",
    "from utils.adapters.gist_loader import load_gist_model\n",
    "from utils.training.experiment_db import ExperimentDB\n",
    "from pathlib import Path\n",
    "import importlib.util, sys\n",
    "\n",
    "gist_id = 'abcdef1234567890'  # replace with your gist id\n",
    "revision = None  # or a specific revision sha\n",
    "md = load_gist_model(gist_id, revision)\n",
    "print('Gist owner:', md.owner)\n",
    "print('Files:', md.file_names)\n",
    "print('SHA256:', md.sha256)\n",
    "\n",
    "# Optional: dynamic import model.py if present\n",
    "root = Path('./external/gists') / md.gist_id / (md.revision or 'latest')\n",
    "model_path = root / 'model.py'\n",
    "model = None\n",
    "if model_path.exists():\n",
    "    spec = importlib.util.spec_from_file_location('gist_model', str(model_path))\n",
    "    mod = importlib.util.module_from_spec(spec)\n",
    "    spec.loader.exec_module(mod)\n",
    "    # Expect either build_model() or Model class\n",
    "    if hasattr(mod, 'build_model'):\n",
    "        model = mod.build_model()\n",
    "    elif hasattr(mod, 'Model'):\n",
    "        model = mod.Model()\n",
    "    print('Loaded model from gist')\n",
    "else:\n",
    "    print('model.py not found in gist; define model manually')\n",
    "\n",
    "# Log gist metadata to ExperimentDB\n",
    "try:\n",
    "    db = ExperimentDB('experiments.db')\n",
    "    run_id = db.log_run(\n",
    "        run_name='gist-validation',\n",
    "        config={'source': 'gist'},\n",
    "        notes='Gist load test',\n",
    "        gist_id=md.gist_id,\n",
    "        gist_revision=md.revision,\n",
    "        gist_sha256=md.sha256,\n",
    "    )\n",
    "    print('Logged run_id:', run_id)\n",
    "except Exception as e:\n",
    "    print('DB logging skipped:', e)\n"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}