import torch
from _typeshed import Incomplete
from dataclasses import dataclass
from datasets import Dataset as HFDataset
from torch.utils.data import DataLoader, Dataset
from typing import Any, Callable, Protocol
from utils.training.task_spec import TaskSpec

__all__ = ['DataModuleProtocol', 'CollatorRegistry', 'CollatorInfo', 'DataLoaderConfig', 'DataLoaderFactory', 'UniversalDataModule']

class DataModuleProtocol(Protocol):
    def train_dataloader(self) -> DataLoader: ...
    def val_dataloader(self) -> DataLoader | None: ...

@dataclass
class CollatorInfo:
    name: str
    factory: Callable[..., Any]
    modality: str
    description: str

class CollatorRegistry:
    def __init__(self) -> None: ...
    @classmethod
    def get_instance(cls) -> CollatorRegistry: ...
    @classmethod
    def reset(cls) -> None: ...
    def register(self, name: str, modality: str, description: str = '') -> Callable[[Callable[..., Any]], Callable[..., Any]]: ...
    def get_collator(self, task_spec: TaskSpec | None = None, collator_name: str | None = None, **kwargs: Any) -> Any: ...
    def list_collators(self) -> list[CollatorInfo]: ...

@dataclass
class DataLoaderConfig:
    batch_size: int = ...
    shuffle: bool = ...
    num_workers: int = ...
    pin_memory: bool | None = ...
    prefetch_factor: int | None = ...
    persistent_workers: bool | None = ...
    drop_last: bool = ...
    seed: int = ...
    collate_fn: Callable[..., Any] | None = ...

class DataLoaderFactory:
    collator_registry: Incomplete
    def __init__(self, collator_registry: CollatorRegistry | None = None) -> None: ...
    def create_dataloader(self, dataset: Dataset | HFDataset | list[torch.Tensor], config: DataLoaderConfig, task_spec: TaskSpec | None = None, tokenizer: Any | None = None) -> DataLoader: ...

class UniversalDataModule:
    train_data: Incomplete
    val_data: Incomplete
    task_spec: Incomplete
    tokenizer: Incomplete
    batch_size: Incomplete
    val_split: Incomplete
    num_workers: Incomplete
    seed: Incomplete
    factory: Incomplete
    def __init__(self, train_data: Dataset | HFDataset | list[torch.Tensor], val_data: Dataset | HFDataset | list[torch.Tensor] | None = None, task_spec: TaskSpec | None = None, tokenizer: Any | None = None, batch_size: int = 32, val_split: float = 0.2, num_workers: int = 2, seed: int = 42, collator_registry: CollatorRegistry | None = None) -> None: ...
    def train_dataloader(self) -> DataLoader: ...
    def val_dataloader(self) -> DataLoader | None: ...
