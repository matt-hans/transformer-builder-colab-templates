"""
Transformer Builder Colab Utilities

Production-ready utilities for training, validating, and exporting
transformer models generated by the Transformer Builder platform.

Version: 2.0.0
License: MIT
"""

__version__ = "2.0.0"

# Core adapters (Tasks 1.3, 1.4, 2.1 complete)
from .adapters.model_adapter import (
    ModelSignatureInspector,
    ComputationalGraphExecutor,
    UniversalModelAdapter
)

# Tokenization (Tasks 2.2-2.7 complete)
from .tokenization.adaptive_tokenizer import AdaptiveTokenizer
from .tokenization.bpe_trainer import FastBPETrainer, BPETrainerConfig
from .tokenization.character_tokenizer import CharacterLevelTokenizer
from .tokenization.validator import TokenizerValidator

# Tokenization data modules - only import if pytorch_lightning available
try:
    from .tokenization.data_module import AdaptiveTokenizerDataModule, SimpleDataModule
except ImportError:
    # Stub classes when pytorch_lightning not available
    class AdaptiveTokenizerDataModule:
        def __init__(self, *args, **kwargs):
            raise ImportError("AdaptiveTokenizerDataModule requires pytorch_lightning (Tier 3 only)")

    class SimpleDataModule:
        def __init__(self, *args, **kwargs):
            raise ImportError("SimpleDataModule requires pytorch_lightning (Tier 3 only)")

# Training (Tasks 3.1-4.4 complete)
from .training.dataset_utilities import DatasetLoader, DatasetUploader
from .training.export_utilities import (
    ONNXExporter,
    TorchScriptExporter,
    ModelCardGenerator
)

# Training modules requiring pytorch_lightning - only import if available
try:
    from .training.checkpoint_manager import CheckpointManager
    from .training.training_core import TrainingCoordinator, train_model
except ImportError:
    # Set to None for Tier 1/2 users without pytorch_lightning
    CheckpointManager = None
    TrainingCoordinator = None
    train_model = None

# UI (Tasks 5.1-5.2 complete)
from .ui.setup_wizard import SetupWizard
from .ui.presets import ConfigPresets, PRESETS

# Helper modules (T001 - W&B Integration)
from .model_helpers import (
    find_model_class,
    instantiate_model,
    create_model_config,
    count_parameters,
    get_model_device,
    setup_model_from_gist
)
from .wandb_helpers import (
    detect_model_type,
    build_wandb_config,
    initialize_wandb_run,
    print_wandb_summary
)

# Test functions (backward compatibility - already available)
from .test_functions import *

__all__ = [
    # Version
    '__version__',

    # Adapters
    'ModelSignatureInspector',
    'ComputationalGraphExecutor',
    'UniversalModelAdapter',

    # Tokenization
    'AdaptiveTokenizer',
    'FastBPETrainer',
    'BPETrainerConfig',
    'CharacterLevelTokenizer',
    'TokenizerValidator',
    'AdaptiveTokenizerDataModule',
    'SimpleDataModule',

    # Training (available now)
    'DatasetLoader',
    'DatasetUploader',
    'CheckpointManager',
    'TrainingCoordinator',
    'train_model',
    'ONNXExporter',
    'TorchScriptExporter',
    'ModelCardGenerator',

    # UI (available now)
    'SetupWizard',
    'ConfigPresets',
    'PRESETS',

    # Helper modules (T001)
    'find_model_class',
    'instantiate_model',
    'create_model_config',
    'count_parameters',
    'get_model_device',
    'setup_model_from_gist',
    'detect_model_type',
    'build_wandb_config',
    'initialize_wandb_run',
    'print_wandb_summary',

    # Test functions (available now - re-exported from test_functions.py)
    'test_shape_robustness',
    'test_gradient_flow',
    'test_output_stability',
    'test_parameter_initialization',
    'test_memory_footprint',
    'test_inference_speed',
    'test_attention_patterns',
    'test_attribution_analysis',
    'test_robustness',
    'test_fine_tuning',
    'test_hyperparameter_search',
    'test_benchmark_comparison',
    'run_all_tier1_tests',
    'run_all_tier2_tests',
    'run_all_tests',
]
