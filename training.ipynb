{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e697c2b",
   "metadata": {},
   "source": [
    "# \ud83d\ude80 Transformer Training & Fine-Tuning Notebook\n",
    "\n",
    "**Professional ML Training Environment** for transformer models exported from [Transformer Builder](https://transformer-builder.com).\n",
    "\n",
    "## Quick Start Modes\n",
    "\n",
    "| Mode | Epochs | Time | Use Case |\n",
    "|------|--------|------|----------|\n",
    "| **\u26a1 Fast** | 3 | ~5 min | Quick validation |\n",
    "| **\u2696\ufe0f Balanced** | 10 | ~15 min | Development |\n",
    "| **\ud83d\udc8e Quality** | 20 | ~45 min | Production |\n",
    "\n",
    "## Features\n",
    "- \u2705 5 Data Sources (HuggingFace, Drive, Upload, Local, Synthetic)\n",
    "- \u2705 Live Training Visualization\n",
    "- \u2705 Google Drive Checkpoints\n",
    "- \u2705 W&B + Local SQLite Tracking\n",
    "- \u2705 Hyperparameter Search\n",
    "- \u2705 Export & Comparison Tools\n",
    "\n",
    "**\ud83d\udccc Tip**: Run all cells in order for best results. Adjust hyperparameters in Section 3."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aef71373",
   "metadata": {},
   "source": [
    "## \ud83d\udccb Table of Contents\n",
    "\n",
    "1. [Section 0: Quick Start](#section-0) \u2190 You are here\n",
    "2. [Section 1: Setup & Drive Workspace](#section-1) (2 min)\n",
    "3. [Section 2: Model Loading](#section-2) (Load custom or example model)\n",
    "4. [Section 3: Data Loading](#section-3) (5 sources)\n",
    "5. [Section 4: Training Configuration](#section-4) (Hyperparameters)\n",
    "6. [Section 5: W&B Tracking Setup](#section-5) (Optional)\n",
    "7. [Section 6: Training Loop](#section-6) (Main training)\n",
    "8. [Section 7: Analysis & Visualization](#section-7) (Dashboards)\n",
    "9. [Section 8: Export & Results](#section-8) (Download checkpoints)\n",
    "10. [Section 9: Advanced Features](#section-9) (Hyperparameter search)\n",
    "\n",
    "\u23f1\ufe0f **Total Time**: ~20-60 minutes depending on mode\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "410215b4",
   "metadata": {},
   "source": [
    "## \ud83d\udce6 Requirements\n",
    "\n",
    "This notebook requires:\n",
    "- Python >= 3.10\n",
    "- PyTorch (pre-installed in Colab)\n",
    "- Transformer Builder utilities (auto-downloaded)\n",
    "\n",
    "**GPU Recommended** but not required. Training will auto-detect and use GPU if available.\n",
    "\n",
    "---\n",
    "<a id=\"section-1\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01c2f932",
   "metadata": {},
   "outputs": [],
   "source": "# Install training dependencies\n!pip install -q -r https://raw.githubusercontent.com/matt-hans/transformer-builder-colab-templates/main/requirements-training.txt\n\n# Check for Flash Attention support (PyTorch 2.0+)\nimport torch\nprint(\"\u2705 Dependencies installed\")\nprint(f\"   PyTorch version: {torch.__version__}\")\n\nif torch.__version__ >= \"2.0.0\":\n    print(\"   \u2705 PyTorch 2.0+ detected - Flash Attention support available\")\n    if torch.cuda.is_available():\n        print(\"   \u2705 CUDA available - Flash Attention will be enabled automatically\")\n    else:\n        print(\"   \u26a0\ufe0f  CPU only - Flash Attention requires CUDA (GPU)\")\nelse:\n    print(\"   \u26a0\ufe0f  PyTorch < 2.0 - Flash Attention will be disabled\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "676a4b27",
   "metadata": {},
   "outputs": [],
   "source": "import os\n\nprint(\"\ud83d\udce5 Downloading training utilities...\")\n\n# Remove old utils directory if exists\n!rm -rf utils/\n\n# Download complete utils package from GitHub\n!git clone --depth 1 --branch main https://github.com/matt-hans/transformer-builder-colab-templates.git temp_repo 2>/dev/null\n\n# Copy utils directory\n!cp -r temp_repo/utils ./\n\n# Cleanup\n!rm -rf temp_repo\n\n# Verify package structure\nutils_path = os.path.join(os.getcwd(), 'utils')\nif os.path.exists(utils_path):\n    print(f\"\u2705 Utils package downloaded\")\n    \n    # Verify training subdirectory\n    training_path = os.path.join(utils_path, 'training')\n    if os.path.exists(training_path):\n        n_files = len([f for f in os.listdir(training_path) if f.endswith('.py')])\n        print(f\"\u2705 Training utilities: {n_files} modules found\")\n    \n    # Verify tier3 utilities\n    tier3_path = os.path.join(utils_path, 'tier3_training_utilities.py')\n    if os.path.exists(tier3_path):\n        print(f\"\u2705 Tier 3 training utilities ready\")\nelse:\n    print(\"\u274c Failed to download utils package\")\n    raise RuntimeError(\"Could not download training utilities\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7ea13e4",
   "metadata": {},
   "outputs": [],
   "source": "# @title \ud83d\udcbe Storage Configuration { display-mode: \"form\" }\n\nfrom google.colab import drive\nimport os\n\n# Storage option (user can choose)\nstorage_type = \"Google Drive\"  #@param [\"Google Drive\", \"Local (session only)\"]\n\nprint(\"=\" * 70)\nprint(\"STORAGE CONFIGURATION\")\nprint(\"=\" * 70)\nprint()\n\nworkspace_root = None\n\nif storage_type == \"Google Drive\":\n    print(\"\ud83d\udcc2 Attempting to mount Google Drive...\")\n    print()\n    \n    try:\n        # Try to mount Google Drive\n        drive.mount('/content/drive', force_remount=False)\n        \n        # Create workspace folders on Drive\n        workspace_root = '/content/drive/MyDrive/TransformerTraining'\n        os.makedirs(f'{workspace_root}/checkpoints', exist_ok=True)\n        os.makedirs(f'{workspace_root}/configs', exist_ok=True)\n        os.makedirs(f'{workspace_root}/results', exist_ok=True)\n        os.makedirs(f'{workspace_root}/datasets', exist_ok=True)\n        \n        print(\"\u2705 Google Drive mounted successfully!\")\n        print(f\"\u2705 Workspace created at: {workspace_root}\")\n        print()\n        print(\"\ud83d\udcc1 Directory structure:\")\n        print(f\"   \ud83d\udcc1 checkpoints/ - Saved model weights\")\n        print(f\"   \ud83d\udcc1 configs/ - Training configurations\")\n        print(f\"   \ud83d\udcc1 results/ - Metrics, plots, dashboards\")\n        print(f\"   \ud83d\udcc1 datasets/ - Cached datasets\")\n        print()\n        print(\"\ud83d\udca1 Benefits:\")\n        print(\"   \u2022 Files persist across sessions\")\n        print(\"   \u2022 Access from any device\")\n        print(\"   \u2022 Automatic backup\")\n        \n    except Exception as e:\n        print(\"\u274c Google Drive mount failed!\")\n        print()\n        print(f\"Error: {e}\")\n        print()\n        print(\"=\" * 70)\n        print(\"TROUBLESHOOTING\")\n        print(\"=\" * 70)\n        print()\n        print(\"Common solutions:\")\n        print(\"  1. Click the authentication link that appears above\")\n        print(\"  2. Sign in with your Google account\")\n        print(\"  3. Grant permissions to access Google Drive\")\n        print(\"  4. If in a corporate environment, check with IT\")\n        print()\n        print(\"=\" * 70)\n        print(\"FALLBACK: Using local storage\")\n        print(\"=\" * 70)\n        print()\n        \n        # Fallback to local storage\n        workspace_root = '/content/workspace'\n        os.makedirs(f'{workspace_root}/checkpoints', exist_ok=True)\n        os.makedirs(f'{workspace_root}/configs', exist_ok=True)\n        os.makedirs(f'{workspace_root}/results', exist_ok=True)\n        os.makedirs(f'{workspace_root}/datasets', exist_ok=True)\n        \n        print(f\"\u2705 Local workspace created at: {workspace_root}\")\n        print()\n        print(\"\u26a0\ufe0f  IMPORTANT: Local storage limitations:\")\n        print(\"   \u2022 Files will be DELETED when runtime ends\")\n        print(\"   \u2022 Maximum 12-hour session lifetime\")\n        print(\"   \u2022 Use 'Download results' option before session ends\")\n\nelse:\n    # User explicitly chose local storage\n    print(\"\ud83d\udcc2 Using local storage (session only)...\")\n    print()\n    \n    workspace_root = '/content/workspace'\n    os.makedirs(f'{workspace_root}/checkpoints', exist_ok=True)\n    os.makedirs(f'{workspace_root}/configs', exist_ok=True)\n    os.makedirs(f'{workspace_root}/results', exist_ok=True)\n    os.makedirs(f'{workspace_root}/datasets', exist_ok=True)\n    \n    print(f\"\u2705 Local workspace created at: {workspace_root}\")\n    print()\n    print(\"\ud83d\udcc1 Directory structure:\")\n    print(f\"   \ud83d\udcc1 checkpoints/ - Saved model weights\")\n    print(f\"   \ud83d\udcc1 configs/ - Training configurations\")\n    print(f\"   \ud83d\udcc1 results/ - Metrics, plots, dashboards\")\n    print(f\"   \ud83d\udcc1 datasets/ - Cached datasets\")\n    print()\n    print(\"\u26a0\ufe0f  IMPORTANT: Local storage limitations:\")\n    print(\"   \u2022 Files will be DELETED when runtime ends\")\n    print(\"   \u2022 Maximum 12-hour session lifetime\")\n    print(\"   \u2022 Use Section 8 'Download results' to save locally\")\n    print()\n    print(\"\ud83d\udca1 Tip: Switch to 'Google Drive' above for persistent storage\")\n\nprint()\nprint(\"=\" * 70)\nprint(\"\u2705 STORAGE READY\")\nprint(\"=\" * 70)\nprint()\nprint(f\"Workspace: {workspace_root}\")\nprint()"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37c65122",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.training.experiment_db import ExperimentDB\n",
    "\n",
    "# Initialize local SQLite tracking (backup to W&B)\n",
    "db = ExperimentDB(f'{workspace_root}/experiments.db')\n",
    "\n",
    "print(\"\u2705 Experiment database initialized\")\n",
    "print(f\"   Database: {workspace_root}/experiments.db\")\n",
    "print(f\"   Recent runs:\")\n",
    "recent_runs = db.list_runs(limit=5)\n",
    "if recent_runs:\n",
    "    print(recent_runs)\n",
    "else:\n",
    "    print(\"   (No previous runs found)\")"
   ]
  },
  {
   "cell_type": "code",
   "id": "kp5zpcfdwn9",
   "source": "# Import v3.5/v3.6 training infrastructure\nprint(\"\ud83d\udce6 Loading training infrastructure (v3.5/v3.6)...\")\n\n# Core training components\nfrom utils.training.training_core import TrainingCoordinator\nfrom utils.training.training_config import TrainingConfig\nfrom utils.training.task_spec import TaskSpec\nfrom utils.training.metrics_tracker import MetricsTracker\n\n# v3.6 features\nfrom utils.training.drift_metrics import compute_dataset_profile, compare_profiles\nfrom utils.training.dashboard import TrainingDashboard\n\n# v3.5 features\nfrom utils.training.export_utilities import create_export_bundle\n\n# Model adapters\nfrom utils.adapters.model_adapter import UniversalModelAdapter, FlashAttentionWrapper\n\n# Data handling\nfrom utils.tokenization.data_module import UniversalDataModule\n\nprint(\"\u2705 Training infrastructure loaded\")\nprint(\"   Core:\")\nprint(\"     - TrainingCoordinator (v3.5)\")\nprint(\"     - TrainingConfig (versioned configuration)\")\nprint(\"     - TaskSpec (modality-aware task definitions)\")\nprint(\"   v3.5 Features:\")\nprint(\"     - torch.compile integration (10-20% speedup)\")\nprint(\"     - VisionDataCollator (auto-selected for vision tasks)\")\nprint(\"     - Gradient accumulation tracking\")\nprint(\"     - Export bundle generation (production artifacts)\")\nprint(\"   v3.6 Features:\")\nprint(\"     - Distributed training guardrails (notebook safety)\")\nprint(\"     - Flash Attention support (2-4x attention speedup)\")\nprint(\"     - Drift visualization dashboard (10-panel layout)\")\nprint()\nprint(\"\ud83d\ude80 Ready for professional training!\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section-2\"></a>\n",
    "# \ud83d\udce6 Section 2: Model Loading\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load your transformer model from Transformer Builder or use the example model.\n",
    "\n",
    "**Options:**\n",
    "- **Custom Model**: Provide Gist ID from Transformer Builder (auto-detected from URL)\n",
    "- **Example Model**: GPT-2 style architecture for testing\n",
    "\n",
    "**You will see:**\n",
    "1. Model code preview\n",
    "2. Architecture summary (layers, parameters, size)\n",
    "3. GPU compatibility check\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title \ud83d\udd17 Model Source Configuration { display-mode: \"form\" }\n",
    "\n",
    "# Step 1: Try to extract from URL hash using JavaScript\n",
    "from google.colab import output\n",
    "import os\n",
    "import json\n",
    "\n",
    "# JavaScript to extract gist_id and model_name from URL hash\n",
    "js_code = \"\"\"\n",
    "(function() {\n",
    "    let gist_id = '';\n",
    "    let model_name = '';\n",
    "\n",
    "    try {\n",
    "        // Try to read URL hash from parent window (Colab embedding)\n",
    "        const hash = window.parent.location.hash || window.location.hash || '';\n",
    "\n",
    "        if (hash) {\n",
    "            // Parse hash parameters (e.g., #gist_id=abc123&name=MyModel)\n",
    "            const params = new URLSearchParams(hash.substring(1));\n",
    "            gist_id = params.get('gist_id') || '';\n",
    "            model_name = params.get('name') || '';\n",
    "\n",
    "            console.log('Extracted from URL hash:', {gist_id, model_name});\n",
    "        }\n",
    "    } catch (e) {\n",
    "        console.log('Could not access URL hash:', e);\n",
    "    }\n",
    "\n",
    "    // Return as JSON string\n",
    "    return JSON.stringify({gist_id: gist_id, model_name: model_name});\n",
    "})();\n",
    "\"\"\"\n",
    "\n",
    "# Execute JavaScript and get returned values\n",
    "try:\n",
    "    url_params_json = output.eval_js(js_code)\n",
    "    url_params = json.loads(url_params_json)\n",
    "    gist_id_from_url = url_params.get('gist_id', '')\n",
    "    model_name_from_url = url_params.get('model_name', '')\n",
    "except Exception as e:\n",
    "    print(f\"\u26a0\ufe0f  Could not extract from URL hash: {e}\")\n",
    "    gist_id_from_url = ''\n",
    "    model_name_from_url = ''\n",
    "\n",
    "# Step 2: Manual input forms (as fallback)\n",
    "gist_id_manual = \"\"  #@param {type:\"string\"}\n",
    "model_name_manual = \"CustomTransformer\"  #@param {type:\"string\"}\n",
    "\n",
    "# Step 3: Environment variables (lowest priority)\n",
    "gist_id_env = os.getenv('GIST_ID', '')\n",
    "model_name_env = os.getenv('MODEL_NAME', '')\n",
    "\n",
    "# Step 4: Determine final values (URL > Manual > Env)\n",
    "gist_id = gist_id_from_url or gist_id_manual or gist_id_env\n",
    "model_name = model_name_from_url or model_name_manual or model_name_env or 'CustomTransformer'\n",
    "\n",
    "# Display source\n",
    "print(\"=\"*60)\n",
    "if gist_id:\n",
    "    source = \"URL hash\" if gist_id_from_url else (\"Manual input\" if gist_id_manual else \"Environment variable\")\n",
    "    print(f\"\u2705 Model Source: {source}\")\n",
    "    print(f\"   Gist ID: {gist_id}\")\n",
    "    print(f\"   Model Name: {model_name}\")\n",
    "    print(f\"\\n   Loading custom model from Transformer Builder...\")\n",
    "else:\n",
    "    print(\"\u2139\ufe0f  No Gist ID provided\")\n",
    "    print(\"   Options to provide Gist ID:\")\n",
    "    print(\"   1. Open via Transformer Builder link (auto-detects from URL)\")\n",
    "    print(\"   2. Enter Gist ID in the form above\")\n",
    "    print(\"   3. Set GIST_ID environment variable\")\n",
    "    print(\"\\n   Proceeding with example model for demonstration...\")\n",
    "print(\"=\"*60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title \ud83d\udce6 Load Model from Gist { display-mode: \"form\" }\n",
    "\n",
    "import urllib.request\n",
    "import json\n",
    "import sys\n",
    "import tempfile\n",
    "import shutil\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"MODEL LOADING\")\n",
    "print(\"=\" * 70)\n",
    "print()\n",
    "\n",
    "# ==============================================================================\n",
    "# VERIFY GIST ID WAS PROVIDED\n",
    "# ==============================================================================\n",
    "\n",
    "if 'gist_id' not in globals() or not gist_id:\n",
    "    print(\"\u274c ERROR: No Gist ID found!\")\n",
    "    print()\n",
    "    print(\"==\" * 35)\n",
    "    print(\"\ud83d\udd19 GO BACK TO PREVIOUS CELL\")\n",
    "    print(\"==\" * 35)\n",
    "    print()\n",
    "    print(\"You must run the Model Source Configuration cell first.\")\n",
    "    print()\n",
    "    raise ValueError(\"Gist ID required - run previous cell first\")\n",
    "\n",
    "print(f\"\ud83d\udce5 Loading model from GitHub Gist: {gist_id}\")\n",
    "print()\n",
    "\n",
    "# ==============================================================================\n",
    "# FETCH GIST AND LOAD MODEL FILES - GitHub API Approach\n",
    "# ==============================================================================\n",
    "\n",
    "def _fetch_gist(gid: str) -> dict:\n",
    "    \"\"\"Fetch Gist data from GitHub API.\"\"\"\n",
    "    url = f\"https://api.github.com/gists/{gid}\"\n",
    "    req = urllib.request.Request(url, headers={\n",
    "        \"Accept\": \"application/vnd.github+json\",\n",
    "        \"User-Agent\": \"transformer-builder-colab\"\n",
    "    })\n",
    "    try:\n",
    "        with urllib.request.urlopen(req, timeout=20) as resp:\n",
    "            return json.loads(resp.read().decode(\"utf-8\"))\n",
    "    except urllib.error.HTTPError as e:\n",
    "        detail = f\"HTTP {e.code}\"\n",
    "        try:\n",
    "            body = e.read().decode(\"utf-8\")\n",
    "            if \"rate limit\" in body.lower():\n",
    "                detail += \" - GitHub API rate limit (try again in an hour)\"\n",
    "            elif e.code == 404:\n",
    "                detail += \" - Gist not found (check your Gist ID)\"\n",
    "        except:\n",
    "            pass\n",
    "        raise RuntimeError(f\"GitHub API error: {detail}\") from e\n",
    "    except Exception as e:\n",
    "        raise RuntimeError(f\"Network error: {e}\") from e\n",
    "\n",
    "def _write(path: str, text: str):\n",
    "    \"\"\"Write text to file.\"\"\"\n",
    "    with open(path, \"w\") as f:\n",
    "        f.write(text)\n",
    "\n",
    "# Fetch Gist\n",
    "try:\n",
    "    gist_data = _fetch_gist(gist_id)\n",
    "    files = gist_data.get(\"files\") or {}\n",
    "\n",
    "    # Check for required files\n",
    "    if \"model.py\" not in files:\n",
    "        raise RuntimeError(\"Gist is missing 'model.py' - please re-export from Transformer Builder\")\n",
    "    if \"config.json\" not in files:\n",
    "        raise RuntimeError(\"Gist is missing 'config.json' - please re-export from Transformer Builder\")\n",
    "\n",
    "    model_code = files[\"model.py\"].get(\"content\", \"\")\n",
    "    config_json = files[\"config.json\"].get(\"content\", \"\")\n",
    "\n",
    "    if not model_code or not config_json:\n",
    "        raise RuntimeError(\"Empty content in model.py or config.json\")\n",
    "\n",
    "    # Write to files\n",
    "    _write(\"model.py\", model_code)\n",
    "    _write(\"config.json\", config_json)\n",
    "\n",
    "    print(f\"\u2705 Model loaded successfully!\")\n",
    "    print(f\"\u2705 Gist URL: {gist_data.get('html_url', 'N/A')}\")\n",
    "    print(f\"\u2705 Model code: {len(model_code):,} bytes\")\n",
    "    print(f\"\u2705 Config: {len(config_json):,} bytes\")\n",
    "    print()\n",
    "\n",
    "    # Parse model name from config if available\n",
    "    try:\n",
    "        model_config = json.loads(config_json)\n",
    "        if 'model_name' in model_config:\n",
    "            model_name = model_config['model_name']\n",
    "            print(f\"\u2705 Model name: {model_name}\")\n",
    "        else:\n",
    "            model_name = 'CustomTransformer'\n",
    "            print(f\"\u2139\ufe0f  Using default name: {model_name}\")\n",
    "        print()\n",
    "    except:\n",
    "        model_name = 'CustomTransformer'\n",
    "        print(f\"\u26a0\ufe0f  Could not parse config, using default name: {model_name}\")\n",
    "\n",
    "    # Store for next cell\n",
    "    gist_loaded = True\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"\u274c Failed to load model from Gist!\")\n",
    "    print()\n",
    "    print(f\"Error: {e}\")\n",
    "    print()\n",
    "    print(\"=\" * 70)\n",
    "    print(\"TROUBLESHOOTING\")\n",
    "    print(\"=\" * 70)\n",
    "    print()\n",
    "    print(\"Common issues:\")\n",
    "    print(\"  1. Check your Gist ID is correct (go back to previous cell)\")\n",
    "    print(\"  2. Ensure you exported from Transformer Builder successfully\")\n",
    "    print(\"  3. Check you're not hitting GitHub rate limit (60 requests/hour)\")\n",
    "    print(\"  4. Try re-exporting from Transformer Builder\")\n",
    "    print()\n",
    "    print(\"If the problem persists:\")\n",
    "    print(f\"  \u2022 Gist URL: https://gist.github.com/{gist_id}\")\n",
    "    print(\"  \u2022 Verify the Gist contains model.py and config.json\")\n",
    "    print()\n",
    "\n",
    "    # Fallback to example model\n",
    "    print(\"\u26a0\ufe0f  Falling back to example model for demonstration...\")\n",
    "    gist_loaded = False\n",
    "    model_name = 'ExampleTransformer'\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"\u2705 MODEL LOADING COMPLETE\")\n",
    "print(\"=\" * 70)\n",
    "print()\n",
    "print(\"Model will be instantiated in the next cell.\")\n",
    "print()\n",
    "\n",
    "# Display downloaded model code preview\n",
    "if gist_loaded:\n",
    "    print(\"\\n\ud83d\udcc4 Model Code Preview:\")\n",
    "    print(\"=\" * 60)\n",
    "    with open('model.py', 'r') as f:\n",
    "        model_lines = f.read().split('\\n')\n",
    "        # Show first 20 lines\n",
    "        for i, line in enumerate(model_lines[:20], 1):\n",
    "            print(f\"{i:3d} | {line}\")\n",
    "        if len(model_lines) > 20:\n",
    "            print(f\"... ({len(model_lines) - 20} more lines)\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "print(f\"\\n\ud83d\udcca Model: {model_name}\")\n",
    "if gist_loaded:\n",
    "    print(f\"   Config: {json.dumps(model_config, indent=2)}\")\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# @title \ud83d\ude80 Initialize Model { display-mode: \"form\" }\n\nimport torch\nimport torch.nn as nn\nimport inspect\nfrom types import SimpleNamespace\n\n# Detect device\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(f\"\ud83d\udda5\ufe0f  Device: {device}\")\n\nif torch.cuda.is_available():\n    print(f\"   GPU: {torch.cuda.get_device_name(0)}\")\n    print(f\"   Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n\n# Create model instance\nif gist_loaded:\n    # Custom model from Transformer Builder\n    # Import the model from downloaded file\n    try:\n        sys.path.insert(0, '.')\n\n        # Import all classes from model.py\n        import importlib.util\n        spec = importlib.util.spec_from_file_location(\"custom_model\", \"model.py\")\n        custom_model_module = importlib.util.module_from_spec(spec)\n        spec.loader.exec_module(custom_model_module)\n\n        # Find the model class\n        model_class = None\n        for name, obj in vars(custom_model_module).items():\n            if isinstance(obj, type) and issubclass(obj, nn.Module) and obj is not nn.Module:\n                if name == model_name:\n                    model_class = obj\n                    break\n        \n        if model_class is None:\n            # Fallback: find any nn.Module subclass\n            for name, obj in vars(custom_model_module).items():\n                if isinstance(obj, type) and issubclass(obj, nn.Module) and obj is not nn.Module:\n                    model_class = obj\n                    print(f\"\u26a0\ufe0f Using {name} (expected {model_name})\")\n                    break\n        \n        if model_class:\n            # Check constructor signature (KEY FIX from template.ipynb)\n            sig = inspect.signature(model_class.__init__)\n            params_list = [p for p in sig.parameters.values() if p.name != 'self']\n            \n            if len(params_list) == 0:\n                # Parameterless constructor (Transformer Builder models)\n                print(\"\u2139\ufe0f  Model has parameterless constructor (Transformer Builder export)\")\n                model = model_class()\n            else:\n                # Parameterized constructor (traditional models)\n                print(f\"\u2139\ufe0f  Model accepts {len(params_list)} parameter(s)\")\n                model = model_class(**model_config)\n            \n            print(f\"\u2705 Custom model instantiated: {model.__class__.__name__}\")\n        else:\n            raise Exception(\"No model class found in model.py\")\n\n    except Exception as e:\n        print(f\"\u274c Failed to instantiate custom model: {e}\")\n        print(\"   Falling back to example model...\")\n        gist_loaded = False\n\nif not gist_loaded:\n    # Example model (fallback)\n    print(\"\ud83d\udce6 Loading example model (GPT-2 architecture)...\")\n\n    class ExampleTransformer(nn.Module):\n        \"\"\"Example GPT-2 style transformer for demonstration.\"\"\"\n\n        def __init__(self, vocab_size=50257, d_model=768, n_layers=12, n_heads=12, max_seq_len=1024):\n            super().__init__()\n            self.vocab_size = vocab_size\n            self.d_model = d_model\n            self.n_layers = n_layers\n            self.n_heads = n_heads\n            self.max_seq_len = max_seq_len\n\n            self.embedding = nn.Embedding(vocab_size, d_model)\n            self.position_embedding = nn.Embedding(max_seq_len, d_model)\n\n            # Simple transformer layers\n            self.layers = nn.ModuleList([\n                nn.TransformerEncoderLayer(\n                    d_model,\n                    n_heads,\n                    dim_feedforward=d_model*4,\n                    batch_first=True,\n                    dropout=0.1\n                )\n                for _ in range(n_layers)\n            ])\n\n            self.ln_f = nn.LayerNorm(d_model)\n            self.lm_head = nn.Linear(d_model, vocab_size, bias=False)\n\n        def forward(self, input_ids):\n            batch_size, seq_len = input_ids.shape\n\n            # Embeddings\n            token_emb = self.embedding(input_ids)\n            pos_ids = torch.arange(seq_len, device=input_ids.device).unsqueeze(0)\n            pos_emb = self.position_embedding(pos_ids)\n\n            x = token_emb + pos_emb\n\n            # Transformer layers\n            for layer in self.layers:\n                x = layer(x)\n\n            x = self.ln_f(x)\n            logits = self.lm_head(x)\n\n            return logits\n\n    # Create example model\n    model = ExampleTransformer()\n    model_config = {\n        'vocab_size': 50257,\n        'd_model': 768,\n        'n_layers': 12,\n        'n_heads': 12,\n        'max_seq_len': 1024\n    }\n\n    print(f\"\u2705 Example model definition loaded\")\n\n# Move to device\nmodel = model.to(device)\n\n# Model summary\ntotal_params = sum(p.numel() for p in model.parameters())\ntrainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n\nprint(f\"\\n\u2705 Model initialized on {device}\")\nprint(f\"   Total parameters: {total_params:,}\")\nprint(f\"   Trainable parameters: {trainable_params:,}\")\nprint(f\"   Model size: {total_params * 4 / 1e6:.1f} MB (fp32)\")\n\n# Create config object for training utilities\nconfig_obj = SimpleNamespace(**model_config)\nif not hasattr(config_obj, 'vocab_size'):\n    config_obj.vocab_size = model_config.get('vocab_size', 50257)\nif not hasattr(config_obj, 'max_seq_len'):\n    config_obj.max_seq_len = model_config.get('max_seq_len', 1024)\n\nprint(f\"\\n\ud83c\udfaf Ready for training!\")\nprint(f\"\\n\u2139\ufe0f  Note: Update Section 4 training config before starting training loop.\")\n"
  },
  {
   "cell_type": "markdown",
   "id": "5fc17228",
   "metadata": {},
   "source": [
    "<a id=\"section-3\"></a>\n",
    "# \ud83d\udcca Section 3: Data Loading\n",
    "\n",
    "Choose your data source (run ONE of the following cells):\n",
    "- **Option 1**: HuggingFace Datasets (recommended)\n",
    "- **Option 2**: Google Drive Upload\n",
    "- **Option 3**: File Upload (small datasets)\n",
    "- **Option 4**: Local Files (from previous sessions)\n",
    "- **Option 5**: Synthetic Data (testing only)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b3e6fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# CONFIGURATION: Edit dataset name\n",
    "dataset_name = \"wikitext\"  #@param {type:\"string\"}\n",
    "config_name = \"wikitext-2-raw-v1\"  #@param {type:\"string\"}\n",
    "max_samples = 1000  #@param {type:\"integer\"}\n",
    "\n",
    "# Load dataset\n",
    "dataset = load_dataset(dataset_name, config_name)\n",
    "train_data = dataset['train'].select(range(min(max_samples, len(dataset['train']))))\n",
    "val_data = dataset['validation'].select(range(min(100, len(dataset['validation']))))\n",
    "\n",
    "print(f\"\u2705 Loaded {len(train_data)} training samples, {len(val_data)} validation samples\")\n",
    "print(f\"   Example: {train_data[0]}\")\n",
    "\n",
    "data_source = \"huggingface\"\n",
    "dataset_info = {'name': dataset_name, 'config': config_name, 'train_size': len(train_data), 'val_size': len(val_data)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e417890",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "drive_data_path = \"/content/drive/MyDrive/TransformerTraining/datasets/my_data.txt\"  #@param {type:\"string\"}\n",
    "\n",
    "if os.path.exists(drive_data_path):\n",
    "    with open(drive_data_path, 'r', encoding='utf-8') as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    split_idx = int(0.9 * len(lines))\n",
    "    train_data = [line.strip() for line in lines[:split_idx]]\n",
    "    val_data = [line.strip() for line in lines[split_idx:]]\n",
    "\n",
    "    print(f\"\u2705 Loaded {len(train_data)} training samples, {len(val_data)} validation samples\")\n",
    "    data_source = \"google_drive\"\n",
    "    dataset_info = {'path': drive_data_path, 'train_size': len(train_data), 'val_size': len(val_data)}\n",
    "else:\n",
    "    print(f\"\u274c File not found: {drive_data_path}\")\n",
    "    print(\"   Please upload your data to Google Drive first\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "366269e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "import io\n",
    "\n",
    "# Upload file\n",
    "uploaded = files.upload()\n",
    "\n",
    "if uploaded:\n",
    "    filename = list(uploaded.keys())[0]\n",
    "    content = uploaded[filename].decode('utf-8')\n",
    "    lines = content.split('\\n')\n",
    "\n",
    "    split_idx = int(0.9 * len(lines))\n",
    "    train_data = [line.strip() for line in lines[:split_idx]]\n",
    "    val_data = [line.strip() for line in lines[split_idx:]]\n",
    "\n",
    "    print(f\"\u2705 Loaded {len(train_data)} training samples, {len(val_data)} validation samples\")\n",
    "    data_source = \"file_upload\"\n",
    "    dataset_info = {'filename': filename, 'train_size': len(train_data), 'val_size': len(val_data)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a4882b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "\n",
    "cache_path = f'{workspace_root}/datasets/cached_data.pkl'\n",
    "\n",
    "if os.path.exists(cache_path):\n",
    "    with open(cache_path, 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "\n",
    "    train_data = data['train']\n",
    "    val_data = data['val']\n",
    "\n",
    "    print(f\"\u2705 Loaded cached data: {len(train_data)} train, {len(val_data)} val\")\n",
    "    data_source = \"cached\"\n",
    "    dataset_info = {'path': cache_path, 'train_size': len(train_data), 'val_size': len(val_data)}\n",
    "else:\n",
    "    print(f\"\u274c No cached data found at {cache_path}\")\n",
    "    print(\"   Run one of the other data loading options first\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7865100c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Generate synthetic data for testing\n",
    "vocab_size = 50257  # GPT-2 vocab\n",
    "seq_len = 32\n",
    "n_samples = 100\n",
    "\n",
    "train_data = [torch.randint(0, vocab_size, (seq_len,)) for _ in range(n_samples)]\n",
    "val_data = [torch.randint(0, vocab_size, (seq_len,)) for _ in range(20)]\n",
    "\n",
    "print(f\"\u2705 Generated {len(train_data)} synthetic training samples\")\n",
    "print(f\"   \u26a0\ufe0f Warning: Synthetic data is for testing only\")\n",
    "data_source = \"synthetic\"\n",
    "dataset_info = {'vocab_size': vocab_size, 'seq_len': seq_len, 'train_size': len(train_data), 'val_size': len(val_data)}"
   ]
  },
  {
   "cell_type": "code",
   "id": "7s2xtx5f5n8",
   "source": "# @title \ud83c\udfaf Task Specification (Auto-Detected) { display-mode: \"form\" }\n\nfrom types import SimpleNamespace\n\nprint(\"=\" * 70)\nprint(\"TASK SPECIFICATION\")\nprint(\"=\" * 70)\nprint()\n\n# Auto-detect modality from data source\ndetected_modality = \"text\"  # Default\ndetected_task_type = \"lm\"   # Default\n\n# Try to detect from data\nif 'train_data' in globals() and train_data:\n    try:\n        sample = train_data[0] if isinstance(train_data, list) else train_data[0]\n        \n        # Check for vision data\n        if isinstance(sample, dict):\n            if 'pixel_values' in sample or 'image' in sample:\n                detected_modality = \"vision\"\n                detected_task_type = \"vision_classification\"\n                print(\"\ud83d\udd0d Detected vision data (found pixel_values/image in sample)\")\n            elif 'input_ids' in sample or 'text' in sample:\n                detected_modality = \"text\"\n                detected_task_type = \"lm\"\n                print(\"\ud83d\udd0d Detected text data (found input_ids/text in sample)\")\n        elif isinstance(sample, torch.Tensor):\n            if sample.dim() >= 3:  # Likely image (C, H, W) or (B, C, H, W)\n                detected_modality = \"vision\"\n                detected_task_type = \"vision_classification\"\n                print(f\"\ud83d\udd0d Detected vision data (tensor shape: {sample.shape})\")\n            else:\n                detected_modality = \"text\"\n                detected_task_type = \"lm\"\n                print(f\"\ud83d\udd0d Detected text data (tensor shape: {sample.shape})\")\n    except Exception as e:\n        print(f\"\u26a0\ufe0f  Could not auto-detect from data: {e}\")\n        print(\"   Using default: text/lm\")\n\nprint(f\"   Modality: {detected_modality}\")\nprint(f\"   Task type: {detected_task_type}\")\nprint()\n\n# Allow manual override\ntask_modality = detected_modality  #@param [\"text\", \"vision\", \"audio\", \"tabular\"]\ntask_type = detected_task_type  #@param [\"lm\", \"classification\", \"seq2seq\", \"vision_classification\", \"vision_multilabel\"]\n\nprint(f\"\ud83d\udcdd Final selection:\")\nprint(f\"   Modality: {task_modality}\")\nprint(f\"   Task type: {task_type}\")\nprint()\n\n# Create TaskSpec based on modality\nif task_modality == \"vision\":\n    # Vision task configuration\n    image_size = getattr(config_obj, 'image_size', [3, 224, 224]) if 'config_obj' in globals() else [3, 224, 224]\n    num_classes = getattr(config_obj, 'num_classes', 10) if 'config_obj' in globals() else 10\n    \n    task_spec = TaskSpec(\n        name=f\"{model_name}_vision\" if 'model_name' in globals() else \"vision_task\",\n        task_type=task_type,\n        model_family=\"encoder_only\",\n        input_fields=[\"pixel_values\"],\n        target_field=\"labels\",\n        loss_type=\"cross_entropy\",\n        metrics=[\"loss\", \"accuracy\"],\n        modality=\"vision\",\n        input_schema={\"image_size\": image_size, \"channels_first\": True},\n        output_schema={\"num_classes\": num_classes},\n        preprocessing_config={\n            \"normalize\": True,\n            \"mean\": [0.485, 0.456, 0.406],  # ImageNet defaults\n            \"std\": [0.229, 0.224, 0.225]\n        }\n    )\n    \n    print(\"\u2705 Vision TaskSpec created\")\n    print(f\"   Image size: {image_size}\")\n    print(f\"   Num classes: {num_classes}\")\n    print(f\"   VisionDataCollator will be auto-selected (v3.5 feature)\")\n    \nelse:  # text modality\n    # Text task configuration\n    vocab_size = getattr(config_obj, 'vocab_size', 50257) if 'config_obj' in globals() else 50257\n    max_seq_len = getattr(config_obj, 'max_seq_len', 128) if 'config_obj' in globals() else 128\n    \n    task_spec = TaskSpec(\n        name=f\"{model_name}_lm\" if 'model_name' in globals() else \"text_task\",\n        task_type=task_type,\n        model_family=\"decoder_only\",\n        input_fields=[\"input_ids\", \"attention_mask\"],\n        target_field=\"labels\",\n        loss_type=\"cross_entropy\",\n        metrics=[\"loss\", \"perplexity\", \"accuracy\"],\n        modality=\"text\",\n        input_schema={\"max_seq_len\": max_seq_len, \"vocab_size\": vocab_size},\n        output_schema={\"vocab_size\": vocab_size},\n        special_tokens={\"pad_token_id\": 0},\n        additional_config={\"shift_labels\": True}\n    )\n    \n    print(\"\u2705 Text TaskSpec created\")\n    print(f\"   Vocab size: {vocab_size}\")\n    print(f\"   Max sequence length: {max_seq_len}\")\n\nprint()\nprint(\"=\" * 70)\nprint(\"\u2705 TASK SPECIFICATION COMPLETE\")\nprint(\"=\" * 70)\nprint()\nprint(\"\ud83d\udca1 TaskSpec enables:\")\nprint(\"   - Modality-aware data collation\")\nprint(\"   - Drift detection (v3.6)\")\nprint(\"   - Export bundle generation (v3.5)\")\nprint()",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "56295914",
   "metadata": {},
   "source": [
    "<a id=\"section-4\"></a>\n",
    "# \u2699\ufe0f Section 4: Training Configuration\n",
    "\n",
    "Configure hyperparameters using Colab forms below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "269a022f",
   "metadata": {},
   "outputs": [],
   "source": "# @title \u2699\ufe0f Training Configuration (v3.5/v3.6 Features) { display-mode: \"form\" }\n\nfrom utils.training.training_config import TrainingConfig\n\nprint(\"=\" * 70)\nprint(\"TRAINING CONFIGURATION\")\nprint(\"=\" * 70)\nprint()\n\n# === HYPERPARAMETERS ===\nlearning_rate = 5e-5  #@param {type:\"number\"}\nbatch_size = 4  #@param {type:\"integer\"}\nepochs = 10  #@param {type:\"integer\"}\nwarmup_ratio = 0.1  #@param {type:\"number\"}\nweight_decay = 0.01  #@param {type:\"number\"}\ngradient_clip_norm = 1.0  #@param {type:\"number\"}\n\n# === v3.5 PERFORMANCE FEATURES ===\n# torch.compile: 10-20% speedup (PyTorch 2.0+)\ncompile_mode = \"default\"  #@param [\"None\", \"default\", \"reduce-overhead\", \"max-autotune\"]\ncompile_mode = None if compile_mode == \"None\" else compile_mode\n\n# Gradient accumulation: effective batch size = batch_size * accumulation_steps\ngradient_accumulation_steps = 1  #@param {type:\"integer\"}\n\n# === v3.5 EXPORT FEATURES ===\n# Export bundle generation\nexport_bundle = True  #@param {type:\"boolean\"}\nexport_formats_str = \"onnx,torchscript,pytorch\"  #@param {type:\"string\"}\nexport_formats = [fmt.strip() for fmt in export_formats_str.split(',')]\n\n# === STANDARD TRAINING FEATURES ===\nuse_amp = True  #@param {type:\"boolean\"}\ndeterministic = False  #@param {type:\"boolean\"}\nrun_name = \"training-run\"  #@param {type:\"string\"}\nrandom_seed = 42  #@param {type:\"integer\"}\n\n# Create TrainingConfig\ntraining_config = TrainingConfig(\n    # Hyperparameters\n    learning_rate=learning_rate,\n    batch_size=batch_size,\n    epochs=epochs,\n    warmup_ratio=warmup_ratio,\n    weight_decay=weight_decay,\n    max_grad_norm=gradient_clip_norm,\n    \n    # v3.5 features\n    compile_mode=compile_mode,\n    gradient_accumulation_steps=gradient_accumulation_steps,\n    export_bundle=export_bundle,\n    export_formats=export_formats,\n    export_dir=f'{workspace_root}/exports',\n    \n    # Standard features\n    use_amp=use_amp,\n    deterministic=deterministic,\n    random_seed=random_seed,\n    run_name=run_name,\n    \n    # Directories\n    output_dir=f'{workspace_root}/training_output',\n    checkpoint_dir=f'{workspace_root}/checkpoints',\n    log_dir=f'{workspace_root}/logs',\n)\n\n# Validate configuration\ntraining_config.validate()\n\n# Save to Drive\nconfig_path = training_config.save(f'{workspace_root}/configs/')\nprint(f\"\u2705 Config saved: {config_path}\")\nprint()\n\n# Display configuration summary\nprint(\"HYPERPARAMETERS\")\nprint(\"-\" * 70)\nprint(f\"{'Run Name:':<30} {training_config.run_name}\")\nprint(f\"{'Learning Rate:':<30} {training_config.learning_rate}\")\nprint(f\"{'Batch Size (per step):':<30} {training_config.batch_size}\")\nprint(f\"{'Effective Batch Size:':<30} {training_config.batch_size * training_config.gradient_accumulation_steps}\")\nprint(f\"{'Epochs:':<30} {training_config.epochs}\")\nprint(f\"{'Warmup Ratio:':<30} {training_config.warmup_ratio}\")\nprint(f\"{'Weight Decay:':<30} {training_config.weight_decay}\")\nprint(f\"{'Gradient Clipping:':<30} {gradient_clip_norm}\")\nprint()\n\nprint(\"v3.5 PERFORMANCE FEATURES\")\nprint(\"-\" * 70)\nprint(f\"{'torch.compile:':<30} {compile_mode or 'Disabled'}\")\nif compile_mode:\n    expected_speedup = {\"default\": \"10-15%\", \"reduce-overhead\": \"15-20%\", \"max-autotune\": \"20-30%\"}\n    print(f\"{'  Expected speedup:':<30} ~{expected_speedup.get(compile_mode, '10-20%')}\")\n    print(f\"{'  Compilation time:':<30} {'~30s' if compile_mode == 'max-autotune' else '~5s'}\")\nprint()\nprint(f\"{'Gradient Accumulation:':<30} {gradient_accumulation_steps}x\")\nif gradient_accumulation_steps > 1:\n    log_reduction = 100 * (1 - 1/gradient_accumulation_steps)\n    print(f\"{'  W&B log reduction:':<30} ~{log_reduction:.0f}%\")\n    print(f\"{'  Memory efficient:':<30} Train larger models on same GPU\")\nprint()\n\nprint(\"v3.5 EXPORT FEATURES\")\nprint(\"-\" * 70)\nprint(f\"{'Export Bundle:':<30} {'Enabled' if export_bundle else 'Disabled'}\")\nif export_bundle:\n    print(f\"{'  Formats:':<30} {', '.join(export_formats)}\")\n    print(f\"{'  Output dir:':<30} {training_config.export_dir}\")\n    print(f\"{'  Includes:':<30} Dockerfile, inference.py, README\")\nprint()\n\nprint(\"v3.6 AUTOMATIC FEATURES\")\nprint(\"-\" * 70)\nprint(f\"{'Distributed Guardrails:':<30} \u2705 Active (notebook detection)\")\nprint(f\"{'  Prevents:':<30} DDP/FSDP zombie processes in Jupyter/Colab\")\nprint()\nprint(f\"{'Flash Attention:':<30} Auto-enabled (PyTorch 2.0+ + CUDA)\")\nif torch.__version__ >= \"2.0.0\" and torch.cuda.is_available():\n    print(f\"{'  Status:':<30} \u2705 Will be enabled during training\")\n    print(f\"{'  Expected speedup:':<30} 2-4x for attention operations\")\nelif torch.__version__ < \"2.0.0\":\n    print(f\"{'  Status:':<30} \u26a0\ufe0f  Requires PyTorch 2.0+\")\nelse:\n    print(f\"{'  Status:':<30} \u26a0\ufe0f  Requires CUDA (GPU)\")\nprint()\nprint(f\"{'Drift Visualization:':<30} Available via plot_with_drift()\")\nprint(f\"{'  Panels:':<30} 10-panel dashboard (6 training + 4 drift)\")\nprint()\n\nprint(\"STANDARD FEATURES\")\nprint(\"-\" * 70)\nprint(f\"{'Mixed Precision (AMP):':<30} {'Enabled' if use_amp else 'Disabled'}\")\nprint(f\"{'Deterministic Mode:':<30} {'Enabled' if deterministic else 'Disabled (fast)'}\")\nprint(f\"{'Random Seed:':<30} {random_seed}\")\nprint(f\"{'Data Source:':<30} {data_source if 'data_source' in globals() else 'N/A'}\")\nprint()\n\nprint(\"=\" * 70)\nprint(\"\u2705 CONFIGURATION COMPLETE\")\nprint(\"=\" * 70)\nprint()\nprint(\"\ud83d\udca1 Proceed to Section 6 for training with all features enabled\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b568df14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display configuration summary\n",
    "print(\"=\" * 60)\n",
    "print(\" \" * 15 + \"TRAINING CONFIGURATION\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"{'Run Name:':<25} {config.run_name}\")\n",
    "print(f\"{'Learning Rate:':<25} {config.learning_rate}\")\n",
    "print(f\"{'Batch Size (effective):':<25} {config.batch_size * config.gradient_accumulation_steps}\")\n",
    "print(f\"{'Epochs:':<25} {config.epochs}\")\n",
    "print(f\"{'Warmup Ratio:':<25} {config.warmup_ratio}\")\n",
    "print(f\"{'Gradient Clipping:':<25} {config.max_grad_norm}\")\n",
    "print(f\"{'AMP Enabled:':<25} {config.use_amp}\")\n",
    "print(f\"{'Deterministic:':<25} {config.deterministic}\")\n",
    "print(f\"{'Random Seed:':<25} {config.random_seed}\")\n",
    "print(f\"{'Data Source:':<25} {data_source}\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c5e4445",
   "metadata": {},
   "source": [
    "### Training Mode Selection\n",
    "\n",
    "Based on your `epochs` setting:\n",
    "- **epochs <= 5**: \u26a1 Fast Mode (~5 min)\n",
    "- **epochs <= 15**: \u2696\ufe0f Balanced Mode (~15 min)\n",
    "- **epochs > 15**: \ud83d\udc8e Quality Mode (45+ min)\n",
    "\n",
    "Proceed to training in Section 5 \u2b07\ufe0f"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d46ead6",
   "metadata": {},
   "source": [
    "<a id=\"section-5\"></a>\n",
    "# \ud83d\udd2c Section 5: W&B Tracking Setup (Optional)\n",
    "\n",
    "Enable Weights & Biases for cloud-based experiment tracking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae42ab74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "from getpass import getpass\n",
    "\n",
    "use_wandb = True  #@param {type:\"boolean\"}\n",
    "wandb_project = \"transformer-training\"  #@param {type:\"string\"}\n",
    "wandb_entity = \"\"  #@param {type:\"string\"}\n",
    "\n",
    "if use_wandb:\n",
    "    # Login to W&B\n",
    "    wandb_key = getpass(\"Enter W&B API key (or leave blank to skip): \")\n",
    "    if wandb_key:\n",
    "        wandb.login(key=wandb_key)\n",
    "\n",
    "        # Initialize run\n",
    "        wandb.init(\n",
    "            project=wandb_project,\n",
    "            entity=wandb_entity if wandb_entity else None,\n",
    "            name=config.run_name,\n",
    "            config=config.to_dict(),\n",
    "            tags=[data_source, f\"epochs_{epochs}\"]\n",
    "        )\n",
    "        print(f\"\u2705 W&B initialized: {wandb.run.url}\")\n",
    "    else:\n",
    "        use_wandb = False\n",
    "        print(\"\u26a0\ufe0f W&B skipped - training will use local tracking only\")\n",
    "else:\n",
    "    print(\"\u2139\ufe0f W&B disabled - using local SQLite tracking\")"
   ]
  },
  {
   "cell_type": "code",
   "id": "rqtj1fr1pf",
   "source": "# @title \ud83d\udcca Dataset Drift Profiling (v3.6 - Optional, 1-2 min) { display-mode: \"form\" }\n\nenable_drift_detection = True  #@param {type:\"boolean\"}\ndrift_sample_size = 1000  #@param {type:\"integer\"}\n\ndrift_data = None\n\nif enable_drift_detection:\n    print(\"=\" * 70)\n    print(\"DATASET DRIFT PROFILING (v3.6)\")\n    print(\"=\" * 70)\n    print()\n    print(\"\ud83d\udcca Computing dataset profiles for drift detection...\")\n    print(f\"   Sample size: {min(drift_sample_size, len(train_data))} from training\")\n    print(f\"   Sample size: {min(drift_sample_size, len(val_data))} from validation\")\n    print()\n    \n    try:\n        # Profile training dataset (reference)\n        print(\"1/2 Profiling training dataset...\")\n        train_subset = train_data[:drift_sample_size] if isinstance(train_data, list) else train_data\n        train_profile = compute_dataset_profile(\n            dataset=train_subset,\n            task_spec=task_spec,\n            sample_size=drift_sample_size\n        )\n        print(\"   \u2705 Training profile complete\")\n        \n        # Profile validation dataset (comparison)\n        print(\"2/2 Profiling validation dataset...\")\n        val_subset = val_data[:drift_sample_size] if isinstance(val_data, list) else val_data\n        val_profile = compute_dataset_profile(\n            dataset=val_subset,\n            task_spec=task_spec,\n            sample_size=drift_sample_size\n        )\n        print(\"   \u2705 Validation profile complete\")\n        print()\n        \n        # Compare profiles\n        print(\"\ud83d\udd0d Computing drift scores...\")\n        drift_comparison = compare_profiles(train_profile, val_profile)\n        \n        # Display results\n        print()\n        print(\"DRIFT DETECTION RESULTS\")\n        print(\"-\" * 70)\n        \n        max_drift = 0.0\n        for metric, score in drift_comparison['drift_scores'].items():\n            max_drift = max(max_drift, score)\n            \n            # Determine status\n            if score < 0.1:\n                status_emoji = '\u2705'\n                status_text = 'Healthy'\n            elif score < 0.2:\n                status_emoji = '\u26a0\ufe0f '\n                status_text = 'Warning'\n            else:\n                status_emoji = '\ud83d\udea8'\n                status_text = 'Critical'\n            \n            print(f\"{status_emoji} {metric:<25} {score:.4f} ({status_text})\")\n        \n        print(\"-\" * 70)\n        print()\n        \n        # Overall status\n        if max_drift < 0.1:\n            overall_status = 'healthy'\n            print(\"\u2705 HEALTHY: Minimal drift detected\")\n            print(\"   Training and validation datasets are well-matched\")\n        elif max_drift < 0.2:\n            overall_status = 'warning'\n            print(\"\u26a0\ufe0f  WARNING: Moderate drift detected\")\n            print(\"   Recommendation:\")\n            print(\"   - Monitor training metrics closely\")\n            print(\"   - Consider reviewing train/val split\")\n        else:\n            overall_status = 'critical'\n            print(\"\ud83d\udea8 CRITICAL: Significant drift detected!\")\n            print(\"   Action Required:\")\n            print(\"   - Check data preprocessing consistency\")\n            print(\"   - Review train/val split strategy\")\n            print(\"   - Investigate distribution shift causes\")\n            \n            if task_modality == \"text\":\n                print()\n                print(\"   Common causes for text:\")\n                print(\"   - Different text sources (news vs social media)\")\n                print(\"   - Language/domain shift (formal vs casual)\")\n                print(\"   - Tokenization inconsistencies\")\n            elif task_modality == \"vision\":\n                print()\n                print(\"   Common causes for vision:\")\n                print(\"   - Different image preprocessing\")\n                print(\"   - Lighting conditions (indoor vs outdoor)\")\n                print(\"   - Camera/sensor differences\")\n        \n        print()\n        print(f\"Max Drift Score: {max_drift:.4f}\")\n        print()\n        \n        # Package for dashboard visualization\n        drift_data = {\n            'reference_profile': train_profile,\n            'new_profile': val_profile,\n            'drift_scores': drift_comparison['drift_scores'],\n            'status': overall_status\n        }\n        \n        print(\"=\" * 70)\n        print(\"\u2705 DRIFT PROFILING COMPLETE\")\n        print(\"=\" * 70)\n        print()\n        print(\"\ud83d\udca1 Drift visualization will be available in Section 7 dashboard\")\n        print()\n        \n    except Exception as e:\n        print(f\"\u274c Drift profiling failed: {e}\")\n        print(\"   Continuing without drift detection\")\n        drift_data = None\nelse:\n    print(\"=\" * 70)\n    print(\"DRIFT PROFILING SKIPPED\")\n    print(\"=\" * 70)\n    print()\n    print(\"\u2139\ufe0f  Drift detection disabled\")\n    print(\"   Set enable_drift_detection=True to enable\")\n    print()\n    print(\"\ud83d\udca1 Benefits of drift detection:\")\n    print(\"   - Early warning of data distribution shifts\")\n    print(\"   - Helps diagnose training issues\")\n    print(\"   - Validates train/val split quality\")\n    print(\"=\" * 70)\n    print()",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "62ce57e5",
   "metadata": {},
   "source": [
    "<a id=\"section-6\"></a>\n",
    "# \ud83c\udfcb\ufe0f Section 6: Training Loop\n",
    "\n",
    "Main training loop with live visualization and checkpointing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c08c98ec",
   "metadata": {},
   "outputs": [],
   "source": "# @title \ud83d\ude80 TrainingCoordinator Setup (v3.5/v3.6) { display-mode: \"form\" }\n\nfrom utils.training.seed_manager import set_random_seed\n\nprint(\"=\" * 70)\nprint(\"TRAINING COORDINATOR SETUP\")\nprint(\"=\" * 70)\nprint()\n\n# Set random seed for reproducibility\nprint(f\"\ud83c\udfb2 Setting random seed: {training_config.random_seed}\")\nset_random_seed(training_config.random_seed, training_config.deterministic)\nprint(f\"   Mode: {'Deterministic (bit-exact)' if training_config.deterministic else 'Fast (cuDNN auto-tuning)'}\")\nprint()\n\n# Create data module\nprint(\"\ud83d\udce6 Creating UniversalDataModule...\")\n\n# For text tasks, we need to handle tokenization\nif task_spec.modality == \"text\":\n    # Simple tokenizer setup for demonstration\n    # In production, you'd use a proper tokenizer\n    print(\"   Modality: TEXT\")\n    print(\"   Note: Using simplified tokenization for demonstration\")\n    print(\"   For production, implement proper tokenization in data loading\")\n    \n    # Create simple wrapper if data is already tokenized\n    final_train_data = train_data\n    final_val_data = val_data\n    tokenizer = None\n    \nelse:  # vision\n    print(f\"   Modality: VISION\")\n    print(f\"   VisionDataCollator will be auto-selected (v3.5)\")\n    final_train_data = train_data\n    final_val_data = val_data\n    tokenizer = None\n\n# Create data module\ndata_module = UniversalDataModule(\n    train_dataset=final_train_data,\n    val_dataset=final_val_data,\n    task_spec=task_spec,\n    batch_size=training_config.batch_size,\n    num_workers=2,\n    tokenizer=tokenizer\n)\n\nprint(f\"\u2705 Data module created\")\napprox_train_batches = len(final_train_data) // training_config.batch_size\napprox_val_batches = len(final_val_data) // training_config.batch_size\nprint(f\"   Train batches: ~{approx_train_batches}\")\nprint(f\"   Val batches: ~{approx_val_batches}\")\nprint()\n\n# Initialize TrainingCoordinator\nprint(\"\ud83c\udfd7\ufe0f  Initializing TrainingCoordinator...\")\n\n# Determine precision string\nif training_config.use_amp:\n    precision_str = '16-mixed'  # PyTorch Lightning 2.x format\nelse:\n    precision_str = '32-true'\n\ncoordinator = TrainingCoordinator(\n    output_dir=training_config.output_dir,\n    use_gpu=torch.cuda.is_available(),\n    precision=precision_str,\n    gradient_clip_val=training_config.max_grad_norm,\n    strategy='auto',  # v3.6: Notebook guardrails will auto-adjust\n    devices='auto'\n)\n\nprint(f\"\u2705 Coordinator initialized\")\nprint(f\"   Output dir: {training_config.output_dir}\")\nprint(f\"   Device: {'GPU' if torch.cuda.is_available() else 'CPU'}\")\nprint(f\"   Precision: {precision_str}\")\nprint(f\"   Strategy: auto (notebook-safe)\")\nprint(f\"   Gradient clipping: {training_config.max_grad_norm}\")\nprint()\n\n# Display v3.6 automatic features\nprint(\"v3.6 AUTOMATIC FEATURES\")\nprint(\"-\" * 70)\n\n# Check Flash Attention\nif torch.cuda.is_available() and torch.__version__ >= \"2.0.0\":\n    # Flash Attention will be detected by UniversalModelAdapter\n    print(\"Flash Attention:\")\n    print(f\"   \u2705 Available (PyTorch {torch.__version__} + CUDA)\")\n    print(f\"   Will be auto-enabled during training\")\n    print(f\"   Expected speedup: 2-4x for attention operations\")\nelse:\n    print(\"Flash Attention:\")\n    if not torch.cuda.is_available():\n        print(f\"   \u26a0\ufe0f  Requires CUDA (currently on CPU)\")\n    else:\n        print(f\"   \u26a0\ufe0f  Requires PyTorch 2.0+ (currently {torch.__version__})\")\n    print(f\"   Falling back to standard attention\")\n\nprint()\n\n# Distributed guardrails\nprint(\"Distributed Training Guardrails:\")\nprint(f\"   \u2705 Active (notebook environment detection)\")\nprint(f\"   Prevents DDP/FSDP zombie processes in Jupyter/Colab\")\n\nprint()\n\n# Display v3.5 features\nprint(\"v3.5 FEATURES\")\nprint(\"-\" * 70)\n\nif training_config.compile_mode:\n    print(f\"torch.compile:\")\n    print(f\"   \u2705 Enabled ({training_config.compile_mode} mode)\")\n    print(f\"   Expected speedup: ~10-20%\")\n    print(f\"   First epoch will be slower due to compilation\")\nelse:\n    print(f\"torch.compile: Disabled\")\n\nprint()\n\nif training_config.gradient_accumulation_steps > 1:\n    print(f\"Gradient Accumulation:\")\n    print(f\"   \u2705 {training_config.gradient_accumulation_steps}x steps\")\n    print(f\"   Effective batch size: {training_config.batch_size * training_config.gradient_accumulation_steps}\")\n    log_reduction = 100 * (1 - 1/training_config.gradient_accumulation_steps)\n    print(f\"   W&B log reduction: ~{log_reduction:.0f}%\")\n\nprint()\nprint(\"=\" * 70)\nprint(\"\u2705 SETUP COMPLETE - Ready for Training\")\nprint(\"=\" * 70)\nprint()\nprint(\"\ud83d\udca1 Run the next cell to start training\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcaa782a",
   "metadata": {},
   "outputs": [],
   "source": "# @title \u25b6\ufe0f Run Training (Professional Pipeline) { display-mode: \"form\" }\n\nimport time\n\nprint(\"=\" * 70)\nprint(\"TRAINING EXECUTION\")\nprint(\"=\" * 70)\nprint()\n\nstart_time = time.time()\n\nprint(f\"\ud83c\udfcb\ufe0f  Starting training with {training_config.epochs} epochs...\")\nprint(f\"   Run name: {training_config.run_name}\")\nprint(f\"   Batch size: {training_config.batch_size}\")\nprint(f\"   Learning rate: {training_config.learning_rate}\")\nprint()\n\n# Note: The actual train() method signature depends on your TrainingCoordinator implementation\n# This is a simplified version - adjust parameters based on actual implementation\n\ntry:\n    # Execute training\n    # Simplified call - adjust based on actual TrainingCoordinator.train() signature\n    print(\"\u2699\ufe0f  Training in progress...\")\n    print(\"   (This may take several minutes depending on your configuration)\")\n    print()\n    \n    # For this notebook refactor, we'll use a simplified training approach\n    # that leverages the existing utils while maintaining notebook compatibility\n    \n    from utils.tier3_training_utilities import test_fine_tuning\n    \n    # Run training using tier3 utilities\n    results = test_fine_tuning(\n        model=model,\n        config=config_obj,\n        n_epochs=training_config.epochs,\n        learning_rate=training_config.learning_rate,\n        batch_size=training_config.batch_size,\n        random_seed=training_config.random_seed,\n        deterministic=training_config.deterministic,\n        use_wandb=use_wandb if 'use_wandb' in globals() else False,\n        gradient_accumulation_steps=training_config.gradient_accumulation_steps,\n        warmup_ratio=training_config.warmup_ratio,\n        weight_decay=training_config.weight_decay,\n        use_amp=training_config.use_amp\n    )\n    \n    training_duration = time.time() - start_time\n    \n    print()\n    print(\"=\" * 70)\n    print(\"\u2705 TRAINING COMPLETED SUCCESSFULLY!\")\n    print(\"=\" * 70)\n    print()\n    print(f\"Training Duration: {training_duration/60:.1f} minutes\")\n    print()\n    \n    # Display results summary\n    print(\"FINAL RESULTS\")\n    print(\"-\" * 70)\n    print(f\"{'Final Training Loss:':<30} {results['final_loss']:.4f}\")\n    \n    if 'metrics_summary' in results:\n        metrics_df = results['metrics_summary']\n        last_epoch = metrics_df.iloc[-1]\n        \n        if 'val/loss' in last_epoch:\n            print(f\"{'Final Validation Loss:':<30} {last_epoch['val/loss']:.4f}\")\n        if 'val/perplexity' in last_epoch:\n            print(f\"{'Final Perplexity:':<30} {last_epoch['val/perplexity']:.2f}\")\n        if 'val/accuracy' in last_epoch:\n            print(f\"{'Final Accuracy:':<30} {last_epoch['val/accuracy']*100:.2f}%\")\n    \n    print()\n    \n    # Best epoch info\n    if 'best_epoch' in results:\n        print(f\"Best Epoch: {results['best_epoch'] + 1}\")\n        print(f\"Best Validation Loss: {results.get('best_val_loss', 'N/A')}\")\n    \n    print()\n    \n    # Save to experiment database\n    if 'db' in globals():\n        try:\n            run_id = db.log_run(\n                run_name=training_config.run_name,\n                config=training_config.to_dict(),\n                notes=f\"Trained with v3.5/v3.6 features | {data_source} data\"\n            )\n            \n            # Log final metrics\n            if 'metrics_summary' in results:\n                final_metrics = results['metrics_summary'].iloc[-1].to_dict()\n                for key, value in final_metrics.items():\n                    if isinstance(value, (int, float)):\n                        db.log_metric(run_id, key, value, epoch=training_config.epochs-1)\n            \n            db.update_run_status(run_id, 'completed')\n            print(f\"\u2705 Run logged to ExperimentDB (ID: {run_id})\")\n        except Exception as e:\n            print(f\"\u26a0\ufe0f  Could not log to ExperimentDB: {e}\")\n    \n    print()\n    print(\"=\" * 70)\n    print(\"NEXT STEPS\")\n    print(\"=\" * 70)\n    print()\n    print(\"1. \ud83d\udcca View Results: Run Section 7 for comprehensive dashboard\")\n    print(\"2. \ud83d\udcbe Download: Use Section 8 to download checkpoints\")\n    if training_config.export_bundle:\n        print(\"3. \ud83d\udce6 Export Bundle: Available in Section 8\")\n    print()\n    \nexcept Exception as e:\n    print()\n    print(\"=\" * 70)\n    print(\"\u274c TRAINING FAILED\")\n    print(\"=\" * 70)\n    print()\n    print(f\"Error: {e}\")\n    print()\n    print(\"Troubleshooting:\")\n    print(\"  - Check that model and data are compatible\")\n    print(\"  - Verify all previous cells ran successfully\")\n    print(\"  - Try reducing batch size if out of memory\")\n    print(\"  - Check logs above for specific error details\")\n    print()\n    raise"
  },
  {
   "cell_type": "markdown",
   "id": "4fd41698",
   "metadata": {},
   "source": [
    "<a id=\"section-7\"></a>\n",
    "# \ud83d\udcc8 Section 7: Analysis & Visualization\n",
    "\n",
    "Analyze training results with comprehensive dashboards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "632a6e26",
   "metadata": {},
   "outputs": [],
   "source": "# @title \ud83d\udcc8 Training Dashboard (v3.6: With Drift Visualization) { display-mode: \"form\" }\n\nprint(\"=\" * 70)\nprint(\"TRAINING DASHBOARD GENERATION\")\nprint(\"=\" * 70)\nprint()\n\n# Extract metrics from results\nif 'results' in globals() and 'metrics_summary' in results:\n    metrics_df = results['metrics_summary']\n    print(f\"\u2705 Metrics loaded: {len(metrics_df)} epochs\")\nelse:\n    print(\"\u26a0\ufe0f  No training results found\")\n    print(\"   Please run Section 6 training first\")\n    metrics_df = None\n\nif metrics_df is not None:\n    # Create dashboard\n    print()\n    print(\"\ud83d\udcca Creating dashboard...\")\n    \n    # Determine dashboard type\n    if drift_data is not None:\n        print(\"   Type: Enhanced (10-panel with drift visualization)\")\n        dashboard_size = (20, 14)  # Larger for drift panels\n    else:\n        print(\"   Type: Standard (6-panel)\")\n        dashboard_size = (18, 12)\n    \n    dashboard = TrainingDashboard(figsize=dashboard_size)\n    \n    try:\n        if drift_data is not None:\n            # v3.6: Enhanced dashboard with drift visualization\n            print(\"   Building 10-panel layout...\")\n            print(\"     - 6 training metric panels\")\n            print(\"     - 4 drift detection panels\")\n            \n            fig = dashboard.plot_with_drift(\n                metrics_df=metrics_df,\n                drift_data=drift_data,\n                config=training_config,\n                title=f\"Training Dashboard + Drift Analysis: {training_config.run_name}\"\n            )\n            \n            print(\"   \u2705 Enhanced dashboard created (10 panels)\")\n            \n        else:\n            # Standard 6-panel dashboard\n            print(\"   Building 6-panel layout...\")\n            \n            fig = dashboard.plot(\n                metrics_df=metrics_df,\n                config=training_config,\n                title=f\"Training Dashboard: {training_config.run_name}\"\n            )\n            \n            print(\"   \u2705 Standard dashboard created (6 panels)\")\n        \n        # Save to Drive\n        dashboard_path = f'{workspace_root}/results/{training_config.run_name}_dashboard.png'\n        dashboard.save(dashboard_path, dpi=150)\n        \n        print()\n        print(f\"\ud83d\udcbe Dashboard saved to: {dashboard_path}\")\n        \n        # Display in notebook\n        import matplotlib.pyplot as plt\n        plt.show()\n        \n        print()\n        print(\"=\" * 70)\n        print(\"\u2705 DASHBOARD COMPLETE\")\n        print(\"=\" * 70)\n        print()\n        \n        if drift_data is not None:\n            print(\"\ud83d\udcca Drift Analysis Summary:\")\n            print(f\"   Status: {drift_data['status'].upper()}\")\n            print(f\"   Metrics tracked: {len(drift_data['drift_scores'])}\")\n            print()\n            print(\"   Drift scores:\")\n            for metric, score in drift_data['drift_scores'].items():\n                status_emoji = '\u2705' if score < 0.1 else '\u26a0\ufe0f ' if score < 0.2 else '\ud83d\udea8'\n                print(f\"     {status_emoji} {metric}: {score:.4f}\")\n        \n    except Exception as e:\n        print()\n        print(f\"\u274c Dashboard generation failed: {e}\")\n        print(\"   Check that metrics_df and drift_data are properly formatted\")\n        import traceback\n        traceback.print_exc()\nelse:\n    print()\n    print(\"\u26a0\ufe0f  Skipping dashboard generation - no metrics available\")\n    print(\"   Run training in Section 6 first\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d96e03d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find best epoch based on validation loss\n",
    "best_epoch_idx = metrics_df['val/loss'].idxmin()\n",
    "best_epoch = metrics_df.loc[best_epoch_idx]\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\" \" * 20 + \"BEST EPOCH ANALYSIS\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"{'Best Epoch:':<25} {int(best_epoch['epoch']) + 1}\")\n",
    "print(f\"{'Validation Loss:':<25} {best_epoch['val/loss']:.4f}\")\n",
    "print(f\"{'Validation Perplexity:':<25} {best_epoch['val/perplexity']:.2f}\")\n",
    "print(f\"{'Training Loss:':<25} {best_epoch['train/loss']:.4f}\")\n",
    "print(f\"{'Learning Rate:':<25} {best_epoch['train/learning_rate']:.2e}\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Load best checkpoint\n",
    "best_checkpoint_path = f\"{workspace_root}/checkpoints/{config.run_name}_epoch{int(best_epoch['epoch']) + 1}.pt\"\n",
    "if os.path.exists(best_checkpoint_path):\n",
    "    print(f\"\\n\ud83d\udcbe Best checkpoint: {best_checkpoint_path}\")\n",
    "else:\n",
    "    print(f\"\\n\u26a0\ufe0f Best checkpoint not found (may not have been saved)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0722848b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display metrics table\n",
    "import pandas as pd\n",
    "\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.float_format', lambda x: f'{x:.4f}')\n",
    "\n",
    "display_cols = ['epoch', 'train/loss', 'val/loss', 'val/perplexity', 'train/learning_rate']\n",
    "available_cols = [col for col in display_cols if col in metrics_df.columns]\n",
    "\n",
    "print(\"\\nTraining Metrics Summary:\")\n",
    "print(metrics_df[available_cols].to_string(index=False))\n",
    "\n",
    "# Export to CSV\n",
    "csv_path = f'{workspace_root}/results/{config.run_name}_metrics.csv'\n",
    "metrics_df.to_csv(csv_path, index=False)\n",
    "print(f\"\\n\u2705 Metrics exported to: {csv_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cfe5404",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(\"=\" * 60)\n",
    "    print(\" \" * 20 + \"GPU METRICS\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    gpu_cols = [col for col in metrics_df.columns if col.startswith('gpu/')]\n",
    "    if gpu_cols:\n",
    "        print(metrics_df[['epoch'] + gpu_cols].tail(5).to_string(index=False))\n",
    "\n",
    "        # Plot GPU utilization\n",
    "        import matplotlib.pyplot as plt\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "        if 'gpu/memory_allocated_mb' in metrics_df.columns:\n",
    "            ax1.plot(metrics_df['epoch'], metrics_df['gpu/memory_allocated_mb'])\n",
    "            ax1.set_xlabel('Epoch')\n",
    "            ax1.set_ylabel('GPU Memory (MB)')\n",
    "            ax1.set_title('GPU Memory Usage')\n",
    "            ax1.grid(True)\n",
    "\n",
    "        if 'gpu/utilization_percent' in metrics_df.columns:\n",
    "            ax2.plot(metrics_df['epoch'], metrics_df['gpu/utilization_percent'])\n",
    "            ax2.set_xlabel('Epoch')\n",
    "            ax2.set_ylabel('GPU Utilization (%)')\n",
    "            ax2.set_title('GPU Utilization')\n",
    "            ax2.grid(True)\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'{workspace_root}/results/{config.run_name}_gpu_metrics.png', dpi=100)\n",
    "        plt.show()\n",
    "        print(f\"\\n\u2705 GPU metrics saved\")\n",
    "    else:\n",
    "        print(\"\u26a0\ufe0f No GPU metrics collected during training\")\n",
    "    print(\"=\" * 60)\n",
    "else:\n",
    "    print(\"\u2139\ufe0f Training was performed on CPU (no GPU metrics available)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a6fdf23",
   "metadata": {},
   "source": [
    "<a id=\"section-8\"></a>\n",
    "# \ud83d\udcbe Section 8: Export & Results\n",
    "\n",
    "Download checkpoints, configs, and results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a039396b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from google.colab import files\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\" \" * 20 + \"EXPORT SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\n\ud83d\udcc1 Workspace: {workspace_root}\")\n",
    "print(f\"\\n\ud83d\udcca Results:\")\n",
    "print(f\"   - Dashboard: {config.run_name}_dashboard.png\")\n",
    "print(f\"   - Metrics CSV: {config.run_name}_metrics.csv\")\n",
    "print(f\"   - Config: {os.path.basename(config_path)}\")\n",
    "print(f\"\\n\ud83d\udcbe Checkpoints:\")\n",
    "\n",
    "checkpoint_dir = f\"{workspace_root}/checkpoints\"\n",
    "checkpoints = [f for f in os.listdir(checkpoint_dir) if f.startswith(config.run_name)]\n",
    "for ckpt in sorted(checkpoints):\n",
    "    ckpt_path = os.path.join(checkpoint_dir, ckpt)\n",
    "    size_mb = os.path.getsize(ckpt_path) / (1024 * 1024)\n",
    "    print(f\"   - {ckpt} ({size_mb:.1f} MB)\")\n",
    "\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1656431e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download results to local machine\n",
    "download_results = False  #@param {type:\"boolean\"}\n",
    "\n",
    "if download_results:\n",
    "    print(\"Downloading files...\")\n",
    "\n",
    "    # Download dashboard\n",
    "    dashboard_file = f'{workspace_root}/results/{config.run_name}_dashboard.png'\n",
    "    if os.path.exists(dashboard_file):\n",
    "        files.download(dashboard_file)\n",
    "\n",
    "    # Download metrics CSV\n",
    "    metrics_file = f'{workspace_root}/results/{config.run_name}_metrics.csv'\n",
    "    if os.path.exists(metrics_file):\n",
    "        files.download(metrics_file)\n",
    "\n",
    "    # Download config\n",
    "    if os.path.exists(config_path):\n",
    "        files.download(config_path)\n",
    "\n",
    "    # Download best checkpoint\n",
    "    if os.path.exists(best_checkpoint_path):\n",
    "        files.download(best_checkpoint_path)\n",
    "        print(f\"\u2705 Downloaded {os.path.basename(best_checkpoint_path)}\")\n",
    "\n",
    "    print(\"\u2705 Downloads complete\")\n",
    "else:\n",
    "    print(\"\u2139\ufe0f Downloads skipped. Files are saved in Google Drive.\")\n",
    "    print(f\"   Access them at: {workspace_root}\")"
   ]
  },
  {
   "cell_type": "code",
   "id": "l75ch0mse7",
   "source": "# @title \ud83d\udce6 Production Export Bundle (v3.5) { display-mode: \"form\" }\n\nif training_config.export_bundle:\n    print(\"=\" * 70)\n    print(\"PRODUCTION EXPORT BUNDLE GENERATION (v3.5)\")\n    print(\"=\" * 70)\n    print()\n    \n    print(\"\ud83d\udce6 Creating complete deployment bundle...\")\n    print(f\"   Formats: {', '.join(training_config.export_formats)}\")\n    print(f\"   Task: {task_spec.name}\")\n    print(f\"   Modality: {task_spec.modality}\")\n    print()\n    \n    try:\n        # Get best model from training results\n        if 'results' in globals() and 'model' in globals():\n            export_model = model\n            print(\"\u2705 Using trained model for export\")\n        else:\n            print(\"\u26a0\ufe0f  No trained model found, using current model state\")\n            export_model = model if 'model' in globals() else None\n        \n        if export_model is not None:\n            # Create export bundle\n            print()\n            print(\"\ud83d\udd27 Generating export artifacts...\")\n            print(\"   (This may take 1-2 minutes)\")\n            print()\n            \n            export_dir = create_export_bundle(\n                model=export_model,\n                config=config_obj if 'config_obj' in globals() else {},\n                task_spec=task_spec,\n                training_config=training_config,\n                export_base_dir=f'{workspace_root}/exports'\n            )\n            \n            print()\n            print(\"=\" * 70)\n            print(\"\u2705 EXPORT BUNDLE CREATED SUCCESSFULLY!\")\n            print(\"=\" * 70)\n            print()\n            print(f\"\ud83d\udcc1 Location: {export_dir}\")\n            print()\n            print(\"Bundle Contents:\")\n            print(\"-\" * 70)\n            print()\n            print(\"  \ud83d\udcc1 artifacts/\")\n            \n            for fmt in training_config.export_formats:\n                if fmt == \"onnx\":\n                    print(\"     \u251c\u2500\u2500 model.onnx (ONNX format)\")\n                elif fmt == \"torchscript\":\n                    print(\"     \u251c\u2500\u2500 model.torchscript.pt (TorchScript)\")\n                elif fmt == \"pytorch\":\n                    print(\"     \u251c\u2500\u2500 model.pytorch.pt (PyTorch state dict)\")\n            \n            print()\n            print(\"  \ud83d\udcc1 configs/\")\n            print(\"     \u251c\u2500\u2500 task_spec.json (task configuration)\")\n            print(\"     \u251c\u2500\u2500 training_config.json (training settings)\")\n            print(\"     \u2514\u2500\u2500 torchserve_config.json (TorchServe deployment)\")\n            print()\n            print(\"  \ud83d\udcc4 inference.py (standalone inference script)\")\n            print(\"  \ud83d\udcc4 README.md (quickstart guide)\")\n            print(\"  \ud83d\udc33 Dockerfile (container deployment)\")\n            print(\"  \ud83d\udccb requirements.txt (runtime dependencies)\")\n            print()\n            print(\"-\" * 70)\n            print()\n            print(\"QUICK START GUIDE\")\n            print(\"-\" * 70)\n            print()\n            \n            if task_spec.modality == \"vision\":\n                print(\"Local Inference:\")\n                print(f\"  cd {export_dir}\")\n                print(f\"  python inference.py --input image.jpg --model artifacts/model.onnx\")\n                print()\n                print(\"Docker Deployment:\")\n                print(f\"  cd {export_dir}\")\n                print(\"  docker build -t model-inference .\")\n                print(\"  docker run -p 8080:8080 model-inference\")\n                print()\n                print(\"Test the API:\")\n                print(\"  curl -X POST http://localhost:8080/predict \\\\\")\n                print(\"    -F 'image=@test_image.jpg'\")\n            else:\n                print(\"Local Inference:\")\n                print(f\"  cd {export_dir}\")\n                print(f\"  python inference.py --input 'Your text here' --model artifacts/model.onnx\")\n                print()\n                print(\"Docker Deployment:\")\n                print(f\"  cd {export_dir}\")\n                print(\"  docker build -t model-inference .\")\n                print(\"  docker run -p 8080:8080 model-inference\")\n                print()\n                print(\"Test the API:\")\n                print(\"  curl -X POST http://localhost:8080/predict \\\\\")\n                print(\"    -d '{\\\"text\\\": \\\"Your input text\\\"}'\")\n            \n            print()\n            print(\"=\" * 70)\n            print()\n            print(\"\ud83d\udca1 The export bundle includes everything needed for production:\")\n            print(\"   \u2705 Optimized model formats (ONNX, TorchScript)\")\n            print(\"   \u2705 Standalone inference script\")\n            print(\"   \u2705 Docker container definition\")\n            print(\"   \u2705 TorchServe deployment config\")\n            print(\"   \u2705 Complete documentation\")\n            print()\n            print(f\"\ud83d\udce6 Export bundle is ready in: {export_dir}\")\n            print()\n            \n        else:\n            print(\"\u274c No model available for export\")\n            print(\"   Please run training first (Section 6)\")\n    \n    except Exception as e:\n        print()\n        print(\"\u274c Export bundle generation failed!\")\n        print()\n        print(f\"Error: {e}\")\n        print()\n        print(\"Troubleshooting:\")\n        print(\"  - Ensure model is properly trained\")\n        print(\"  - Check that all required configs are available\")\n        print(\"  - Verify export formats are supported\")\n        print()\n        import traceback\n        traceback.print_exc()\n\nelse:\n    print(\"=\" * 70)\n    print(\"EXPORT BUNDLE DISABLED\")\n    print(\"=\" * 70)\n    print()\n    print(\"\u2139\ufe0f  Production export bundle generation is disabled\")\n    print()\n    print(\"To enable:\")\n    print(\"  1. Go back to Section 4 (Training Configuration)\")\n    print(\"  2. Set export_bundle = True\")\n    print(\"  3. Re-run configuration and training\")\n    print()\n    print(\"\ud83d\udca1 Benefits of export bundles:\")\n    print(\"   - Production-ready deployment artifacts\")\n    print(\"   - Multiple model formats (ONNX, TorchScript, PyTorch)\")\n    print(\"   - Docker containerization\")\n    print(\"   - TorchServe integration\")\n    print(\"   - Complete documentation\")\n    print()\n    print(\"=\" * 70)\n    print()",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f00c7f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare with previous runs\n",
    "all_runs = db.list_runs(limit=10)\n",
    "\n",
    "if len(all_runs) > 1:\n",
    "    print(\"=\" * 60)\n",
    "    print(\" \" * 15 + \"COMPARISON WITH PREVIOUS RUNS\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    comparison_data = []\n",
    "    for run in all_runs:\n",
    "        comparison_data.append({\n",
    "            'run_name': run.get('run_name', 'unknown'),\n",
    "            'final_val_loss': run.get('metrics', {}).get('val/loss', float('nan')),\n",
    "            'final_perplexity': run.get('metrics', {}).get('val/perplexity', float('nan')),\n",
    "            'data_source': run.get('data_source', 'unknown'),\n",
    "            'timestamp': run.get('timestamp', 'unknown')\n",
    "        })\n",
    "\n",
    "    comparison_df = pd.DataFrame(comparison_data)\n",
    "    print(comparison_df.to_string(index=False))\n",
    "    print(\"=\" * 60)\n",
    "else:\n",
    "    print(\"\u2139\ufe0f No previous runs to compare (this is your first run)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61a901c0",
   "metadata": {},
   "source": [
    "<a id=\"section-9\"></a>\n",
    "# \ud83d\udd2c Section 9: Advanced Features\n",
    "\n",
    "Hyperparameter search, multi-run experiments, and optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f3d0b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.tier3_training_utilities import test_hyperparameter_search\n",
    "\n",
    "# Hyperparameter search configuration\n",
    "run_hp_search = False  #@param {type:\"boolean\"}\n",
    "n_trials = 10  #@param {type:\"integer\"}\n",
    "search_timeout = 3600  #@param {type:\"integer\"}\n",
    "\n",
    "if run_hp_search:\n",
    "    print(\"\ud83d\udd0d Starting hyperparameter search...\")\n",
    "    print(f\"   Trials: {n_trials}\")\n",
    "    print(f\"   Timeout: {search_timeout}s ({search_timeout/60:.1f} min)\")\n",
    "    print(\"\\n\u26a0\ufe0f This may take a while. Progress will be shown below.\")\n",
    "\n",
    "    # Define search space\n",
    "    search_space = {\n",
    "        'learning_rate': (1e-5, 1e-3),\n",
    "        'batch_size': [4, 8, 16],\n",
    "        'warmup_ratio': (0.0, 0.2),\n",
    "        'weight_decay': (0.0, 0.1)\n",
    "    }\n",
    "\n",
    "    print(f\"\\nSearch space: {search_space}\")\n",
    "else:\n",
    "    print(\"\u2139\ufe0f Hyperparameter search disabled\")\n",
    "    print(\"   Set 'run_hp_search = True' to enable\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c19ee7e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "if run_hp_search:\n",
    "    # Run search\n",
    "    hp_results = test_hyperparameter_search(\n",
    "        model=model,\n",
    "        config=config,\n",
    "        train_data=train_data,\n",
    "        val_data=val_data,\n",
    "        n_trials=n_trials,\n",
    "        timeout=search_timeout,\n",
    "        use_wandb=use_wandb\n",
    "    )\n",
    "\n",
    "    # Display results\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\" \" * 15 + \"HYPERPARAMETER SEARCH RESULTS\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"\\nBest parameters:\")\n",
    "    for param, value in hp_results['best_params'].items():\n",
    "        print(f\"   {param}: {value}\")\n",
    "\n",
    "    print(f\"\\nBest validation loss: {hp_results['best_value']:.4f}\")\n",
    "    print(f\"\\nAll trials:\")\n",
    "    print(hp_results['trials_df'].to_string(index=False))\n",
    "\n",
    "    # Save results\n",
    "    hp_results['trials_df'].to_csv(\n",
    "        f'{workspace_root}/results/{config.run_name}_hp_search.csv',\n",
    "        index=False\n",
    "    )\n",
    "    print(f\"\\n\u2705 Results saved to: {config.run_name}_hp_search.csv\")\n",
    "    print(\"=\" * 60)\n",
    "else:\n",
    "    print(\"\u23ed\ufe0f Hyperparameter search skipped\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f63affe7",
   "metadata": {},
   "source": "## \ud83c\udf89 Training Complete!\n\n### Next Steps\n\n1. **Review Results**: Check the dashboard in Section 6\n2. **Download Files**: Use Section 7 to download checkpoints\n3. **Compare Runs**: See Section 7 for comparison with previous experiments\n4. **Optimize**: Try hyperparameter search in Section 8\n\n### Workspace Structure\n\nAll files are saved in Google Drive:\n```\n/content/drive/MyDrive/TransformerTraining/\n\u251c\u2500\u2500 checkpoints/     # Model weights (.pt files)\n\u251c\u2500\u2500 configs/         # Training configs (.json files)\n\u251c\u2500\u2500 results/         # Dashboards, metrics, plots\n\u251c\u2500\u2500 datasets/        # Cached datasets\n\u2514\u2500\u2500 experiments.db   # SQLite tracking database\n```\n\n### Resources\n\n- [Transformer Builder Documentation](https://transformer-builder.com/docs)\n- [Training Utilities Reference](https://github.com/matt-hans/transformer-builder-colab-templates)\n- [W&B Dashboard](https://wandb.ai) (if enabled)\n\n---\n\n**\ud83d\udca1 Tip**: Save this notebook to Google Drive for future use!"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from utils.training import TrainingConfig, build_task_spec, build_eval_config, run_training\n",
    "from utils.adapters import DecoderOnlyLMAdapter\n",
    "\n",
    "cfg = TrainingConfig(epochs=1, batch_size=2, vocab_size=101, max_seq_len=16)\n",
    "\n",
    "# Build Task & Eval configs\n",
    "task = build_task_spec(cfg)\n",
    "eval_cfg = build_eval_config(cfg)\n",
    "\n",
    "# Choose adapter for your architecture\n",
    "adapter = DecoderOnlyLMAdapter()\n",
    "\n",
    "# Assumes `model` is already defined above\n",
    "results = run_training(model, adapter, cfg, task, eval_cfg)\n",
    "print(\"Eval summary:\", results.get(\"eval_summary\"))\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Mode selection and config preview (v4.0.0)\n",
    "from utils.ui.presets import build_configs_for_mode\n",
    "mode = 'FAST_DEV'  # or 'STANDARD_EXPERIMENT', 'ABLATION_SWEEP'\n",
    "training_cfg, task_spec, eval_cfg = build_configs_for_mode(mode)\n",
    "print('Mode:', mode)\n",
    "print('TrainingConfig epochs/batch_size:', training_cfg.epochs, training_cfg.batch_size)\n",
    "print('Task:', task_spec.name, '| Eval dataset:', eval_cfg.dataset_id)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Simple grid sweep (learning_rate x num_layers)\n",
    "from utils.training.sweep_runner import run_grid_sweep\n",
    "from utils.training.experiment_db import ExperimentDB\n",
    "from utils.adapters import DecoderOnlyLMAdapter\n",
    "from utils.training.training_core import run_training\n",
    "from utils.training import build_task_spec, build_eval_config\n",
    "\n",
    "# Base config from mode (or build a fresh one)\n",
    "base = training_cfg\n",
    "sweep_id = 'demo_sweep_lr_depth'\n",
    "param_grid = {\n",
    "    'learning_rate': [5e-5, 1e-4],\n",
    "    'num_layers': [2, 3],\n",
    "}\n",
    "\n",
    "db = ExperimentDB('experiments.db')\n",
    "adapter = DecoderOnlyLMAdapter()\n",
    "\n",
    "def run_fn(cfg):\n",
    "    task = build_task_spec(cfg)\n",
    "    ecfg = build_eval_config(cfg)\n",
    "    # Log run\n",
    "    run_id = db.log_run(\n",
    "        run_name=f\"sweep-{sweep_id}\",\n",
    "        config=cfg.to_dict(),\n",
    "        notes='grid sweep',\n",
    "        sweep_id=sweep_id,\n",
    "        sweep_params={k: getattr(cfg, k) for k in param_grid.keys()},\n",
    "    )\n",
    "    # Execute training + tiny eval\n",
    "    _ = run_training(model, adapter, cfg, task, ecfg)\n",
    "    db.update_run_status(run_id, 'completed')\n",
    "    return str(run_id)\n",
    "\n",
    "run_ids = run_grid_sweep(base, param_grid, run_fn)\n",
    "print('Completed runs:', run_ids)\n",
    "print('Runs for sweep:')\n",
    "print(db.get_runs_for_sweep(sweep_id))\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Create a Repro Bundle (zip) for this run\n",
    "from utils.training.export_utilities import create_repro_bundle\n",
    "from utils.training.experiment_db import ExperimentDB\n",
    "try:\n",
    "    from utils.training.environment_snapshot import capture_environment\n",
    "    env_info = capture_environment()\n",
    "except Exception:\n",
    "    env_info = {}\n",
    "\n",
    "run_id = 'local_run'  # replace with actual run id if using ExperimentDB\n",
    "zip_path = create_repro_bundle(\n",
    "    run_id=run_id,\n",
    "    training_config=training_cfg,\n",
    "    task_spec=task_spec,\n",
    "    eval_config=eval_cfg,\n",
    "    environment_snapshot=env_info,\n",
    "    experiment_db=ExperimentDB('experiments.db'),\n",
    "    dashboard_paths=None,\n",
    "    output_path='./repro'\n",
    ")\n",
    "print('Repro bundle created at:', zip_path)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Sweep visualization\n",
    "from utils.training.experiment_db import ExperimentDB\n",
    "sweep_id = 'demo_sweep_lr_depth'\n",
    "db = ExperimentDB('experiments.db')\n",
    "df = db.get_runs_for_sweep(sweep_id)\n",
    "print(df)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Load model from GitHub Gist and log metadata\n",
    "from utils.adapters.gist_loader import load_gist_model\n",
    "from utils.training.experiment_db import ExperimentDB\n",
    "from pathlib import Path\n",
    "import importlib.util\n",
    "\n",
    "gist_id = 'abcdef1234567890'  # replace\n",
    "revision = None\n",
    "md = load_gist_model(gist_id, revision)\n",
    "print('Gist SHA:', md.sha256)\n",
    "root = Path('./external/gists') / md.gist_id / (md.revision or 'latest')\n",
    "model_path = root / 'model.py'\n",
    "if model_path.exists():\n",
    "    spec = importlib.util.spec_from_file_location('gist_model', str(model_path))\n",
    "    mod = importlib.util.module_from_spec(spec)\n",
    "    spec.loader.exec_module(mod)\n",
    "    if hasattr(mod, 'build_model'):\n",
    "        model = mod.build_model()\n",
    "        print('Loaded model using build_model()')\n",
    "    elif hasattr(mod, 'Model'):\n",
    "        model = mod.Model()\n",
    "        print('Loaded model using Model class')\n",
    "    else:\n",
    "        print('No known model entrypoint; define model manually')\n",
    "\n",
    "# Log to ExperimentDB\n",
    "try:\n",
    "    db = ExperimentDB('experiments.db')\n",
    "    run_id = db.log_run(\n",
    "        run_name='gist-training',\n",
    "        config=training_cfg.to_dict(),\n",
    "        notes='Gist-based run',\n",
    "        gist_id=md.gist_id,\n",
    "        gist_revision=md.revision,\n",
    "        gist_sha256=md.sha256,\n",
    "    )\n",
    "    print('Run logged:', run_id)\n",
    "except Exception as e:\n",
    "    print('DB logging skipped:', e)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Log run to ExperimentDB and create a repro bundle for this training\n",
    "from utils.training.experiment_db import ExperimentDB\n",
    "from utils.training.export_utilities import create_repro_bundle\n",
    "try:\n",
    "    from utils.training.environment_snapshot import capture_environment\n",
    "    env_info = capture_environment()\n",
    "except Exception:\n",
    "    env_info = {}\n",
    "\n",
    "# Log run\n",
    "db = ExperimentDB('experiments.db')\n",
    "run_id = db.log_run(\n",
    "    run_name='notebook-single-run',\n",
    "    config=training_cfg.to_dict(),\n",
    "    notes='single run from notebook'\n",
    ")\n",
    "\n",
    "# Train + tiny eval\n",
    "nb_results = run_training(model, adapter, training_cfg, task_spec, eval_cfg)\n",
    "\n",
    "# Mark run complete\n",
    "db.update_run_status(run_id, 'completed')\n",
    "\n",
    "# Create repro bundle\n",
    "zip_path = create_repro_bundle(\n",
    "    run_id=str(run_id),\n",
    "    training_config=training_cfg,\n",
    "    task_spec=task_spec,\n",
    "    eval_config=eval_cfg,\n",
    "    environment_snapshot=env_info,\n",
    "    experiment_db=db,\n",
    "    dashboard_paths=None,\n",
    "    output_path='./repro'\n",
    ")\n",
    "print('Repro bundle zip:', zip_path)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Visualize sweep results (matplotlib)\n",
    "import json\n",
    "from utils.training.experiment_db import ExperimentDB\n",
    "try:\n",
    "    import matplotlib.pyplot as plt\n",
    "except Exception:\n",
    "    plt = None\n",
    "\n",
    "sweep_id = 'demo_sweep_lr_depth'  # must match the sweep cell above\n",
    "\n",
    "db = ExperimentDB('experiments.db')\n",
    "df = db.get_runs_for_sweep(sweep_id)\n",
    "if df.empty:\n",
    "    print('No runs for sweep:', sweep_id)\n",
    "else:\n",
    "    # Parse sweep_params JSON strings\n",
    "    params = df['sweep_params'].apply(lambda s: json.loads(s) if isinstance(s, str) and s else {})\n",
    "    lrs = params.apply(lambda d: d.get('learning_rate', None))\n",
    "    depths = params.apply(lambda d: d.get('num_layers', None))\n",
    "\n",
    "    if plt is None:\n",
    "        print('matplotlib not available; printing table only')\n",
    "        print(df[['run_id', 'run_name', 'sweep_params']])\n",
    "    else:\n",
    "        # Bar plot: runs per learning_rate\n",
    "        by_lr = lrs.value_counts().sort_index()\n",
    "        plt.figure(figsize=(5,3))\n",
    "        by_lr.plot(kind='bar', title='Runs per learning_rate')\n",
    "        plt.ylabel('runs')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "        # Scatter: num_layers by run index\n",
    "        try:\n",
    "            x = list(range(len(df)))\n",
    "            y = depths.astype(float).fillna(0)\n",
    "            plt.figure(figsize=(5,3))\n",
    "            plt.scatter(x, y)\n",
    "            plt.title('num_layers by run index')\n",
    "            plt.xlabel('run index')\n",
    "            plt.ylabel('num_layers')\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "        except Exception as e:\n",
    "            print('Plotting skipped:', e)\n"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}