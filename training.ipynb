{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e697c2b",
   "metadata": {},
   "source": [
    "# \ud83d\ude80 Transformer Training & Fine-Tuning Notebook\n",
    "\n",
    "**Professional ML Training Environment** for transformer models exported from [Transformer Builder](https://transformer-builder.com).\n",
    "\n",
    "## Quick Start Modes\n",
    "\n",
    "| Mode | Epochs | Time | Use Case |\n",
    "|------|--------|------|----------|\n",
    "| **\u26a1 Fast** | 3 | ~5 min | Quick validation |\n",
    "| **\u2696\ufe0f Balanced** | 10 | ~15 min | Development |\n",
    "| **\ud83d\udc8e Quality** | 20 | ~45 min | Production |\n",
    "\n",
    "## Features\n",
    "- \u2705 5 Data Sources (HuggingFace, Drive, Upload, Local, Synthetic)\n",
    "- \u2705 Live Training Visualization\n",
    "- \u2705 Google Drive Checkpoints\n",
    "- \u2705 W&B + Local SQLite Tracking\n",
    "- \u2705 Hyperparameter Search\n",
    "- \u2705 Export & Comparison Tools\n",
    "\n",
    "**\ud83d\udccc Tip**: Run all cells in order for best results. Adjust hyperparameters in Section 3."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aef71373",
   "metadata": {},
   "source": [
    "## \ud83d\udccb Table of Contents\n",
    "\n",
    "1. [Section 0: Quick Start](#section-0) \u2190 You are here\n",
    "2. [Section 1: Setup & Drive Workspace](#section-1) (2 min)\n",
    "3. [Section 2: Model Loading](#section-2) (Load custom or example model)\n",
    "4. [Section 3: Data Loading](#section-3) (5 sources)\n",
    "5. [Section 4: Training Configuration](#section-4) (Hyperparameters)\n",
    "6. [Section 5: W&B Tracking Setup](#section-5) (Optional)\n",
    "7. [Section 6: Training Loop](#section-6) (Main training)\n",
    "8. [Section 7: Analysis & Visualization](#section-7) (Dashboards)\n",
    "9. [Section 8: Export & Results](#section-8) (Download checkpoints)\n",
    "10. [Section 9: Advanced Features](#section-9) (Hyperparameter search)\n",
    "\n",
    "\u23f1\ufe0f **Total Time**: ~20-60 minutes depending on mode\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "410215b4",
   "metadata": {},
   "source": [
    "## \ud83d\udce6 Requirements\n",
    "\n",
    "This notebook requires:\n",
    "- Python >= 3.10\n",
    "- PyTorch (pre-installed in Colab)\n",
    "- Transformer Builder utilities (auto-downloaded)\n",
    "\n",
    "**GPU Recommended** but not required. Training will auto-detect and use GPU if available.\n",
    "\n",
    "---\n",
    "<a id=\"section-1\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01c2f932",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install training dependencies\n",
    "!pip install -q -r https://raw.githubusercontent.com/matt-hans/transformer-builder-colab-templates/main/requirements-training.txt\n",
    "\n",
    "# Check for Flash Attention support (PyTorch 2.0+)\n",
    "import torch\n",
    "print(\"\u2705 Dependencies installed\")\n",
    "print(f\"   PyTorch version: {torch.__version__}\")\n",
    "\n",
    "if torch.__version__ >= \"2.0.0\":\n",
    "    print(\"   \u2705 PyTorch 2.0+ detected - Flash Attention support available\")\n",
    "    if torch.cuda.is_available():\n",
    "        print(\"   \u2705 CUDA available - Flash Attention will be enabled automatically\")\n",
    "    else:\n",
    "        print(\"   \u26a0\ufe0f  CPU only - Flash Attention requires CUDA (GPU)\")\n",
    "else:\n",
    "    print(\"   \u26a0\ufe0f  PyTorch < 2.0 - Flash Attention will be disabled\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "676a4b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "print(\"\ud83d\udce5 Downloading training utilities...\")\n",
    "\n",
    "# Remove old utils directory if exists\n",
    "!rm -rf utils/\n",
    "\n",
    "# Download complete utils package from GitHub\n",
    "!git clone --depth 1 --branch main https://github.com/matt-hans/transformer-builder-colab-templates.git temp_repo 2>/dev/null\n",
    "\n",
    "# Copy utils directory\n",
    "!cp -r temp_repo/utils ./\n",
    "\n",
    "# Cleanup\n",
    "!rm -rf temp_repo\n",
    "\n",
    "# Clear Python import cache to ensure fresh imports\n",
    "import sys\n",
    "modules_to_clear = [k for k in sys.modules.keys() if k.startswith('utils')]\n",
    "for module in modules_to_clear:\n",
    "    del sys.modules[module]\n",
    "\n",
    "if modules_to_clear:\n",
    "    print(f\"   \ud83d\udd04 Cleared {len(modules_to_clear)} cached modules\")\n",
    "\n",
    "# Verify package structure\n",
    "utils_path = os.path.join(os.getcwd(), 'utils')\n",
    "if os.path.exists(utils_path):\n",
    "    print(f\"\u2705 Utils package downloaded\")\n",
    "    \n",
    "    # Verify Git commit (for debugging sync issues)\n",
    "    import subprocess\n",
    "    try:\n",
    "        commit_hash = subprocess.check_output(\n",
    "            [\"git\", \"-C\", utils_path, \"rev-parse\", \"--short\", \"HEAD\"],\n",
    "            stderr=subprocess.DEVNULL\n",
    "        ).decode().strip()\n",
    "        print(f\"   Git commit: {commit_hash}\")\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    \n",
    "    # Verify training subdirectory\n",
    "    training_path = os.path.join(utils_path, 'training')\n",
    "    if os.path.exists(training_path):\n",
    "        training_modules = [f for f in os.listdir(training_path) if f.endswith('.py')]\n",
    "        print(f\"\u2705 Training utilities: {len(training_modules)} modules found\")\n",
    "        \n",
    "        # Verify engine subdirectory exists\n",
    "        engine_path = os.path.join(training_path, 'engine')\n",
    "        if os.path.exists(engine_path):\n",
    "            engine_modules = [f for f in os.listdir(engine_path) if f.endswith('.py')]\n",
    "            print(f\"\u2705 Engine modules: {len(engine_modules)} components found\")\n",
    "else:\n",
    "    print(\"\u274c Failed to download utils package\")\n",
    "    raise RuntimeError(\"Could not download training utilities\")\n",
    "\n",
    "print(\"\\n\ud83d\udd0d Verifying download...\")\n",
    "\n",
    "# Check critical modules exist (ACTUAL ARCHITECTURE)\n",
    "required_modules = [\n",
    "    'utils/__init__.py',\n",
    "    'utils/training/__init__.py',\n",
    "    'utils/training/task_spec.py',\n",
    "    'utils/training/training_config.py',\n",
    "    'utils/training/metrics_tracker.py',\n",
    "    'utils/training/drift_metrics.py',\n",
    "    'utils/training/dashboard.py',\n",
    "    'utils/training/engine/__init__.py',\n",
    "    'utils/training/engine/trainer.py',\n",
    "    'utils/training/engine/loop.py',              # Actual file name\n",
    "    'utils/training/engine/checkpoint.py',\n",
    "    'utils/training/engine/loss.py',\n",
    "    'utils/training/engine/gradient_monitor.py',\n",
    "    'utils/training/engine/gradient_accumulator.py',\n",
    "    'utils/training/engine/data.py',\n",
    "    'utils/training/engine/metrics.py',\n",
    "]\n",
    "\n",
    "missing = []\n",
    "for module in required_modules:\n",
    "    if not os.path.exists(module):\n",
    "        missing.append(module)\n",
    "\n",
    "if missing:\n",
    "    print(\"\u274c Download incomplete! Missing modules:\")\n",
    "    for m in missing:\n",
    "        print(f\"   - {m}\")\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"FALLBACK INSTRUCTIONS\")\n",
    "    print(\"=\"*70)\n",
    "    print(\"\\nManual download steps:\")\n",
    "    print(\"1. Run in a new cell:\")\n",
    "    print(\"   !git clone https://github.com/matt-hans/transformer-builder-colab-templates.git\")\n",
    "    print(\"   !cp -r transformer-builder-colab-templates/utils ./\")\n",
    "    print(\"   !rm -rf transformer-builder-colab-templates\")\n",
    "    print(\"\\n2. Re-run this cell to verify\")\n",
    "    raise RuntimeError(\"Utils package download failed\")\n",
    "\n",
    "print(\"\u2705 All required modules verified\")\n",
    "print(\"   Modular training engine ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7ea13e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title \ud83d\udcbe Storage Configuration { display-mode: \"form\" }\n",
    "\n",
    "from google.colab import drive\n",
    "import os\n",
    "\n",
    "# Storage option (user can choose)\n",
    "storage_type = \"Google Drive\"  #@param [\"Google Drive\", \"Local (session only)\"]\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"STORAGE CONFIGURATION\")\n",
    "print(\"=\" * 70)\n",
    "print()\n",
    "\n",
    "workspace_root = None\n",
    "\n",
    "if storage_type == \"Google Drive\":\n",
    "    print(\"\ud83d\udcc2 Attempting to mount Google Drive...\")\n",
    "    print()\n",
    "    \n",
    "    try:\n",
    "        # Try to mount Google Drive\n",
    "        drive.mount('/content/drive', force_remount=False)\n",
    "        \n",
    "        # Create workspace folders on Drive\n",
    "        workspace_root = '/content/drive/MyDrive/TransformerTraining'\n",
    "        os.makedirs(f'{workspace_root}/checkpoints', exist_ok=True)\n",
    "        os.makedirs(f'{workspace_root}/configs', exist_ok=True)\n",
    "        os.makedirs(f'{workspace_root}/results', exist_ok=True)\n",
    "        os.makedirs(f'{workspace_root}/datasets', exist_ok=True)\n",
    "        \n",
    "        print(\"\u2705 Google Drive mounted successfully!\")\n",
    "        print(f\"\u2705 Workspace created at: {workspace_root}\")\n",
    "        print()\n",
    "        print(\"\ud83d\udcc1 Directory structure:\")\n",
    "        print(f\"   \ud83d\udcc1 checkpoints/ - Saved model weights\")\n",
    "        print(f\"   \ud83d\udcc1 configs/ - Training configurations\")\n",
    "        print(f\"   \ud83d\udcc1 results/ - Metrics, plots, dashboards\")\n",
    "        print(f\"   \ud83d\udcc1 datasets/ - Cached datasets\")\n",
    "        print()\n",
    "        print(\"\ud83d\udca1 Benefits:\")\n",
    "        print(\"   \u2022 Files persist across sessions\")\n",
    "        print(\"   \u2022 Access from any device\")\n",
    "        print(\"   \u2022 Automatic backup\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(\"\u274c Google Drive mount failed!\")\n",
    "        print()\n",
    "        print(f\"Error: {e}\")\n",
    "        print()\n",
    "        print(\"=\" * 70)\n",
    "        print(\"TROUBLESHOOTING\")\n",
    "        print(\"=\" * 70)\n",
    "        print()\n",
    "        print(\"Common solutions:\")\n",
    "        print(\"  1. Click the authentication link that appears above\")\n",
    "        print(\"  2. Sign in with your Google account\")\n",
    "        print(\"  3. Grant permissions to access Google Drive\")\n",
    "        print(\"  4. If in a corporate environment, check with IT\")\n",
    "        print()\n",
    "        print(\"=\" * 70)\n",
    "        print(\"FALLBACK: Using local storage\")\n",
    "        print(\"=\" * 70)\n",
    "        print()\n",
    "        \n",
    "        # Fallback to local storage\n",
    "        workspace_root = '/content/workspace'\n",
    "        os.makedirs(f'{workspace_root}/checkpoints', exist_ok=True)\n",
    "        os.makedirs(f'{workspace_root}/configs', exist_ok=True)\n",
    "        os.makedirs(f'{workspace_root}/results', exist_ok=True)\n",
    "        os.makedirs(f'{workspace_root}/datasets', exist_ok=True)\n",
    "        \n",
    "        print(f\"\u2705 Local workspace created at: {workspace_root}\")\n",
    "        print()\n",
    "        print(\"\u26a0\ufe0f  IMPORTANT: Local storage limitations:\")\n",
    "        print(\"   \u2022 Files will be DELETED when runtime ends\")\n",
    "        print(\"   \u2022 Maximum 12-hour session lifetime\")\n",
    "        print(\"   \u2022 Use 'Download results' option before session ends\")\n",
    "\n",
    "else:\n",
    "    # User explicitly chose local storage\n",
    "    print(\"\ud83d\udcc2 Using local storage (session only)...\")\n",
    "    print()\n",
    "    \n",
    "    workspace_root = '/content/workspace'\n",
    "    os.makedirs(f'{workspace_root}/checkpoints', exist_ok=True)\n",
    "    os.makedirs(f'{workspace_root}/configs', exist_ok=True)\n",
    "    os.makedirs(f'{workspace_root}/results', exist_ok=True)\n",
    "    os.makedirs(f'{workspace_root}/datasets', exist_ok=True)\n",
    "    \n",
    "    print(f\"\u2705 Local workspace created at: {workspace_root}\")\n",
    "    print()\n",
    "    print(\"\ud83d\udcc1 Directory structure:\")\n",
    "    print(f\"   \ud83d\udcc1 checkpoints/ - Saved model weights\")\n",
    "    print(f\"   \ud83d\udcc1 configs/ - Training configurations\")\n",
    "    print(f\"   \ud83d\udcc1 results/ - Metrics, plots, dashboards\")\n",
    "    print(f\"   \ud83d\udcc1 datasets/ - Cached datasets\")\n",
    "    print()\n",
    "    print(\"\u26a0\ufe0f  IMPORTANT: Local storage limitations:\")\n",
    "    print(\"   \u2022 Files will be DELETED when runtime ends\")\n",
    "    print(\"   \u2022 Maximum 12-hour session lifetime\")\n",
    "    print(\"   \u2022 Use Section 8 'Download results' to save locally\")\n",
    "    print()\n",
    "    print(\"\ud83d\udca1 Tip: Switch to 'Google Drive' above for persistent storage\")\n",
    "\n",
    "print()\n",
    "print(\"=\" * 70)\n",
    "print(\"\u2705 STORAGE READY\")\n",
    "print(\"=\" * 70)\n",
    "print()\n",
    "print(f\"Workspace: {workspace_root}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37c65122",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.training.experiment_db import ExperimentDB\n",
    "\n",
    "# Initialize local SQLite tracking (backup to W&B)\n",
    "db = ExperimentDB(f'{workspace_root}/experiments.db')\n",
    "\n",
    "print(\"\u2705 Experiment database initialized\")\n",
    "print(f\"   Database: {workspace_root}/experiments.db\")\n",
    "print(f\"   Recent runs:\")\n",
    "recent_runs = db.list_runs(limit=5)\n",
    "if not recent_runs.empty:\n",
    "    print(recent_runs)\n",
    "else:\n",
    "    print(\"   (No previous runs found)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df8c4bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title \ud83d\udd0d Prerequisite Validation { display-mode: \"form\" }\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"PREREQUISITE VALIDATION\")\n",
    "print(\"=\"*70)\n",
    "print()\n",
    "\n",
    "validation_passed = True\n",
    "errors = []\n",
    "\n",
    "# Check 1: Utils package exists\n",
    "print(\"1/4 Checking utils package...\")\n",
    "if not os.path.exists('utils'):\n",
    "    errors.append(\"Utils package not found. Run Section 1 setup cells first.\")\n",
    "    validation_passed = False\n",
    "else:\n",
    "    print(\"   \u2705 Utils directory exists\")\n",
    "\n",
    "# Check 2: Critical modules present\n",
    "print(\"2/4 Checking training modules...\")\n",
    "required_files = [\n",
    "    'utils/training/task_spec.py',\n",
    "    'utils/training/training_config.py',\n",
    "    'utils/training/training_core.py',\n",
    "]\n",
    "missing_files = [f for f in required_files if not os.path.exists(f)]\n",
    "if missing_files:\n",
    "    errors.append(f\"Missing training modules: {', '.join(missing_files)}\")\n",
    "    validation_passed = False\n",
    "else:\n",
    "    print(\"   \u2705 All training modules present\")\n",
    "\n",
    "# Check 3: Python can import utils\n",
    "print(\"3/4 Testing imports...\")\n",
    "try:\n",
    "    import sys\n",
    "    if '.' not in sys.path:\n",
    "        sys.path.insert(0, '.')\n",
    "    \n",
    "    from utils.training.task_spec import TaskSpec\n",
    "    from utils.training.training_config import TrainingConfig\n",
    "    print(\"   \u2705 Core imports successful\")\n",
    "except ImportError as e:\n",
    "    errors.append(f\"Import test failed: {e}\")\n",
    "    validation_passed = False\n",
    "\n",
    "# Check 4: Workspace configured\n",
    "print(\"4/4 Checking workspace...\")\n",
    "if 'workspace_root' not in globals() or workspace_root is None:\n",
    "    errors.append(\"Workspace not configured. Run Section 1 storage setup first.\")\n",
    "    validation_passed = False\n",
    "else:\n",
    "    print(f\"   \u2705 Workspace: {workspace_root}\")\n",
    "\n",
    "print()\n",
    "if validation_passed:\n",
    "    print(\"=\"*70)\n",
    "    print(\"\u2705 ALL PREREQUISITES MET\")\n",
    "    print(\"=\"*70)\n",
    "    print(\"\\n\u2728 Ready to proceed with training setup\")\n",
    "else:\n",
    "    print(\"=\"*70)\n",
    "    print(\"\u274c VALIDATION FAILED\")\n",
    "    print(\"=\"*70)\n",
    "    print(\"\\nErrors found:\")\n",
    "    for i, err in enumerate(errors, 1):\n",
    "        print(f\"   {i}. {err}\")\n",
    "    print(\"\\n\ud83d\udcdd Resolution steps:\")\n",
    "    print(\"   1. Restart runtime: Runtime \u2192 Restart runtime\")\n",
    "    print(\"   2. Run all cells in Section 1 (Setup & Drive Workspace) in order\")\n",
    "    print(\"   3. Wait for each cell to complete before proceeding\")\n",
    "    print(\"   4. Re-run this validation cell\")\n",
    "    raise RuntimeError(\"Prerequisites not met. See errors above.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "kp5zpcfdwn9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import v3.6 training infrastructure\n",
    "\n",
    "# Ensure path is set\n",
    "import sys\n",
    "if '.' not in sys.path:\n",
    "    sys.path.insert(0, '.')\n",
    "\n",
    "print(\"\ud83d\udce6 Loading training infrastructure (v3.6)...\")\n",
    "\n",
    "try:\n",
    "    # Core training engine\n",
    "    from utils.training.engine.trainer import Trainer\n",
    "    from utils.training.engine.loop import TrainingLoop, ValidationLoop\n",
    "\n",
    "    # Core training components\n",
    "    from utils.training.training_config import TrainingConfig, TrainingConfigBuilder\n",
    "    from utils.training.task_spec import TaskSpec\n",
    "    from utils.training.metrics_tracker import MetricsTracker\n",
    "    from utils.training.experiment_db import ExperimentDB\n",
    "    from utils.training.training_core import TrainingCoordinator\n",
    "\n",
    "    # v3.6 features\n",
    "    from utils.training.drift_metrics import compute_dataset_profile, compare_profiles\n",
    "    from utils.training.dashboard import TrainingDashboard\n",
    "\n",
    "    # v3.5 features\n",
    "    from utils.training.export_utilities import create_export_bundle\n",
    "\n",
    "    # Model adapters\n",
    "    from utils.adapters.model_adapter import UniversalModelAdapter, FlashAttentionWrapper\n",
    "\n",
    "    # Data handling\n",
    "    from utils.training.engine.data import UniversalDataModule\n",
    "    from utils.tokenization.data_module import SimpleDataModule\n",
    "\n",
    "    # VALIDATE: All required classes are imported\n",
    "    required_classes = {\n",
    "        # Training engine\n",
    "        'Trainer': Trainer,\n",
    "        'TrainingLoop': TrainingLoop,\n",
    "        'ValidationLoop': ValidationLoop,\n",
    "        \n",
    "        # Configuration\n",
    "        'TrainingConfig': TrainingConfig,\n",
    "        'TrainingConfigBuilder': TrainingConfigBuilder,\n",
    "        'TaskSpec': TaskSpec,\n",
    "        \n",
    "        # Utilities\n",
    "        'MetricsTracker': MetricsTracker,\n",
    "        'ExperimentDB': ExperimentDB,\n",
    "        'TrainingCoordinator': TrainingCoordinator,\n",
    "        \n",
    "        # Data modules\n",
    "        'SimpleDataModule': SimpleDataModule,\n",
    "        'UniversalDataModule': UniversalDataModule,\n",
    "        \n",
    "        # Adapters\n",
    "        'UniversalModelAdapter': UniversalModelAdapter,\n",
    "        'FlashAttentionWrapper': FlashAttentionWrapper,\n",
    "        \n",
    "        # Analysis\n",
    "        'TrainingDashboard': TrainingDashboard,\n",
    "    }\n",
    "\n",
    "    missing = [name for name, cls in required_classes.items() if cls is None]\n",
    "    if missing:\n",
    "        raise ImportError(\n",
    "            f\"\u274c Missing required classes: {', '.join(missing)}\\n\"\n",
    "            f\"   Check that all dependencies are installed (run Cell 1)\\n\"\n",
    "            f\"   Re-run this cell after fixing dependencies\"\n",
    "        )\n",
    "\n",
    "    print(\"\u2705 Training infrastructure loaded\")\n",
    "    print(f\"   Validated: {len(required_classes)} classes imported successfully\")\n",
    "    print()\n",
    "    print(\"\ud83d\udccb Available Features:\")\n",
    "    print(\"   Core Engine:\")\n",
    "    print(\"     \u2022 Trainer - Complete training orchestration\")\n",
    "    print(\"     \u2022 TrainingLoop/ValidationLoop - Epoch execution\")\n",
    "    print(\"     \u2022 TrainingCoordinator - Legacy Lightning-based training\")\n",
    "    print(\"     \u2022 TrainingConfig - Versioned configuration system\")\n",
    "    print(\"     \u2022 TaskSpec - Modality-aware task definitions\")\n",
    "    print()\n",
    "    print(\"   v3.5 Features:\")\n",
    "    print(\"     \u2022 torch.compile integration (10-20% speedup)\")\n",
    "    print(\"     \u2022 VisionDataCollator (auto-selected for vision tasks)\")\n",
    "    print(\"     \u2022 Gradient accumulation tracking (75% log reduction)\")\n",
    "    print(\"     \u2022 Export bundle generation (production artifacts)\")\n",
    "    print()\n",
    "    print(\"   v3.6 Features:\")\n",
    "    print(\"     \u2022 Distributed training guardrails (notebook safety)\")\n",
    "    print(\"     \u2022 Drift visualization dashboard (4-panel analysis)\")\n",
    "    print(\"     \u2022 Flash Attention support (2-4x speedup)\")\n",
    "    print()\n",
    "    print(\"   Data Handling:\")\n",
    "    print(\"     \u2022 UniversalDataModule - Framework-agnostic data loading (v3.6 engine)\")\n",
    "    print(\"     \u2022 SimpleDataModule - PyTorch Lightning wrapper (pre-tokenized data)\")\n",
    "    print()\n",
    "    print(\"   Training Patterns:\")\n",
    "    print(\"     \u2022 Modern API: Use Trainer for new code\")\n",
    "    print(\"     \u2022 Legacy API: TrainingCoordinator for Lightning compatibility\")\n",
    "\n",
    "except ImportError as e:\n",
    "    print(\"\u274c Failed to import training infrastructure!\")\n",
    "    print(f\"\\nError: {e}\")\n",
    "    print(\"\\nTroubleshooting:\")\n",
    "    print(\"  1. Ensure all setup cells in Section 1 completed\")\n",
    "    print(\"  2. Check that utils/ directory downloaded correctly\")\n",
    "    print(\"  3. Verify requirements-training.txt installed\")\n",
    "    raise\n",
    "# Verify Trainer has tokenizer parameter (detect stale cache)\n",
    "import inspect\n",
    "\n",
    "sig = inspect.signature(Trainer.__init__)\n",
    "if 'tokenizer' not in sig.parameters:\n",
    "    raise ImportError(\n",
    "        \"\u274c Stale Trainer detected! Missing 'tokenizer' parameter.\\n\"\n",
    "        \"Resolution:\\n\"\n",
    "        \"  1. Runtime \u2192 Restart runtime\\n\"\n",
    "        \"  2. Re-run Cell 4 (download utils)\\n\"\n",
    "        \"  3. Re-run this cell (imports)\"\n",
    "    )\n",
    "else:\n",
    "    print(\"\u2705 Trainer imports validated (tokenizer param present)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3056a7e3",
   "metadata": {},
   "source": [
    "<a id=\"section-2\"></a>\n",
    "# \ud83d\udce6 Section 2: Model Loading\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05f317f6",
   "metadata": {},
   "source": [
    "Load your transformer model from Transformer Builder or use the example model.\n",
    "\n",
    "**Options:**\n",
    "- **Custom Model**: Provide Gist ID from Transformer Builder (auto-detected from URL)\n",
    "- **Example Model**: GPT-2 style architecture for testing\n",
    "\n",
    "**You will see:**\n",
    "1. Model code preview\n",
    "2. Architecture summary (layers, parameters, size)\n",
    "3. GPU compatibility check\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a2d2da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title \ud83d\udd17 Model Source Configuration { display-mode: \"form\" }\n",
    "\n",
    "# Step 1: Try to extract from URL hash using JavaScript\n",
    "from google.colab import output\n",
    "import os\n",
    "import json\n",
    "\n",
    "# JavaScript to extract gist_id and model_name from URL hash\n",
    "js_code = \"\"\"\n",
    "(function() {\n",
    "    let gist_id = '';\n",
    "    let model_name = '';\n",
    "\n",
    "    try {\n",
    "        // Try to read URL hash from parent window (Colab embedding)\n",
    "        const hash = window.parent.location.hash || window.location.hash || '';\n",
    "\n",
    "        if (hash) {\n",
    "            // Parse hash parameters (e.g., #gist_id=abc123&name=MyModel)\n",
    "            const params = new URLSearchParams(hash.substring(1));\n",
    "            gist_id = params.get('gist_id') || '';\n",
    "            model_name = params.get('name') || '';\n",
    "\n",
    "            console.log('Extracted from URL hash:', {gist_id, model_name});\n",
    "        }\n",
    "    } catch (e) {\n",
    "        console.log('Could not access URL hash:', e);\n",
    "    }\n",
    "\n",
    "    // Return as JSON string\n",
    "    return JSON.stringify({gist_id: gist_id, model_name: model_name});\n",
    "})();\n",
    "\"\"\"\n",
    "\n",
    "# Execute JavaScript and get returned values\n",
    "try:\n",
    "    url_params_json = output.eval_js(js_code)\n",
    "    url_params = json.loads(url_params_json)\n",
    "    gist_id_from_url = url_params.get('gist_id', '')\n",
    "    model_name_from_url = url_params.get('model_name', '')\n",
    "except Exception as e:\n",
    "    print(f\"\u26a0\ufe0f  Could not extract from URL hash: {e}\")\n",
    "    gist_id_from_url = ''\n",
    "    model_name_from_url = ''\n",
    "\n",
    "# Step 2: Manual input forms (as fallback)\n",
    "gist_id_manual = \"\"  #@param {type:\"string\"}\n",
    "model_name_manual = \"CustomTransformer\"  #@param {type:\"string\"}\n",
    "\n",
    "# Step 3: Environment variables (lowest priority)\n",
    "gist_id_env = os.getenv('GIST_ID', '')\n",
    "model_name_env = os.getenv('MODEL_NAME', '')\n",
    "\n",
    "# Step 4: Determine final values (URL > Manual > Env)\n",
    "gist_id = gist_id_from_url or gist_id_manual or gist_id_env\n",
    "model_name = model_name_from_url or model_name_manual or model_name_env or 'CustomTransformer'\n",
    "\n",
    "# Display source\n",
    "print(\"=\"*60)\n",
    "if gist_id:\n",
    "    source = \"URL hash\" if gist_id_from_url else (\"Manual input\" if gist_id_manual else \"Environment variable\")\n",
    "    print(f\"\u2705 Model Source: {source}\")\n",
    "    print(f\"   Gist ID: {gist_id}\")\n",
    "    print(f\"   Model Name: {model_name}\")\n",
    "    print(f\"\\n   Loading custom model from Transformer Builder...\")\n",
    "else:\n",
    "    print(\"\u2139\ufe0f  No Gist ID provided\")\n",
    "    print(\"   Options to provide Gist ID:\")\n",
    "    print(\"   1. Open via Transformer Builder link (auto-detects from URL)\")\n",
    "    print(\"   2. Enter Gist ID in the form above\")\n",
    "    print(\"   3. Set GIST_ID environment variable\")\n",
    "    print(\"\\n   Proceeding with example model for demonstration...\")\n",
    "print(\"=\"*60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f7942bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title \ud83d\udce6 Load Model from Gist { display-mode: \"form\" }\n",
    "\n",
    "import urllib.request\n",
    "import json\n",
    "import sys\n",
    "import tempfile\n",
    "import shutil\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"MODEL LOADING\")\n",
    "print(\"=\" * 70)\n",
    "print()\n",
    "\n",
    "# ==============================================================================\n",
    "# VERIFY GIST ID WAS PROVIDED\n",
    "# ==============================================================================\n",
    "\n",
    "if 'gist_id' not in globals() or not gist_id:\n",
    "    print(\"\u274c ERROR: No Gist ID found!\")\n",
    "    print()\n",
    "    print(\"==\" * 35)\n",
    "    print(\"\ud83d\udd19 GO BACK TO PREVIOUS CELL\")\n",
    "    print(\"==\" * 35)\n",
    "    print()\n",
    "    print(\"You must run the Model Source Configuration cell first.\")\n",
    "    print()\n",
    "    raise ValueError(\"Gist ID required - run previous cell first\")\n",
    "\n",
    "print(f\"\ud83d\udce5 Loading model from GitHub Gist: {gist_id}\")\n",
    "print()\n",
    "\n",
    "# ==============================================================================\n",
    "# FETCH GIST AND LOAD MODEL FILES - GitHub API Approach\n",
    "# ==============================================================================\n",
    "\n",
    "def _fetch_gist(gid: str) -> dict:\n",
    "    \"\"\"Fetch Gist data from GitHub API.\"\"\"\n",
    "    url = f\"https://api.github.com/gists/{gid}\"\n",
    "    req = urllib.request.Request(url, headers={\n",
    "        \"Accept\": \"application/vnd.github+json\",\n",
    "        \"User-Agent\": \"transformer-builder-colab\"\n",
    "    })\n",
    "    try:\n",
    "        with urllib.request.urlopen(req, timeout=20) as resp:\n",
    "            return json.loads(resp.read().decode(\"utf-8\"))\n",
    "    except urllib.error.HTTPError as e:\n",
    "        detail = f\"HTTP {e.code}\"\n",
    "        try:\n",
    "            body = e.read().decode(\"utf-8\")\n",
    "            if \"rate limit\" in body.lower():\n",
    "                detail += \" - GitHub API rate limit (try again in an hour)\"\n",
    "            elif e.code == 404:\n",
    "                detail += \" - Gist not found (check your Gist ID)\"\n",
    "        except:\n",
    "            pass\n",
    "        raise RuntimeError(f\"GitHub API error: {detail}\") from e\n",
    "    except Exception as e:\n",
    "        raise RuntimeError(f\"Network error: {e}\") from e\n",
    "\n",
    "def _write(path: str, text: str):\n",
    "    \"\"\"Write text to file.\"\"\"\n",
    "    with open(path, \"w\") as f:\n",
    "        f.write(text)\n",
    "\n",
    "# Fetch Gist\n",
    "try:\n",
    "    gist_data = _fetch_gist(gist_id)\n",
    "    files = gist_data.get(\"files\") or {}\n",
    "\n",
    "    # Check for required files\n",
    "    if \"model.py\" not in files:\n",
    "        raise RuntimeError(\"Gist is missing 'model.py' - please re-export from Transformer Builder\")\n",
    "    if \"config.json\" not in files:\n",
    "        raise RuntimeError(\"Gist is missing 'config.json' - please re-export from Transformer Builder\")\n",
    "\n",
    "    model_code = files[\"model.py\"].get(\"content\", \"\")\n",
    "    config_json = files[\"config.json\"].get(\"content\", \"\")\n",
    "\n",
    "    if not model_code or not config_json:\n",
    "        raise RuntimeError(\"Empty content in model.py or config.json\")\n",
    "\n",
    "    # Write to files\n",
    "    _write(\"model.py\", model_code)\n",
    "    _write(\"config.json\", config_json)\n",
    "\n",
    "    print(f\"\u2705 Model loaded successfully!\")\n",
    "    print(f\"\u2705 Gist URL: {gist_data.get('html_url', 'N/A')}\")\n",
    "    print(f\"\u2705 Model code: {len(model_code):,} bytes\")\n",
    "    print(f\"\u2705 Config: {len(config_json):,} bytes\")\n",
    "    print()\n",
    "\n",
    "    # Parse model name from config if available\n",
    "    try:\n",
    "        model_config = json.loads(config_json)\n",
    "        if 'model_name' in model_config:\n",
    "            model_name = model_config['model_name']\n",
    "            print(f\"\u2705 Model name: {model_name}\")\n",
    "        else:\n",
    "            model_name = 'CustomTransformer'\n",
    "            print(f\"\u2139\ufe0f  Using default name: {model_name}\")\n",
    "        print()\n",
    "    except:\n",
    "        model_name = 'CustomTransformer'\n",
    "        print(f\"\u26a0\ufe0f  Could not parse config, using default name: {model_name}\")\n",
    "\n",
    "    # Store for next cell\n",
    "    gist_loaded = True\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"\u274c Failed to load model from Gist!\")\n",
    "    print()\n",
    "    print(f\"Error: {e}\")\n",
    "    print()\n",
    "    print(\"=\" * 70)\n",
    "    print(\"TROUBLESHOOTING\")\n",
    "    print(\"=\" * 70)\n",
    "    print()\n",
    "    print(\"Common issues:\")\n",
    "    print(\"  1. Check your Gist ID is correct (go back to previous cell)\")\n",
    "    print(\"  2. Ensure you exported from Transformer Builder successfully\")\n",
    "    print(\"  3. Check you're not hitting GitHub rate limit (60 requests/hour)\")\n",
    "    print(\"  4. Try re-exporting from Transformer Builder\")\n",
    "    print()\n",
    "    print(\"If the problem persists:\")\n",
    "    print(f\"  \u2022 Gist URL: https://gist.github.com/{gist_id}\")\n",
    "    print(\"  \u2022 Verify the Gist contains model.py and config.json\")\n",
    "    print()\n",
    "\n",
    "    # Fallback to example model\n",
    "    print(\"\u26a0\ufe0f  Falling back to example model for demonstration...\")\n",
    "    gist_loaded = False\n",
    "    model_name = 'ExampleTransformer'\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"\u2705 MODEL LOADING COMPLETE\")\n",
    "print(\"=\" * 70)\n",
    "print()\n",
    "print(\"Model will be instantiated in the next cell.\")\n",
    "print()\n",
    "\n",
    "# Display downloaded model code preview\n",
    "if gist_loaded:\n",
    "    print(\"\\n\ud83d\udcc4 Model Code Preview:\")\n",
    "    print(\"=\" * 60)\n",
    "    with open('model.py', 'r') as f:\n",
    "        model_lines = f.read().split('\\n')\n",
    "        # Show first 20 lines\n",
    "        for i, line in enumerate(model_lines[:20], 1):\n",
    "            print(f\"{i:3d} | {line}\")\n",
    "        if len(model_lines) > 20:\n",
    "            print(f\"... ({len(model_lines) - 20} more lines)\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "print(f\"\\n\ud83d\udcca Model: {model_name}\")\n",
    "if gist_loaded:\n",
    "    print(f\"   Config: {json.dumps(model_config, indent=2)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dfda51d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title \ud83d\ude80 Initialize Model { display-mode: \"form\" }\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import inspect\n",
    "from types import SimpleNamespace\n",
    "\n",
    "# Detect device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"\ud83d\udda5\ufe0f  Device: {device}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"   GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"   Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
    "\n",
    "# Create model instance\n",
    "if gist_loaded:\n",
    "    # Custom model from Transformer Builder\n",
    "    # Import the model from downloaded file\n",
    "    try:\n",
    "        sys.path.insert(0, '.')\n",
    "\n",
    "        # Import all classes from model.py\n",
    "        import importlib.util\n",
    "        spec = importlib.util.spec_from_file_location(\"custom_model\", \"model.py\")\n",
    "        custom_model_module = importlib.util.module_from_spec(spec)\n",
    "        spec.loader.exec_module(custom_model_module)\n",
    "\n",
    "        # Find the model class\n",
    "        model_class = None\n",
    "        for name, obj in vars(custom_model_module).items():\n",
    "            if isinstance(obj, type) and issubclass(obj, nn.Module) and obj is not nn.Module:\n",
    "                if name == model_name:\n",
    "                    model_class = obj\n",
    "                    break\n",
    "        \n",
    "        if model_class is None:\n",
    "            # Fallback: find any nn.Module subclass\n",
    "            for name, obj in vars(custom_model_module).items():\n",
    "                if isinstance(obj, type) and issubclass(obj, nn.Module) and obj is not nn.Module:\n",
    "                    model_class = obj\n",
    "                    print(f\"\u26a0\ufe0f Using {name} (expected {model_name})\")\n",
    "                    break\n",
    "        \n",
    "        if model_class:\n",
    "            # Check constructor signature (KEY FIX from template.ipynb)\n",
    "            sig = inspect.signature(model_class.__init__)\n",
    "            params_list = [p for p in sig.parameters.values() if p.name != 'self']\n",
    "            \n",
    "            if len(params_list) == 0:\n",
    "                # Parameterless constructor (Transformer Builder models)\n",
    "                print(\"\u2139\ufe0f  Model has parameterless constructor (Transformer Builder export)\")\n",
    "                model = model_class()\n",
    "            else:\n",
    "                # Parameterized constructor (traditional models)\n",
    "                print(f\"\u2139\ufe0f  Model accepts {len(params_list)} parameter(s)\")\n",
    "                model = model_class(**model_config)\n",
    "            \n",
    "            print(f\"\u2705 Custom model instantiated: {model.__class__.__name__}\")\n",
    "        else:\n",
    "            raise Exception(\"No model class found in model.py\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"\u274c Failed to instantiate custom model: {e}\")\n",
    "        print(\"   Falling back to example model...\")\n",
    "        gist_loaded = False\n",
    "\n",
    "if not gist_loaded:\n",
    "    # Example model (fallback)\n",
    "    print(\"\ud83d\udce6 Loading example model (GPT-2 architecture)...\")\n",
    "\n",
    "    class ExampleTransformer(nn.Module):\n",
    "        \"\"\"Example GPT-2 style transformer for demonstration.\"\"\"\n",
    "\n",
    "        def __init__(self, vocab_size=50257, d_model=768, n_layers=12, n_heads=12, max_seq_len=1024):\n",
    "            super().__init__()\n",
    "            self.vocab_size = vocab_size\n",
    "            self.d_model = d_model\n",
    "            self.n_layers = n_layers\n",
    "            self.n_heads = n_heads\n",
    "            self.max_seq_len = max_seq_len\n",
    "\n",
    "            self.embedding = nn.Embedding(vocab_size, d_model)\n",
    "            self.position_embedding = nn.Embedding(max_seq_len, d_model)\n",
    "\n",
    "            # Simple transformer layers\n",
    "            self.layers = nn.ModuleList([\n",
    "                nn.TransformerEncoderLayer(\n",
    "                    d_model,\n",
    "                    n_heads,\n",
    "                    dim_feedforward=d_model*4,\n",
    "                    batch_first=True,\n",
    "                    dropout=0.1\n",
    "                )\n",
    "                for _ in range(n_layers)\n",
    "            ])\n",
    "\n",
    "            self.ln_f = nn.LayerNorm(d_model)\n",
    "            self.lm_head = nn.Linear(d_model, vocab_size, bias=False)\n",
    "\n",
    "        def forward(self, input_ids):\n",
    "            batch_size, seq_len = input_ids.shape\n",
    "\n",
    "            # Embeddings\n",
    "            token_emb = self.embedding(input_ids)\n",
    "            pos_ids = torch.arange(seq_len, device=input_ids.device).unsqueeze(0)\n",
    "            pos_emb = self.position_embedding(pos_ids)\n",
    "\n",
    "            x = token_emb + pos_emb\n",
    "\n",
    "            # Transformer layers\n",
    "            for layer in self.layers:\n",
    "                x = layer(x)\n",
    "\n",
    "            x = self.ln_f(x)\n",
    "            logits = self.lm_head(x)\n",
    "\n",
    "            return logits\n",
    "\n",
    "    # Create example model\n",
    "    model = ExampleTransformer()\n",
    "    model_config = {\n",
    "        'vocab_size': 50257,\n",
    "        'd_model': 768,\n",
    "        'n_layers': 12,\n",
    "        'n_heads': 12,\n",
    "        'max_seq_len': 1024\n",
    "    }\n",
    "\n",
    "    print(f\"\u2705 Example model definition loaded\")\n",
    "\n",
    "# Move to device\n",
    "model = model.to(device)\n",
    "\n",
    "# Model summary\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f\"\\n\u2705 Model initialized on {device}\")\n",
    "print(f\"   Total parameters: {total_params:,}\")\n",
    "print(f\"   Trainable parameters: {trainable_params:,}\")\n",
    "print(f\"   Model size: {total_params * 4 / 1e6:.1f} MB (fp32)\")\n",
    "\n",
    "# Create config object for training utilities\n",
    "config_obj = SimpleNamespace(**model_config)\n",
    "if not hasattr(config_obj, 'vocab_size'):\n",
    "    config_obj.vocab_size = model_config.get('vocab_size', 50257)\n",
    "if not hasattr(config_obj, 'max_seq_len'):\n",
    "    config_obj.max_seq_len = model_config.get('max_seq_len', 1024)\n",
    "\n",
    "print(f\"\\n\ud83c\udfaf Ready for training!\")\n",
    "print(f\"\\n\u2139\ufe0f  Note: Update Section 4 training config before starting training loop.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fc17228",
   "metadata": {},
   "source": [
    "<a id=\"section-3\"></a>\n",
    "# \ud83d\udcca Section 3: Data Loading\n",
    "\n",
    "Choose your data source (run ONE of the following cells):\n",
    "- **Option 1**: HuggingFace Datasets (recommended)\n",
    "- **Option 2**: Google Drive Upload\n",
    "- **Option 3**: File Upload (small datasets)\n",
    "- **Option 4**: Local Files (from previous sessions)\n",
    "- **Option 5**: Synthetic Data (testing only)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b3e6fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# CONFIGURATION: Edit dataset name\n",
    "dataset_name = \"wikitext\"  #@param {type:\"string\"}\n",
    "config_name = \"wikitext-2-raw-v1\"  #@param {type:\"string\"}\n",
    "max_samples = 1000  #@param {type:\"integer\"}\n",
    "\n",
    "# Load dataset\n",
    "dataset = load_dataset(dataset_name, config_name)\n",
    "train_data = dataset['train'].select(range(min(max_samples, len(dataset['train']))))\n",
    "val_data = dataset['validation'].select(range(min(100, len(dataset['validation']))))\n",
    "\n",
    "print(f\"\u2705 Loaded {len(train_data)} training samples, {len(val_data)} validation samples\")\n",
    "print(f\"   Example: {train_data[0]}\")\n",
    "\n",
    "data_source = \"huggingface\"\n",
    "dataset_info = {'name': dataset_name, 'config': config_name, 'train_size': len(train_data), 'val_size': len(val_data)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e417890",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "drive_data_path = \"/content/drive/MyDrive/TransformerTraining/datasets/my_data.txt\"  #@param {type:\"string\"}\n",
    "\n",
    "if os.path.exists(drive_data_path):\n",
    "    with open(drive_data_path, 'r', encoding='utf-8') as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    split_idx = int(0.9 * len(lines))\n",
    "    train_data = [line.strip() for line in lines[:split_idx]]\n",
    "    val_data = [line.strip() for line in lines[split_idx:]]\n",
    "\n",
    "    print(f\"\u2705 Loaded {len(train_data)} training samples, {len(val_data)} validation samples\")\n",
    "    data_source = \"google_drive\"\n",
    "    dataset_info = {'path': drive_data_path, 'train_size': len(train_data), 'val_size': len(val_data)}\n",
    "else:\n",
    "    print(f\"\u274c File not found: {drive_data_path}\")\n",
    "    print(\"   Please upload your data to Google Drive first\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "366269e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "import io\n",
    "\n",
    "# Upload file\n",
    "uploaded = files.upload()\n",
    "\n",
    "if uploaded:\n",
    "    filename = list(uploaded.keys())[0]\n",
    "    content = uploaded[filename].decode('utf-8')\n",
    "    lines = content.split('\\n')\n",
    "\n",
    "    split_idx = int(0.9 * len(lines))\n",
    "    train_data = [line.strip() for line in lines[:split_idx]]\n",
    "    val_data = [line.strip() for line in lines[split_idx:]]\n",
    "\n",
    "    print(f\"\u2705 Loaded {len(train_data)} training samples, {len(val_data)} validation samples\")\n",
    "    data_source = \"file_upload\"\n",
    "    dataset_info = {'filename': filename, 'train_size': len(train_data), 'val_size': len(val_data)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a4882b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "\n",
    "cache_path = f'{workspace_root}/datasets/cached_data.pkl'\n",
    "\n",
    "if os.path.exists(cache_path):\n",
    "    with open(cache_path, 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "\n",
    "    train_data = data['train']\n",
    "    val_data = data['val']\n",
    "\n",
    "    print(f\"\u2705 Loaded cached data: {len(train_data)} train, {len(val_data)} val\")\n",
    "    data_source = \"cached\"\n",
    "    dataset_info = {'path': cache_path, 'train_size': len(train_data), 'val_size': len(val_data)}\n",
    "else:\n",
    "    print(f\"\u274c No cached data found at {cache_path}\")\n",
    "    print(\"   Run one of the other data loading options first\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7865100c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Generate synthetic data for testing\n",
    "vocab_size = 50257  # GPT-2 vocab\n",
    "seq_len = 32\n",
    "n_samples = 100\n",
    "\n",
    "train_data = [torch.randint(0, vocab_size, (seq_len,)) for _ in range(n_samples)]\n",
    "val_data = [torch.randint(0, vocab_size, (seq_len,)) for _ in range(20)]\n",
    "\n",
    "print(f\"\u2705 Generated {len(train_data)} synthetic training samples\")\n",
    "print(f\"   \u26a0\ufe0f Warning: Synthetic data is for testing only\")\n",
    "data_source = \"synthetic\"\n",
    "dataset_info = {'vocab_size': vocab_size, 'seq_len': seq_len, 'train_size': len(train_data), 'val_size': len(val_data)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7s2xtx5f5n8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title \ud83c\udfaf Task Specification (Auto-Detected) { display-mode: \"form\" }\n",
    "\n",
    "# === SELF-CONTAINED IMPORTS ===\n",
    "import sys\n",
    "import os\n",
    "if '.' not in sys.path:\n",
    "    sys.path.insert(0, '.')\n",
    "\n",
    "# Import with error handling\n",
    "try:\n",
    "    from utils.training.task_spec import TaskSpec\n",
    "    from types import SimpleNamespace\n",
    "    import torch\n",
    "except ImportError as e:\n",
    "    print(\"\u274c Import failed!\")\n",
    "    print(f\"\\nError: {e}\")\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"TROUBLESHOOTING\")\n",
    "    print(\"=\"*70)\n",
    "    print(\"\\n1. Run the 'Prerequisite Validation' cell above\")\n",
    "    print(\"2. Ensure Section 1 setup completed successfully\")\n",
    "    print(\"3. Check that utils package is downloaded\")\n",
    "    raise\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"TASK SPECIFICATION\")\n",
    "print(\"=\" * 70)\n",
    "print()\n",
    "\n",
    "# Auto-detect modality from data source\n",
    "detected_modality = \"text\"  # Default\n",
    "detected_task_type = \"lm\"   # Default\n",
    "\n",
    "# Try to detect from data\n",
    "if 'train_data' in globals() and train_data:\n",
    "    try:\n",
    "        sample = train_data[0] if isinstance(train_data, list) else train_data[0]\n",
    "        \n",
    "        # Check for vision data\n",
    "        if isinstance(sample, dict):\n",
    "            if 'pixel_values' in sample or 'image' in sample:\n",
    "                detected_modality = \"vision\"\n",
    "                detected_task_type = \"vision_classification\"\n",
    "                print(\"\ud83d\udd0d Detected vision data (found pixel_values/image in sample)\")\n",
    "            elif 'input_ids' in sample or 'text' in sample:\n",
    "                detected_modality = \"text\"\n",
    "                detected_task_type = \"lm\"\n",
    "                print(\"\ud83d\udd0d Detected text data (found input_ids/text in sample)\")\n",
    "        elif isinstance(sample, torch.Tensor):\n",
    "            if sample.dim() >= 3:  # Likely image (C, H, W) or (B, C, H, W)\n",
    "                detected_modality = \"vision\"\n",
    "                detected_task_type = \"vision_classification\"\n",
    "                print(f\"\ud83d\udd0d Detected vision data (tensor shape: {sample.shape})\")\n",
    "            else:\n",
    "                detected_modality = \"text\"\n",
    "                detected_task_type = \"lm\"\n",
    "                print(f\"\ud83d\udd0d Detected text data (tensor shape: {sample.shape})\")\n",
    "    except Exception as e:\n",
    "        print(f\"\u26a0\ufe0f  Could not auto-detect from data: {e}\")\n",
    "        print(\"   Using default: text/lm\")\n",
    "\n",
    "print(f\"   Modality: {detected_modality}\")\n",
    "print(f\"   Task type: {detected_task_type}\")\n",
    "print()\n",
    "\n",
    "# Allow manual override\n",
    "task_modality = detected_modality  #@param [\"text\", \"vision\", \"audio\", \"tabular\"]\n",
    "task_type = detected_task_type  #@param [\"lm\", \"classification\", \"seq2seq\", \"vision_classification\", \"vision_multilabel\"]\n",
    "\n",
    "print(f\"\ud83d\udcdd Final selection:\")\n",
    "print(f\"   Modality: {task_modality}\")\n",
    "print(f\"   Task type: {task_type}\")\n",
    "print()\n",
    "\n",
    "# Create TaskSpec based on modality\n",
    "if task_modality == \"vision\":\n",
    "    # Vision task configuration\n",
    "    image_size = getattr(config_obj, 'image_size', [3, 224, 224]) if 'config_obj' in globals() else [3, 224, 224]\n",
    "    num_classes = getattr(config_obj, 'num_classes', 10) if 'config_obj' in globals() else 10\n",
    "    \n",
    "    task_spec = TaskSpec(\n",
    "        name=f\"{model_name}_vision\" if 'model_name' in globals() else \"vision_task\",\n",
    "        task_type=task_type,\n",
    "        model_family=\"encoder_only\",\n",
    "        input_fields=[\"pixel_values\"],\n",
    "        target_field=\"labels\",\n",
    "        loss_type=\"cross_entropy\",\n",
    "        metrics=[\"loss\", \"accuracy\"],\n",
    "        modality=\"vision\",\n",
    "        input_schema={\"image_size\": image_size, \"channels_first\": True},\n",
    "        output_schema={\"num_classes\": num_classes},\n",
    "        preprocessing_config={\n",
    "            \"normalize\": True,\n",
    "            \"mean\": [0.485, 0.456, 0.406],  # ImageNet defaults\n",
    "            \"std\": [0.229, 0.224, 0.225]\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    print(\"\u2705 Vision TaskSpec created\")\n",
    "    print(f\"   Image size: {image_size}\")\n",
    "    print(f\"   Num classes: {num_classes}\")\n",
    "    print(f\"   VisionDataCollator will be auto-selected (v3.5 feature)\")\n",
    "    \n",
    "else:  # text modality\n",
    "    # Text task configuration\n",
    "    vocab_size = getattr(config_obj, 'vocab_size', 50257) if 'config_obj' in globals() else 50257\n",
    "    max_seq_len = getattr(config_obj, 'max_seq_len', 128) if 'config_obj' in globals() else 128\n",
    "    \n",
    "    task_spec = TaskSpec(\n",
    "        name=f\"{model_name}_lm\" if 'model_name' in globals() else \"text_task\",\n",
    "        task_type=task_type,\n",
    "        model_family=\"decoder_only\",\n",
    "        input_fields=[\"input_ids\", \"attention_mask\"],\n",
    "        target_field=\"labels\",\n",
    "        loss_type=\"cross_entropy\",\n",
    "        metrics=[\"loss\", \"perplexity\", \"accuracy\"],\n",
    "        modality=\"text\",\n",
    "        input_schema={\"max_seq_len\": max_seq_len, \"vocab_size\": vocab_size},\n",
    "        output_schema={\"vocab_size\": vocab_size},\n",
    "        special_tokens={\"pad_token_id\": 0},\n",
    "        additional_config={\"shift_labels\": True}\n",
    "    )\n",
    "    \n",
    "    print(\"\u2705 Text TaskSpec created\")\n",
    "    print(f\"   Vocab size: {vocab_size}\")\n",
    "    print(f\"   Max sequence length: {max_seq_len}\")\n",
    "\n",
    "print()\n",
    "print(\"=\" * 70)\n",
    "print(\"\u2705 TASK SPECIFICATION COMPLETE\")\n",
    "print(\"=\" * 70)\n",
    "print()\n",
    "print(\"\ud83d\udca1 TaskSpec enables:\")\n",
    "print(\"   - Modality-aware data collation\")\n",
    "print(\"   - Drift detection (v3.6)\")\n",
    "print(\"   - Export bundle generation (v3.5)\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afac06b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title \ud83d\udcdd Data Tokenization & Preprocessing { display-mode: \"form\" }\n",
    "\n",
    "# === SELF-CONTAINED IMPORTS ===\n",
    "import sys\n",
    "import os\n",
    "if '.' not in sys.path:\n",
    "    sys.path.insert(0, '.')\n",
    "\n",
    "try:\n",
    "    import torch\n",
    "    from utils.tokenization.adaptive_tokenizer import AdaptiveTokenizer\n",
    "    from utils.tokenization.data_collator import LanguageModelingDataCollator\n",
    "    import time\n",
    "except ImportError as e:\n",
    "    print(\"\u274c Import failed!\")\n",
    "    print(f\"\\nError: {e}\")\n",
    "    print(\"\\nTroubleshooting:\")\n",
    "    print(\"1. Ensure utils package downloaded (Section 1)\")\n",
    "    print(\"2. Re-run notebook from start\")\n",
    "    raise\n",
    "\n",
    "# === PREREQUISITE CHECKS ===\n",
    "if 'train_data' not in globals() or 'val_data' not in globals():\n",
    "    raise NameError(\"train_data/val_data not found. Run data loading cell first.\")\n",
    "if 'config_obj' not in globals():\n",
    "    raise NameError(\"config_obj not found. Run model loading cell first.\")\n",
    "if 'task_spec' not in globals():\n",
    "    raise NameError(\"task_spec not found. Run task specification cell first.\")\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"DATA TOKENIZATION & PREPROCESSING\")\n",
    "print(\"=\"*70)\n",
    "print()\n",
    "\n",
    "# === MODALITY-AWARE PROCESSING ===\n",
    "modality = task_spec.modality\n",
    "print(f\"\ud83d\udccb Modality: {modality}\")\n",
    "print(f\"\ud83d\udce6 Vocab Size: {config_obj.vocab_size}\")\n",
    "print(f\"\ud83d\udccf Max Sequence Length: {task_spec.input_schema['max_seq_len']}\")\n",
    "print()\n",
    "\n",
    "if modality == 'text':\n",
    "    # === TEXT TOKENIZATION ===\n",
    "    \n",
    "    # Step 1: Auto-detect text field\n",
    "    text_fields = ['text', 'content', 'sentence', 'document', 'body', 'input', 'prompt']\n",
    "    text_field = next((f for f in text_fields if f in train_data.features), None)\n",
    "    \n",
    "    if text_field is None:\n",
    "        print(\"\u274c No text field found in dataset!\")\n",
    "        print(f\"   Available fields: {list(train_data.features.keys())}\")\n",
    "        raise ValueError(\"Cannot auto-detect text field. Please specify manually.\")\n",
    "    \n",
    "    print(f\"\u2705 Text field detected: '{text_field}'\")\n",
    "    print()\n",
    "    \n",
    "    # Step 2: Load or create tokenizer via AdaptiveTokenizer\n",
    "    print(\"\ud83d\udd27 Loading tokenizer...\")\n",
    "    tokenizer = AdaptiveTokenizer.load_or_create(\n",
    "        vocab_size=config_obj.vocab_size,\n",
    "        dataset=train_data\n",
    "    )\n",
    "    print(f\"\u2705 Tokenizer loaded: {tokenizer.__class__.__name__}\")\n",
    "    \n",
    "    # Get vocab size safely\n",
    "    if hasattr(tokenizer, 'vocab_size'):\n",
    "        tok_vocab = tokenizer.vocab_size\n",
    "    elif hasattr(tokenizer, 'get_vocab_size'):\n",
    "        tok_vocab = tokenizer.get_vocab_size()\n",
    "    else:\n",
    "        tok_vocab = len(tokenizer.get_vocab()) if hasattr(tokenizer, 'get_vocab') else 'unknown'\n",
    "    print(f\"   Vocab size: {tok_vocab}\")\n",
    "    print()\n",
    "    \n",
    "    # Step 3: Define tokenization function (lazy evaluation)\n",
    "    def tokenize_batch(batch):\n",
    "        \"\"\"Tokenize a batch of examples using lazy evaluation.\"\"\"\n",
    "        # Handle different tokenizer interfaces\n",
    "        if hasattr(tokenizer, '__call__'):\n",
    "            # HuggingFace tokenizer\n",
    "            result = tokenizer(\n",
    "                batch[text_field],\n",
    "                truncation=True,\n",
    "                max_length=task_spec.input_schema['max_seq_len'],\n",
    "                padding=False,  # Defer to collator for dynamic padding\n",
    "                return_tensors=None  # Keep as lists for now\n",
    "            )\n",
    "        elif hasattr(tokenizer, 'encode'):\n",
    "            # Simple encode interface\n",
    "            result = {\n",
    "                'input_ids': [tokenizer.encode(text, max_length=task_spec.input_schema['max_seq_len'], truncation=True) \n",
    "                             for text in batch[text_field]]\n",
    "            }\n",
    "        else:\n",
    "            raise ValueError(f\"Tokenizer {type(tokenizer)} has no compatible encode method\")\n",
    "        return result\n",
    "    \n",
    "    # Step 4: Apply tokenization via dataset.map (lazy loading)\n",
    "    print(\"\u2699\ufe0f  Tokenizing datasets (this may take a moment)...\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Determine cache behavior\n",
    "    overwrite_cache = False  # Set to True during debugging\n",
    "    num_proc = min(4, os.cpu_count() or 1)  # Parallel processing\n",
    "    \n",
    "    # Tokenize train dataset\n",
    "    train_data = train_data.map(\n",
    "        tokenize_batch,\n",
    "        batched=True,\n",
    "        remove_columns=[text_field],  # Remove raw text to save memory\n",
    "        num_proc=num_proc if os.name != 'nt' else 1,  # Windows compatibility\n",
    "        load_from_cache_file=not overwrite_cache,\n",
    "        desc=\"Tokenizing train data\"\n",
    "    )\n",
    "    \n",
    "    # Tokenize validation dataset\n",
    "    val_data = val_data.map(\n",
    "        tokenize_batch,\n",
    "        batched=True,\n",
    "        remove_columns=[text_field],\n",
    "        num_proc=num_proc if os.name != 'nt' else 1,\n",
    "        load_from_cache_file=not overwrite_cache,\n",
    "        desc=\"Tokenizing val data\"\n",
    "    )\n",
    "    \n",
    "    elapsed = time.time() - start_time\n",
    "    print(f\"\u2705 Tokenization complete in {elapsed:.2f}s\")\n",
    "    print()\n",
    "    \n",
    "    # Step 5: Set format to PyTorch (lazy, zero-copy)\n",
    "    train_data.set_format(type='torch', columns=['input_ids'])\n",
    "    val_data.set_format(type='torch', columns=['input_ids'])\n",
    "    \n",
    "    # Step 6: Create collator for dynamic padding\n",
    "    data_collator = LanguageModelingDataCollator(\n",
    "        tokenizer=tokenizer,\n",
    "        mlm=False,  # Causal LM (GPT-style)\n",
    "        padding_side='right'\n",
    "    )\n",
    "    \n",
    "    # Step 7: Display statistics\n",
    "    print(\"\ud83d\udcca Tokenization Statistics:\")\n",
    "    print(f\"   Train samples: {len(train_data)}\")\n",
    "    print(f\"   Val samples: {len(val_data)}\")\n",
    "    \n",
    "    # Compute length statistics\n",
    "    sample_size = min(1000, len(train_data))\n",
    "    train_lengths = [len(ex['input_ids']) for ex in train_data.select(range(sample_size))]\n",
    "    mean_len = sum(train_lengths) / len(train_lengths)\n",
    "    max_len = max(train_lengths)\n",
    "    truncated_pct = sum(1 for l in train_lengths if l == task_spec.input_schema['max_seq_len']) / len(train_lengths) * 100\n",
    "    \n",
    "    print(f\"   Mean length: {mean_len:.1f} tokens\")\n",
    "    print(f\"   Max length: {max_len} tokens\")\n",
    "    print(f\"   Truncated: {truncated_pct:.1f}%\")\n",
    "    \n",
    "    if truncated_pct > 10:\n",
    "        print(f\"   \u26a0\ufe0f  Warning: >{truncated_pct:.0f}% sequences truncated. Consider increasing max_seq_len.\")\n",
    "    \n",
    "    # Step 8: Show example\n",
    "    print()\n",
    "    print(\"\ud83d\udd0d Example tokenized sample:\")\n",
    "    example = train_data[0]\n",
    "    print(f\"   Input IDs shape: {example['input_ids'].shape}\")\n",
    "    print(f\"   First 20 tokens: {example['input_ids'][:20].tolist()}\")\n",
    "    if hasattr(tokenizer, 'decode'):\n",
    "        try:\n",
    "            decoded = tokenizer.decode(example['input_ids'][:50])\n",
    "            print(f\"   Decoded preview: {decoded[:100]}...\")\n",
    "        except:\n",
    "            print(f\"   (decode not available for this tokenizer)\")\n",
    "\n",
    "elif modality == 'vision':\n",
    "    # === VISION PREPROCESSING ===\n",
    "    try:\n",
    "        from torchvision import transforms\n",
    "        from utils.tokenization.data_collator import VisionDataCollator\n",
    "        \n",
    "        print(\"\ud83d\uddbc\ufe0f  Vision modality detected\")\n",
    "        \n",
    "        # Get image size from task_spec or config\n",
    "        image_size = getattr(task_spec, 'image_size', 224)\n",
    "        \n",
    "        # Define image transforms\n",
    "        transform = transforms.Compose([\n",
    "            transforms.Resize((image_size, image_size)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "        \n",
    "        def preprocess_images(batch):\n",
    "            \"\"\"Preprocess images.\"\"\"\n",
    "            images = [transform(img.convert('RGB')) for img in batch['image']]\n",
    "            return {'pixel_values': images}\n",
    "        \n",
    "        print(\"\u2699\ufe0f  Preprocessing images...\")\n",
    "        train_data = train_data.map(\n",
    "            preprocess_images,\n",
    "            batched=True,\n",
    "            remove_columns=['image'],\n",
    "            desc=\"Preprocessing train images\"\n",
    "        )\n",
    "        val_data = val_data.map(\n",
    "            preprocess_images,\n",
    "            batched=True,\n",
    "            remove_columns=['image'],\n",
    "            desc=\"Preprocessing val images\"\n",
    "        )\n",
    "        \n",
    "        train_data.set_format(type='torch', columns=['pixel_values', 'label'])\n",
    "        val_data.set_format(type='torch', columns=['pixel_values', 'label'])\n",
    "        \n",
    "        data_collator = VisionDataCollator(image_size)\n",
    "        print(f\"\u2705 Vision preprocessing complete\")\n",
    "    except ImportError as e:\n",
    "        print(f\"\u26a0\ufe0f  Vision preprocessing failed: {e}\")\n",
    "        print(\"   Install torchvision: !pip install torchvision\")\n",
    "        data_collator = None\n",
    "\n",
    "elif modality == 'audio':\n",
    "    # === AUDIO PREPROCESSING ===\n",
    "    print(\"\ud83c\udfb5 Audio modality detected\")\n",
    "    print(\"\u26a0\ufe0f  Audio preprocessing not yet implemented\")\n",
    "    print(\"   Falling back to default behavior\")\n",
    "    data_collator = None\n",
    "\n",
    "else:\n",
    "    # === UNKNOWN MODALITY ===\n",
    "    print(f\"\u26a0\ufe0f  Unknown modality: {modality}\")\n",
    "    print(\"   Proceeding without preprocessing\")\n",
    "    data_collator = None\n",
    "\n",
    "print()\n",
    "print(\"=\"*70)\n",
    "print(\"\u2705 PREPROCESSING COMPLETE\")\n",
    "print(\"=\"*70)\n",
    "print()\n",
    "print(\"\ud83d\udce6 Output format:\")\n",
    "print(f\"   train_data: {type(train_data)}\")\n",
    "print(f\"   val_data: {type(val_data)}\")\n",
    "print(f\"   data_collator: {type(data_collator).__name__ if data_collator else 'None'}\")\n",
    "print()\n",
    "print(\"\u2728 Ready for training!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef4cc0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title \ud83d\udd0d Data Quality Validation & Filtering (v4.0 - Permissive) { display-mode: \"form\" }\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 5: DATA QUALITY VALIDATION & FILTERING\n",
    "# ============================================================================\n",
    "# PERMISSIVE VALIDATION: Provides warnings based on severity, allows training to proceed.\n",
    "# Different datasets have different characteristics (WikiText: 25-40%, C4: 1-5%).\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"STEP 5: DATA QUALITY VALIDATION & FILTERING\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "from utils.training.validation import SequenceLengthValidator\n",
    "from utils.training.data_quality import filter_short_sequences\n",
    "\n",
    "# Determine minimum sequence length from task type\n",
    "min_seq_len = 2 if task_spec.task_type in ['lm', 'causal_lm', 'language_modeling'] else 1\n",
    "\n",
    "print(f\"\\nTask: {task_spec.task_type}\")\n",
    "print(f\"Minimum sequence length: {min_seq_len} tokens\")\n",
    "\n",
    "# LAYER 1: Dataset-level validation (permissive - guidance, not gatekeeping)\n",
    "print(\"\\n[1/2] Validating dataset quality...\")\n",
    "validator = SequenceLengthValidator(\n",
    "    min_seq_len=min_seq_len,\n",
    "    max_filter_rate=0.20  # Advisory threshold (not blocking)\n",
    ")\n",
    "\n",
    "validation_result = validator.validate(train_data)\n",
    "filter_rate = validation_result.metrics['filter_rate']\n",
    "\n",
    "# Severity-based messaging (permissive approach)\n",
    "if filter_rate < 0.10:\n",
    "    print(f\"   \u2705 Dataset quality: Excellent ({filter_rate:.1%} filter rate)\")\n",
    "elif filter_rate < 0.20:\n",
    "    print(f\"   \u2139\ufe0f Dataset quality: Good ({filter_rate:.1%} filter rate)\")\n",
    "    print(\"      Moderate filtering is normal for some datasets.\")\n",
    "elif filter_rate < 0.40:\n",
    "    print(f\"   \u26a0\ufe0f High filter rate detected: {filter_rate:.1%}\")\n",
    "    print(\"      This is NORMAL for structured datasets like WikiText (25-40% expected).\")\n",
    "    print(\"      Empty lines between paragraphs/sections are filtered during preprocessing.\")\n",
    "    print(\"      Training will continue with valid content sequences...\")\n",
    "elif filter_rate < 0.60:\n",
    "    print(f\"   \ud83d\udd36 Very high filter rate: {filter_rate:.1%}\")\n",
    "    print(\"      This is unusual but may be expected for certain datasets.\")\n",
    "    print(\"      Review your dataset if this seems incorrect.\")\n",
    "    print(\"      Training will continue, but results may be affected...\")\n",
    "else:\n",
    "    print(f\"   \ud83d\udea8 CRITICAL: Extremely high filter rate: {filter_rate:.1%}\")\n",
    "    print(\"      This suggests possible data corruption or incorrect dataset.\")\n",
    "    print(f\"      {validation_result.metrics['filtered_sequences']} of {validation_result.metrics['sample_size']} sequences will be filtered.\")\n",
    "    print(\"\\nRecommended actions:\")\n",
    "    print(\"  1. Verify dataset source (is it corrupted?)\")\n",
    "    print(\"  2. Check tokenization settings\")\n",
    "    print(\"  3. Review data preprocessing steps\")\n",
    "    user_input = input(\"\\nContinue training anyway? (yes/no): \")\n",
    "    if user_input.lower() != 'yes':\n",
    "        raise ValueError(\"Training aborted by user due to data quality concerns\")\n",
    "\n",
    "# Print warnings (if any)\n",
    "for warning in validation_result.warnings:\n",
    "    print(f\"   \u2139\ufe0f {warning}\")\n",
    "\n",
    "# LAYER 2: Filter short sequences (preprocessing - runs once)\n",
    "print(f\"\\n[2/2] Filtering sequences < {min_seq_len} tokens...\")\n",
    "print(f\"   Before: {len(train_data)} training sequences\")\n",
    "\n",
    "train_data = filter_short_sequences(train_data, min_length=min_seq_len, verbose=True)\n",
    "val_data = filter_short_sequences(val_data, min_length=min_seq_len, verbose=True)\n",
    "\n",
    "print(f\"   After: {len(train_data)} training sequences\")\n",
    "print(f\"\\n\u2705 Data quality validation complete!\")\n",
    "print(\"=\" * 70)\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56295914",
   "metadata": {},
   "source": [
    "<a id=\"section-4\"></a>\n",
    "# \u2699\ufe0f Section 4: Training Configuration\n",
    "\n",
    "Configure hyperparameters using Colab forms below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "269a022f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title \u2699\ufe0f Training Configuration (v3.5/v3.6 Features) { display-mode: \"form\" }\n",
    "\n",
    "# === SELF-CONTAINED IMPORTS ===\n",
    "import sys\n",
    "import os\n",
    "if '.' not in sys.path:\n",
    "    sys.path.insert(0, '.')\n",
    "\n",
    "# Import with error handling\n",
    "try:\n",
    "    from utils.training.training_config import TrainingConfig\n",
    "    import torch\n",
    "except ImportError as e:\n",
    "    print(\"\u274c Import failed!\")\n",
    "    print(f\"\\nError: {e}\")\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"TROUBLESHOOTING\")\n",
    "    print(\"=\"*70)\n",
    "    print(\"\\n1. Run the 'Prerequisite Validation' cell in Section 1\")\n",
    "    print(\"2. Ensure utils package is properly installed\")\n",
    "    print(\"3. Run all previous cells in order\")\n",
    "    raise\n",
    "\n",
    "# Prerequisite check\n",
    "if 'workspace_root' not in globals():\n",
    "    print(\"\u274c workspace_root not found!\")\n",
    "    print(\"\\n\ud83d\udccd You are here: Section 4 (Training Configuration)\")\n",
    "    print(\"\\n\u26a0\ufe0f  Required: Run Section 1 (Setup & Drive Workspace) first\")\n",
    "    raise NameError(\"workspace_root not defined. Run Section 1 setup cells.\")\n",
    "\n",
    "if 'task_spec' not in globals():\n",
    "    print(\"\u274c task_spec not found!\")\n",
    "    print(\"\\n\ud83d\udccd You are here: Section 4 (Training Configuration)\")\n",
    "    print(\"\\n\u26a0\ufe0f  Required: Run Section 3 (Task Specification) first\")\n",
    "    raise NameError(\"task_spec not defined. Run Task Specification cell in Section 3.\")\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"TRAINING CONFIGURATION\")\n",
    "print(\"=\" * 70)\n",
    "print()\n",
    "\n",
    "# === HYPERPARAMETERS ===\n",
    "learning_rate = 5e-5  #@param {type:\"number\"}\n",
    "batch_size = 4  #@param {type:\"integer\"}\n",
    "epochs = 10  #@param {type:\"integer\"}\n",
    "warmup_ratio = 0.1  #@param {type:\"number\"}\n",
    "weight_decay = 0.01  #@param {type:\"number\"}\n",
    "gradient_clip_norm = 1.0  #@param {type:\"number\"}\n",
    "\n",
    "# === v3.5 PERFORMANCE FEATURES ===\n",
    "# torch.compile: 10-20% speedup (PyTorch 2.0+)\n",
    "compile_mode = \"default\"  #@param [\"None\", \"default\", \"reduce-overhead\", \"max-autotune\"]\n",
    "compile_mode = None if compile_mode == \"None\" else compile_mode\n",
    "\n",
    "# Gradient accumulation: effective batch size = batch_size * accumulation_steps\n",
    "gradient_accumulation_steps = 1  #@param {type:\"integer\"}\n",
    "\n",
    "# === v3.5 EXPORT FEATURES ===\n",
    "# Export bundle generation\n",
    "export_bundle = True  #@param {type:\"boolean\"}\n",
    "export_formats_str = \"onnx,torchscript,pytorch\"  #@param {type:\"string\"}\n",
    "export_formats = [fmt.strip() for fmt in export_formats_str.split(',')]\n",
    "\n",
    "# === STANDARD TRAINING FEATURES ===\n",
    "use_amp = True  #@param {type:\"boolean\"}\n",
    "deterministic = False  #@param {type:\"boolean\"}\n",
    "run_name = \"training-run\"  #@param {type:\"string\"}\n",
    "random_seed = 42  #@param {type:\"integer\"}\n",
    "\n",
    "# Create TrainingConfig\n",
    "training_config = TrainingConfig(\n",
    "    # Hyperparameters\n",
    "    learning_rate=learning_rate,\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    warmup_ratio=warmup_ratio,\n",
    "    weight_decay=weight_decay,\n",
    "    max_grad_norm=gradient_clip_norm,\n",
    "    \n",
    "    # v3.5 features\n",
    "    compile_mode=compile_mode,\n",
    "    gradient_accumulation_steps=gradient_accumulation_steps,\n",
    "    export_bundle=export_bundle,\n",
    "    export_formats=export_formats,\n",
    "    export_dir=f'{workspace_root}/exports',\n",
    "    \n",
    "    # Standard features\n",
    "    use_amp=use_amp,\n",
    "    deterministic=deterministic,\n",
    "    random_seed=random_seed,\n",
    "    run_name=run_name,\n",
    "    \n",
    "    # Directories\n",
    "    checkpoint_dir=f'{workspace_root}/checkpoints',\n",
    ")\n",
    "\n",
    "# Validate configuration\n",
    "training_config.validate()\n",
    "\n",
    "# Save to Drive with proper filename\n",
    "import os\n",
    "from datetime import datetime\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "config_filename = f\"config_{training_config.run_name}_{timestamp}.json\"\n",
    "config_path = os.path.join(f'{workspace_root}/configs', config_filename)\n",
    "training_config.save(config_path)\n",
    "print(f\"\u2705 Config saved: {config_path}\")\n",
    "print()\n",
    "\n",
    "# Display configuration summary\n",
    "print(\"HYPERPARAMETERS\")\n",
    "print(\"-\" * 70)\n",
    "print(f\"{'Run Name:':<30} {training_config.run_name}\")\n",
    "print(f\"{'Learning Rate:':<30} {training_config.learning_rate}\")\n",
    "print(f\"{'Batch Size (per step):':<30} {training_config.batch_size}\")\n",
    "print(f\"{'Effective Batch Size:':<30} {training_config.batch_size * training_config.gradient_accumulation_steps}\")\n",
    "print(f\"{'Epochs:':<30} {training_config.epochs}\")\n",
    "print(f\"{'Warmup Ratio:':<30} {training_config.warmup_ratio}\")\n",
    "print(f\"{'Weight Decay:':<30} {training_config.weight_decay}\")\n",
    "print(f\"{'Gradient Clipping:':<30} {gradient_clip_norm}\")\n",
    "print()\n",
    "\n",
    "print(\"v3.5 PERFORMANCE FEATURES\")\n",
    "print(\"-\" * 70)\n",
    "print(f\"{'torch.compile:':<30} {compile_mode or 'Disabled'}\")\n",
    "if compile_mode:\n",
    "    expected_speedup = {\"default\": \"10-15%\", \"reduce-overhead\": \"15-20%\", \"max-autotune\": \"20-30%\"}\n",
    "    print(f\"{'  Expected speedup:':<30} ~{expected_speedup.get(compile_mode, '10-20%')}\")\n",
    "    print(f\"{'  Compilation time:':<30} {'~30s' if compile_mode == 'max-autotune' else '~5s'}\")\n",
    "print()\n",
    "print(f\"{'Gradient Accumulation:':<30} {gradient_accumulation_steps}x\")\n",
    "if gradient_accumulation_steps > 1:\n",
    "    log_reduction = 100 * (1 - 1/gradient_accumulation_steps)\n",
    "    print(f\"{'  W&B log reduction:':<30} ~{log_reduction:.0f}%\")\n",
    "    print(f\"{'  Memory efficient:':<30} Train larger models on same GPU\")\n",
    "print()\n",
    "\n",
    "print(\"v3.5 EXPORT FEATURES\")\n",
    "print(\"-\" * 70)\n",
    "print(f\"{'Export Bundle:':<30} {'Enabled' if export_bundle else 'Disabled'}\")\n",
    "if export_bundle:\n",
    "    print(f\"{'  Formats:':<30} {', '.join(export_formats)}\")\n",
    "    print(f\"{'  Output dir:':<30} {training_config.export_dir}\")\n",
    "    print(f\"{'  Includes:':<30} Dockerfile, inference.py, README\")\n",
    "print()\n",
    "\n",
    "print(\"v3.6 AUTOMATIC FEATURES\")\n",
    "print(\"-\" * 70)\n",
    "print(f\"{'Distributed Guardrails:':<30} \u2705 Active (notebook detection)\")\n",
    "print(f\"{'  Prevents:':<30} DDP/FSDP zombie processes in Jupyter/Colab\")\n",
    "print()\n",
    "print(f\"{'Flash Attention:':<30} Auto-enabled (PyTorch 2.0+ + CUDA)\")\n",
    "if torch.__version__ >= \"2.0.0\" and torch.cuda.is_available():\n",
    "    print(f\"{'  Status:':<30} \u2705 Will be enabled during training\")\n",
    "    print(f\"{'  Expected speedup:':<30} 2-4x for attention operations\")\n",
    "elif torch.__version__ < \"2.0.0\":\n",
    "    print(f\"{'  Status:':<30} \u26a0\ufe0f  Requires PyTorch 2.0+\")\n",
    "else:\n",
    "    print(f\"{'  Status:':<30} \u26a0\ufe0f  Requires CUDA (GPU)\")\n",
    "print()\n",
    "print(f\"{'Drift Visualization:':<30} Available via plot_with_drift()\")\n",
    "print(f\"{'  Panels:':<30} 10-panel dashboard (6 training + 4 drift)\")\n",
    "print()\n",
    "\n",
    "print(\"STANDARD FEATURES\")\n",
    "print(\"-\" * 70)\n",
    "print(f\"{'Mixed Precision (AMP):':<30} {'Enabled' if use_amp else 'Disabled'}\")\n",
    "print(f\"{'Deterministic Mode:':<30} {'Enabled' if deterministic else 'Disabled (fast)'}\")\n",
    "print(f\"{'Random Seed:':<30} {random_seed}\")\n",
    "print(f\"{'Data Source:':<30} {data_source if 'data_source' in globals() else 'N/A'}\")\n",
    "print()\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"\u2705 CONFIGURATION COMPLETE\")\n",
    "print(\"=\" * 70)\n",
    "print()\n",
    "print(\"\ud83d\udca1 Proceed to Section 6 for training with all features enabled\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b568df14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display configuration summary\n",
    "print(\"=\" * 60)\n",
    "print(\" \" * 15 + \"TRAINING CONFIGURATION\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"{'Run Name:':<25} {training_config.run_name}\")\n",
    "print(f\"{'Learning Rate:':<25} {training_config.learning_rate}\")\n",
    "print(f\"{'Batch Size (effective):':<25} {training_config.batch_size * training_config.gradient_accumulation_steps}\")\n",
    "print(f\"{'Epochs:':<25} {training_config.epochs}\")\n",
    "print(f\"{'Warmup Ratio:':<25} {training_config.warmup_ratio}\")\n",
    "print(f\"{'Gradient Clipping:':<25} {training_config.max_grad_norm}\")\n",
    "print(f\"{'AMP Enabled:':<25} {training_config.use_amp}\")\n",
    "print(f\"{'Deterministic:':<25} {training_config.deterministic}\")\n",
    "print(f\"{'Random Seed:':<25} {training_config.random_seed}\")\n",
    "print(f\"{'Data Source:':<25} {data_source if 'data_source' in globals() else 'N/A'}\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c5e4445",
   "metadata": {},
   "source": [
    "### Training Mode Selection\n",
    "\n",
    "Based on your `epochs` setting:\n",
    "- **epochs <= 5**: \u26a1 Fast Mode (~5 min)\n",
    "- **epochs <= 15**: \u2696\ufe0f Balanced Mode (~15 min)\n",
    "- **epochs > 15**: \ud83d\udc8e Quality Mode (45+ min)\n",
    "\n",
    "Proceed to training in Section 5 \u2b07\ufe0f"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d46ead6",
   "metadata": {},
   "source": [
    "<a id=\"section-5\"></a>\n",
    "# \ud83d\udd2c Section 5: W&B Tracking Setup (Optional)\n",
    "\n",
    "Enable Weights & Biases for cloud-based experiment tracking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae42ab74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "from getpass import getpass\n",
    "\n",
    "use_wandb = True  #@param {type:\"boolean\"}\n",
    "wandb_project = \"transformer-training\"  #@param {type:\"string\"}\n",
    "wandb_entity = \"\"  #@param {type:\"string\"}\n",
    "\n",
    "if use_wandb:\n",
    "    # Login to W&B\n",
    "    wandb_key = getpass(\"Enter W&B API key (or leave blank to skip): \")\n",
    "    if wandb_key:\n",
    "        wandb.login(key=wandb_key)\n",
    "\n",
    "        # Initialize run\n",
    "        wandb.init(\n",
    "            project=wandb_project,\n",
    "            entity=wandb_entity if wandb_entity else None,\n",
    "            name=config.run_name,\n",
    "            config=config.to_dict(),\n",
    "            tags=[data_source, f\"epochs_{epochs}\"]\n",
    "        )\n",
    "        print(f\"\u2705 W&B initialized: {wandb.run.url}\")\n",
    "    else:\n",
    "        use_wandb = False\n",
    "        print(\"\u26a0\ufe0f W&B skipped - training will use local tracking only\")\n",
    "else:\n",
    "    print(\"\u2139\ufe0f W&B disabled - using local SQLite tracking\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rqtj1fr1pf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title \ud83d\udcca Dataset Drift Profiling (v3.6 - Optional, 1-2 min) { display-mode: \"form\" }\n",
    "\n",
    "enable_drift_detection = True  #@param {type:\"boolean\"}\n",
    "drift_sample_size = 1000  #@param {type:\"integer\"}\n",
    "\n",
    "drift_data = None\n",
    "\n",
    "if enable_drift_detection:\n",
    "    print(\"=\" * 70)\n",
    "    print(\"DATASET DRIFT PROFILING (v3.6)\")\n",
    "    print(\"=\" * 70)\n",
    "    print()\n",
    "    print(\"\ud83d\udcca Computing dataset profiles for drift detection...\")\n",
    "    print(f\"   Sample size: {min(drift_sample_size, len(train_data))} from training\")\n",
    "    print(f\"   Sample size: {min(drift_sample_size, len(val_data))} from validation\")\n",
    "    print()\n",
    "    \n",
    "    try:\n",
    "        # Profile training dataset (reference)\n",
    "        print(\"1/2 Profiling training dataset...\")\n",
    "        train_subset = train_data[:drift_sample_size] if isinstance(train_data, list) else train_data\n",
    "        train_profile = compute_dataset_profile(\n",
    "            dataset=train_subset,\n",
    "            task_spec=task_spec,\n",
    "            sample_size=drift_sample_size\n",
    "        )\n",
    "        print(\"   \u2705 Training profile complete\")\n",
    "        \n",
    "        # Profile validation dataset (comparison)\n",
    "        print(\"2/2 Profiling validation dataset...\")\n",
    "        val_subset = val_data[:drift_sample_size] if isinstance(val_data, list) else val_data\n",
    "        val_profile = compute_dataset_profile(\n",
    "            dataset=val_subset,\n",
    "            task_spec=task_spec,\n",
    "            sample_size=drift_sample_size\n",
    "        )\n",
    "        print(\"   \u2705 Validation profile complete\")\n",
    "        print()\n",
    "        \n",
    "        # Compare profiles\n",
    "        print(\"\ud83d\udd0d Computing drift scores...\")\n",
    "        drift_comparison = compare_profiles(train_profile, val_profile)\n",
    "        \n",
    "        # Display results\n",
    "        print()\n",
    "        print(\"DRIFT DETECTION RESULTS\")\n",
    "        print(\"-\" * 70)\n",
    "        \n",
    "        max_drift = 0.0\n",
    "        for metric, score in drift_comparison['drift_scores'].items():\n",
    "            max_drift = max(max_drift, score)\n",
    "            \n",
    "            # Determine status\n",
    "            if score < 0.1:\n",
    "                status_emoji = '\u2705'\n",
    "                status_text = 'Healthy'\n",
    "            elif score < 0.2:\n",
    "                status_emoji = '\u26a0\ufe0f '\n",
    "                status_text = 'Warning'\n",
    "            else:\n",
    "                status_emoji = '\ud83d\udea8'\n",
    "                status_text = 'Critical'\n",
    "            \n",
    "            print(f\"{status_emoji} {metric:<25} {score:.4f} ({status_text})\")\n",
    "        \n",
    "        print(\"-\" * 70)\n",
    "        print()\n",
    "        \n",
    "        # Overall status\n",
    "        if max_drift < 0.1:\n",
    "            overall_status = 'ok'\n",
    "            print(\"\u2705 HEALTHY: Minimal drift detected\")\n",
    "            print(\"   Training and validation datasets are well-matched\")\n",
    "        elif max_drift < 0.2:\n",
    "            overall_status = 'warn'\n",
    "            print(\"\u26a0\ufe0f  WARNING: Moderate drift detected\")\n",
    "            print(\"   Recommendation:\")\n",
    "            print(\"   - Monitor training metrics closely\")\n",
    "            print(\"   - Consider reviewing train/val split\")\n",
    "        else:\n",
    "            overall_status = 'alert'\n",
    "            print(\"\ud83d\udea8 CRITICAL: Significant drift detected!\")\n",
    "            print(\"   Action Required:\")\n",
    "            print(\"   - Check data preprocessing consistency\")\n",
    "            print(\"   - Review train/val split strategy\")\n",
    "            print(\"   - Investigate distribution shift causes\")\n",
    "            \n",
    "            if task_modality == \"text\":\n",
    "                print()\n",
    "                print(\"   Common causes for text:\")\n",
    "                print(\"   - Different text sources (news vs social media)\")\n",
    "                print(\"   - Language/domain shift (formal vs casual)\")\n",
    "                print(\"   - Tokenization inconsistencies\")\n",
    "            elif task_modality == \"vision\":\n",
    "                print()\n",
    "                print(\"   Common causes for vision:\")\n",
    "                print(\"   - Different image preprocessing\")\n",
    "                print(\"   - Lighting conditions (indoor vs outdoor)\")\n",
    "                print(\"   - Camera/sensor differences\")\n",
    "        \n",
    "        print()\n",
    "        print(f\"Max Drift Score: {max_drift:.4f}\")\n",
    "        print()\n",
    "        \n",
    "        # Package for dashboard visualization\n",
    "        drift_data = {\n",
    "            'ref_profile': train_profile,\n",
    "            'new_profile': val_profile,\n",
    "            'drift_scores': drift_comparison['drift_scores'],\n",
    "            'status': overall_status\n",
    "        }\n",
    "        \n",
    "        print(\"=\" * 70)\n",
    "        print(\"\u2705 DRIFT PROFILING COMPLETE\")\n",
    "        print(\"=\" * 70)\n",
    "        print()\n",
    "        print(\"\ud83d\udca1 Drift visualization will be available in Section 7 dashboard\")\n",
    "        print()\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\u274c Drift profiling failed: {e}\")\n",
    "        print(\"   Continuing without drift detection\")\n",
    "        drift_data = None\n",
    "else:\n",
    "    print(\"=\" * 70)\n",
    "    print(\"DRIFT PROFILING SKIPPED\")\n",
    "    print(\"=\" * 70)\n",
    "    print()\n",
    "    print(\"\u2139\ufe0f  Drift detection disabled\")\n",
    "    print(\"   Set enable_drift_detection=True to enable\")\n",
    "    print()\n",
    "    print(\"\ud83d\udca1 Benefits of drift detection:\")\n",
    "    print(\"   - Early warning of data distribution shifts\")\n",
    "    print(\"   - Helps diagnose training issues\")\n",
    "    print(\"   - Validates train/val split quality\")\n",
    "    print(\"=\" * 70)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62ce57e5",
   "metadata": {},
   "source": [
    "<a id=\"section-6\"></a>\n",
    "# \ud83c\udfcb\ufe0f Section 6: Training Loop\n",
    "\n",
    "Main training loop with live visualization and checkpointing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c08c98ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title \ud83d\ude80 Data Module Setup (v4.0) { display-mode: \"form\" }\n",
    "\n",
    "from utils.training.seed_manager import set_random_seed\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"DATA MODULE SETUP\")\n",
    "print(\"=\" * 70)\n",
    "print()\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "print(f\"\ud83c\udfb2 Setting random seed: {training_config.random_seed}\")\n",
    "set_random_seed(training_config.random_seed, training_config.deterministic)\n",
    "print(f\"   Mode: {'Deterministic (bit-exact)' if training_config.deterministic else 'Fast (cuDNN auto-tuning)'}\")\n",
    "print()\n",
    "\n",
    "# Create data module\n",
    "print(\"\ud83d\udce6 Creating SimpleDataModule...\")\n",
    "\n",
    "# For text tasks, we need to handle tokenization\n",
    "if task_spec.modality == \"text\":\n",
    "    # \u2705 PRESERVE tokenizer from Cell 21 (AdaptiveTokenizer)\n",
    "    # v4.0 REQUIREMENT: Text tasks need tokenizer for data collation\n",
    "    print(\"   Modality: TEXT\")\n",
    "    \n",
    "    # Validate tokenizer exists\n",
    "    if 'tokenizer' not in globals() or tokenizer is None:\n",
    "        raise ValueError(\n",
    "            \"\u274c tokenizer not found!\\n\\n\"\n",
    "            \"Text tasks require tokenizer for data collation (v4.0+).\\n\\n\"\n",
    "            \"Fix: Run Cell 21 (Data Tokenization & Preprocessing) first.\"\n",
    "        )\n",
    "    \n",
    "    print(f\"   Tokenizer: {type(tokenizer).__name__}\")\n",
    "    print(f\"   Data format: Pre-tokenized (fixed length)\")\n",
    "    \n",
    "    # Create simple wrapper if data is already tokenized\n",
    "    final_train_data = train_data\n",
    "    final_val_data = val_data\n",
    "    # \u2705 tokenizer already exists from Cell 21 - keep it!\n",
    "    \n",
    "else:  # vision\n",
    "    print(f\"   Modality: VISION\")\n",
    "    print(f\"   VisionDataCollator will be auto-selected (v3.5)\")\n",
    "    final_train_data = train_data\n",
    "    final_val_data = val_data\n",
    "    tokenizer = None  # \u2705 Vision tasks don't need tokenizer\n",
    "\n",
    "# Create data module\n",
    "data_module = SimpleDataModule(\n",
    "    train_dataset=final_train_data,\n",
    "    val_dataset=final_val_data,\n",
    "    task_spec=task_spec,\n",
    "    batch_size=training_config.batch_size,\n",
    "    num_workers=2,\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "print(f\"\u2705 Data module created\")\n",
    "approx_train_batches = len(final_train_data) // training_config.batch_size\n",
    "approx_val_batches = len(final_val_data) // training_config.batch_size\n",
    "print(f\"   Train batches: ~{approx_train_batches}\")\n",
    "print(f\"   Val batches: ~{approx_val_batches}\")\n",
    "print()\n",
    "\n",
    "# Display v4.0 features\n",
    "print(\"v4.0 FEATURES\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "# Tokenizer requirement for text tasks\n",
    "if task_spec.modality == \"text\":\n",
    "    print(f\"Tokenizer Requirement (v4.0):\")\n",
    "    print(f\"   \u2705 Tokenizer provided: {type(tokenizer).__name__}\")\n",
    "    print(f\"   Auto-collator: LanguageModelingDataCollator\")\n",
    "    print(f\"   Handles variable-length sequences automatically\")\n",
    "else:\n",
    "    print(f\"VisionDataCollator (v3.5):\")\n",
    "    print(f\"   \u2705 Auto-selected for vision tasks\")\n",
    "    print(f\"   Handles image tensors and normalization\")\n",
    "\n",
    "print()\n",
    "\n",
    "# Display v3.6 automatic features\n",
    "print(\"v3.6 AUTOMATIC FEATURES\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "# Check Flash Attention\n",
    "if torch.cuda.is_available() and torch.__version__ >= \"2.0.0\":\n",
    "    # Flash Attention will be detected by UniversalModelAdapter\n",
    "    print(\"Flash Attention:\")\n",
    "    print(f\"   \u2705 Available (PyTorch {torch.__version__} + CUDA)\")\n",
    "    print(f\"   Will be auto-enabled during training\")\n",
    "    print(f\"   Expected speedup: 2-4x for attention operations\")\n",
    "else:\n",
    "    print(\"Flash Attention:\")\n",
    "    if not torch.cuda.is_available():\n",
    "        print(f\"   \u26a0\ufe0f  Requires CUDA (currently on CPU)\")\n",
    "    else:\n",
    "        print(f\"   \u26a0\ufe0f  Requires PyTorch 2.0+ (currently {torch.__version__})\")\n",
    "    print(f\"   Falling back to standard attention\")\n",
    "\n",
    "print()\n",
    "\n",
    "# Distributed guardrails\n",
    "print(\"Distributed Training Guardrails:\")\n",
    "print(f\"   \u2705 Active (notebook environment detection)\")\n",
    "print(f\"   Prevents DDP/FSDP zombie processes in Jupyter/Colab\")\n",
    "\n",
    "print()\n",
    "\n",
    "# Display v3.5 features\n",
    "print(\"v3.5 FEATURES\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "if training_config.compile_mode:\n",
    "    print(f\"torch.compile:\")\n",
    "    print(f\"   \u2705 Enabled ({training_config.compile_mode} mode)\")\n",
    "    print(f\"   Expected speedup: ~10-20%\")\n",
    "    print(f\"   First epoch will be slower due to compilation\")\n",
    "else:\n",
    "    print(f\"torch.compile: Disabled\")\n",
    "\n",
    "print()\n",
    "\n",
    "if training_config.gradient_accumulation_steps > 1:\n",
    "    print(f\"Gradient Accumulation:\")\n",
    "    print(f\"   \u2705 {training_config.gradient_accumulation_steps}x steps\")\n",
    "    print(f\"   Effective batch size: {training_config.batch_size * training_config.gradient_accumulation_steps}\")\n",
    "    log_reduction = 100 * (1 - 1/training_config.gradient_accumulation_steps)\n",
    "    print(f\"   W&B log reduction: ~{log_reduction:.0f}%\")\n",
    "\n",
    "print()\n",
    "print(\"=\" * 70)\n",
    "print(\"\u2705 SETUP COMPLETE - Ready for Training\")\n",
    "print(\"=\" * 70)\n",
    "print()\n",
    "print(\"\ud83d\udca1 Run the next cell to start training with Trainer (v4.0)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcaa782a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title \u25b6\ufe0f Run Training { display-mode: \"form\" }\n",
    "\n",
    "import time\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"TRAINING EXECUTION\")\n",
    "print(\"=\" * 70)\n",
    "print()\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "print(f\"\ud83c\udfcb\ufe0f  Starting training with {training_config.epochs} epochs...\")\n",
    "print(f\"   Run name: {run_name}\")\n",
    "print(f\"   Batch size: {training_config.batch_size}\")\n",
    "print(f\"   Learning rate: {training_config.learning_rate}\")\n",
    "print()\n",
    "\n",
    "try:\n",
    "    # === PREREQUISITE VALIDATION (v4.0) ===\n",
    "    print(\"\ud83d\udd0d Validating prerequisites...\")\n",
    "    \n",
    "    # Check required variables exist\n",
    "    required_vars = ['model', 'config_obj', 'training_config', 'task_spec', 'train_data', 'val_data']\n",
    "    missing = [v for v in required_vars if v not in globals()]\n",
    "    if missing:\n",
    "        raise NameError(\n",
    "            f\"\u274c Missing prerequisites: {missing}\\n\\n\"\n",
    "            \"Fix: Run prerequisite cells in order:\\n\"\n",
    "            \"  Cell 8 (imports) \u2192 Cell 13 (model) \u2192 Cell 19 (data) \u2192\\n\"\n",
    "            \"  Cell 20 (task spec) \u2192 Cell 21 (tokenization) \u2192 Cell 23 (config)\"\n",
    "        )\n",
    "    \n",
    "    # v4.0: Text tasks require tokenizer for data collation\n",
    "    if task_spec.modality == 'text':\n",
    "        if 'tokenizer' not in globals() or tokenizer is None:\n",
    "            raise ValueError(\n",
    "                \"\u274c tokenizer is None for text task!\\n\\n\"\n",
    "                \"Cause: Cell 30 may have overwritten tokenizer from Cell 21,\\n\"\n",
    "                \"       or Cell 21 was not run.\\n\\n\"\n",
    "                \"Fix:\\n\"\n",
    "                \"  1. Re-run Cell 21 (Data Tokenization & Preprocessing)\\n\"\n",
    "                \"  2. Ensure Cell 30 doesn't set tokenizer=None for text tasks\\n\"\n",
    "                \"  3. Re-run this cell\\n\"\n",
    "            )\n",
    "        if not hasattr(tokenizer, 'encode') and not callable(tokenizer):\n",
    "            raise ValueError(\n",
    "                f\"\u274c Invalid tokenizer type: {type(tokenizer)}\\n\\n\"\n",
    "                f\"Expected: AdaptiveTokenizer or HuggingFace tokenizer\\n\"\n",
    "                f\"Got: {type(tokenizer).__name__}\\n\\n\"\n",
    "                f\"Fix: Re-run Cell 21 to create valid tokenizer\"\n",
    "            )\n",
    "        print(f\"   \u2705 Tokenizer validated: {type(tokenizer).__name__}\")\n",
    "    else:\n",
    "        print(f\"   \u2705 Prerequisites validated (modality: {task_spec.modality})\")\n",
    "    \n",
    "    print()\n",
    "\n",
    "    # Initialize Trainer\n",
    "    print(\"\ud83d\udd27 Initializing Trainer...\")\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        config=config_obj,\n",
    "        training_config=training_config,\n",
    "        task_spec=task_spec,\n",
    "        tokenizer=tokenizer  # \u2705 CRITICAL FOR TEXT TASKS (v4.0)\n",
    "    )\n",
    "    print(\"   \u2705 Trainer initialized\")\n",
    "    print(f\"   - torch.compile: {'Enabled' if training_config.compile_mode else 'Disabled'}\")\n",
    "    print(f\"   - Gradient accumulation: {training_config.gradient_accumulation_steps} steps\")\n",
    "    print()\n",
    "\n",
    "    # Execute training\n",
    "    print(\"\u2699\ufe0f  Training in progress...\")\n",
    "    print(\"   (This may take several minutes depending on your configuration)\")\n",
    "    print()\n",
    "\n",
    "    results = trainer.train(\n",
    "        train_data=train_data,\n",
    "        val_data=val_data\n",
    "    )\n",
    "\n",
    "    # Process results\n",
    "    elapsed = time.time() - start_time\n",
    "\n",
    "    print()\n",
    "    print(\"=\" * 70)\n",
    "    print(\"TRAINING COMPLETE\")\n",
    "    print(\"=\" * 70)\n",
    "    print()\n",
    "    print(f\"\u2705 Training finished in {elapsed:.1f}s ({elapsed/60:.1f} min)\")\n",
    "    print()\n",
    "    print(f\"\ud83d\udcca Final Metrics:\")\n",
    "    print(f\"   Train Loss: {results['loss_history'][-1]:.4f}\")\n",
    "\n",
    "    # Get final validation metrics from summary\n",
    "    if 'metrics_summary' in results and not results['metrics_summary'].empty:\n",
    "        final_metrics = results['metrics_summary'].iloc[-1]\n",
    "        if 'val/loss' in final_metrics:\n",
    "            print(f\"   Val Loss: {final_metrics['val/loss']:.4f}\")\n",
    "        if 'val/perplexity' in final_metrics:\n",
    "            print(f\"   Perplexity: {final_metrics['val/perplexity']:.2f}\")\n",
    "\n",
    "    print(f\"   Best Epoch: {results['best_epoch']}\")\n",
    "    print()\n",
    "\n",
    "    # Save checkpoint\n",
    "    if training_config.checkpoint_dir:\n",
    "        checkpoint_path = f\"{training_config.checkpoint_dir}/final_model.pt\"\n",
    "        import torch\n",
    "        torch.save({\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'training_config': training_config.to_dict(),\n",
    "            'results': results,\n",
    "            'epoch': training_config.epochs\n",
    "        }, checkpoint_path)\n",
    "        print(f\"\ud83d\udcbe Final checkpoint saved: {checkpoint_path}\")\n",
    "        print()\n",
    "\n",
    "    # Log to ExperimentDB (if configured)\n",
    "    if 'db' in globals() and db is not None:\n",
    "        try:\n",
    "            run_id = db.log_run(\n",
    "                run_name=run_name,\n",
    "                config=training_config.to_dict(),\n",
    "                notes=training_config.notes or \"Training run from notebook\"\n",
    "            )\n",
    "\n",
    "            # Log metrics per epoch\n",
    "            for epoch_idx, loss in enumerate(results['loss_history']):\n",
    "                db.log_metric(run_id, 'train/loss', loss, epoch=epoch_idx)\n",
    "\n",
    "            # Log final checkpoint\n",
    "            if 'checkpoint_paths' in results and results['checkpoint_paths']:\n",
    "                best_checkpoint = results['checkpoint_paths'][-1]\n",
    "                db.log_artifact(\n",
    "                    run_id,\n",
    "                    'checkpoint',\n",
    "                    best_checkpoint,\n",
    "                    metadata={'epoch': results['best_epoch']}\n",
    "                )\n",
    "\n",
    "            db.update_run_status(run_id, 'completed')\n",
    "            print(f\"\ud83d\udcdd Logged to ExperimentDB: run_id={run_id}\")\n",
    "            print()\n",
    "        except Exception as e:\n",
    "            print(f\"\u26a0\ufe0f  ExperimentDB logging failed: {e}\")\n",
    "            print(\"   (Training results still available in 'results' variable)\")\n",
    "\n",
    "    print(\"=\" * 70)\n",
    "    print()\n",
    "    print(\"\ud83d\udca1 Next Steps:\")\n",
    "    print(\"   1. Run the 'Training Dashboard' cell below to visualize metrics\")\n",
    "    print(\"   2. Use results['metrics_summary'] for detailed analysis\")\n",
    "    print(\"   3. Check results['checkpoint_paths'] for saved models\")\n",
    "    print(\"=\" * 70)\n",
    "\n",
    "except Exception as e:\n",
    "    print()\n",
    "    print(\"\u274c Training failed!\")\n",
    "    print(f\"\\nError: {e}\")\n",
    "    print(\"\\nTroubleshooting:\")\n",
    "    print(\"  1. Check that model is properly initialized\")\n",
    "    print(\"  2. Verify train_data and val_data are correctly preprocessed\")\n",
    "    print(\"  3. Ensure sufficient GPU memory (reduce batch_size if OOM)\")\n",
    "    print(\"  4. Review training_config parameters\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "cellView": "form"
   },
   "source": [
    "# @title \ud83d\udd27 Optional: Recover Training Results from Checkpoint { display-mode: \"form\" }\n",
    "\n",
    "# ============================================================================\n",
    "# CHECKPOINT RECOVERY\n",
    "#\n",
    "# Use this cell to recover results from a saved checkpoint if:\n",
    "# - Training was interrupted (error, runtime disconnect, etc.)\n",
    "# - You want to analyze a previous training run\n",
    "# - You need to resume from a specific epoch\n",
    "#\n",
    "# The checkpoint contains full metrics history saved during training.\n",
    "# This cell is SELF-CONTAINED and doesn't require prior training cell execution.\n",
    "# ============================================================================\n",
    "\n",
    "# @markdown ### Checkpoint Directory\n",
    "# @markdown Specify where your checkpoints are saved:\n",
    "checkpoint_directory = \"/content/drive/MyDrive/TransformerTraining/checkpoints\"  #@param {type:\"string\"}\n",
    "\n",
    "from utils.training.engine.recovery import recover_training_results, list_checkpoints\n",
    "from utils.training.config import TrainingConfig\n",
    "import os\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"CHECKPOINT RECOVERY\")\n",
    "print(\"=\" * 70)\n",
    "print()\n",
    "\n",
    "# Try multiple common checkpoint locations if specified path doesn't exist\n",
    "checkpoint_search_paths = [\n",
    "    checkpoint_directory,\n",
    "    \"/content/workspace/checkpoints\",\n",
    "    \"./training_output/checkpoints\",\n",
    "    \"./tmp_training_output/checkpoints\"\n",
    "]\n",
    "\n",
    "# Find first existing checkpoint directory\n",
    "ckpt_dir = None\n",
    "for path in checkpoint_search_paths:\n",
    "    if os.path.exists(path):\n",
    "        ckpt_dir = path\n",
    "        break\n",
    "\n",
    "if ckpt_dir is None:\n",
    "    print(\"\u274c No checkpoint directory found!\")\n",
    "    print(f\"   Searched locations:\")\n",
    "    for path in checkpoint_search_paths:\n",
    "        print(f\"     - {path}\")\n",
    "    print()\n",
    "    print(\"   \ud83d\udca1 Tip: Run training first or specify correct checkpoint_directory above\")\n",
    "else:\n",
    "    print(f\"\ud83d\udcc2 Using checkpoint directory: {ckpt_dir}\")\n",
    "    print()\n",
    "    \n",
    "    # List available checkpoints\n",
    "    print(\"\ud83d\udcc2 Available checkpoints:\")\n",
    "    checkpoints = list_checkpoints(ckpt_dir)\n",
    "    \n",
    "    if not checkpoints:\n",
    "        print(\"   \u274c No checkpoints found in directory\")\n",
    "        print(\"   \u2192 Run training first to create checkpoints\")\n",
    "    else:\n",
    "        print(f\"   Found {len(checkpoints)} checkpoint(s):\\n\")\n",
    "        for i, ckpt in enumerate(checkpoints[:5], 1):  # Show up to 5 most recent\n",
    "            print(f\"   {i}. Epoch {ckpt['epoch']:2d} | \"\n",
    "                  f\"train_loss={ckpt.get('train_loss', 0):.4f} | \"\n",
    "                  f\"val_loss={ckpt.get('val_loss', 0):.4f}\")\n",
    "            print(f\"      {ckpt['filename']}\")\n",
    "        print()\n",
    "    \n",
    "        # Recover from best checkpoint\n",
    "        print(\"\ud83d\udd04 Recovering training results from best checkpoint...\")\n",
    "        print()\n",
    "    \n",
    "        try:\n",
    "            # Recover results\n",
    "            results = recover_training_results(\n",
    "                checkpoint_dir=ckpt_dir,\n",
    "                monitor='val_loss',\n",
    "                mode='min'\n",
    "            )\n",
    "    \n",
    "            # Extract variables needed by downstream cells\n",
    "            metrics_df = results['metrics_summary']\n",
    "            workspace_root = results.get('workspace_root', os.path.dirname(ckpt_dir))\n",
    "            run_name = results.get('run_name', 'recovered_run')\n",
    "            \n",
    "            # Create minimal training_config for downstream cells\n",
    "            # This is a SimpleNamespace-like object that provides the expected attributes\n",
    "            from types import SimpleNamespace\n",
    "            training_config = SimpleNamespace(\n",
    "                run_name=run_name,\n",
    "                checkpoint_dir=ckpt_dir,\n",
    "                # Add other commonly accessed attributes\n",
    "                epochs=len(metrics_df) if metrics_df is not None else 0,\n",
    "            )\n",
    "            \n",
    "            # For backward compatibility, create 'config' alias\n",
    "            config = training_config\n",
    "            \n",
    "            # Calculate elapsed time from checkpoint if available\n",
    "            elapsed = results.get('training_time', 0.0)\n",
    "    \n",
    "            # Print results (matches Cell 32 output format)\n",
    "            print()\n",
    "            print(\"=\" * 70)\n",
    "            print(\"TRAINING COMPLETE (RECOVERED FROM CHECKPOINT)\")\n",
    "            print(\"=\" * 70)\n",
    "            print()\n",
    "            print(f\"\u2705 Training finished in {elapsed:.1f}s ({elapsed/60:.1f} min)\")\n",
    "            print()\n",
    "            print(f\"\ud83d\udcca Final Metrics:\")\n",
    "            print(f\"   Train Loss: {results['loss_history'][-1]:.4f}\")\n",
    "    \n",
    "            # Get final validation metrics from summary\n",
    "            if 'metrics_summary' in results and not results['metrics_summary'].empty:\n",
    "                final_metrics = results['metrics_summary'].iloc[-1]\n",
    "                if 'val/loss' in final_metrics:\n",
    "                    print(f\"   Val Loss: {final_metrics['val/loss']:.4f}\")\n",
    "                if 'val/perplexity' in final_metrics:\n",
    "                    print(f\"   Perplexity: {final_metrics['val/perplexity']:.2f}\")\n",
    "                if 'val/accuracy' in final_metrics:\n",
    "                    print(f\"   Accuracy: {final_metrics['val/accuracy']:.2%}\")\n",
    "    \n",
    "            print(f\"   Best Epoch: {results['best_epoch']}\")\n",
    "            print()\n",
    "            \n",
    "            # Set drift_data to None for recovered sessions (drift detection only runs during live training)\n",
    "            drift_data = None\n",
    "            \n",
    "            print(\"\u2705 Recovery complete! Variables populated:\")\n",
    "            print(f\"   - results: Training results dictionary\")\n",
    "            print(f\"   - metrics_df: {len(metrics_df)} epochs of metrics\")\n",
    "            print(f\"   - workspace_root: {workspace_root}\")\n",
    "            print(f\"   - training_config: Minimal config object\")\n",
    "            print(f\"   - config: Alias for training_config\")\n",
    "            print()\n",
    "    \n",
    "            # Log to ExperimentDB if available (optional)\n",
    "            if 'db' in globals() and db is not None:\n",
    "                try:\n",
    "                    # Create new run for recovered session\n",
    "                    new_run_id = db.log_run(\n",
    "                        run_name=f\"{run_name}_recovered\",\n",
    "                        config={'recovered': True, 'original_run': run_name},\n",
    "                        notes=f\"Recovered from checkpoint: {results['checkpoint_path']}\"\n",
    "                    )\n",
    "                    \n",
    "                    for _, row in metrics_df.iterrows():\n",
    "                        epoch = int(row['epoch'])\n",
    "                        db.log_metric(new_run_id, 'train/loss', row['train/loss'], epoch=epoch)\n",
    "                        if 'val/loss' in row:\n",
    "                            db.log_metric(new_run_id, 'val/loss', row['val/loss'], epoch=epoch)\n",
    "    \n",
    "                    # Log checkpoint path\n",
    "                    db.log_artifact(new_run_id, 'checkpoint', results['checkpoint_path'])\n",
    "                    db.update_run_status(new_run_id, 'completed')\n",
    "                    print(f\"\u2705 Metrics logged to ExperimentDB (run_id={new_run_id})\")\n",
    "                    print()\n",
    "                except Exception as e:\n",
    "                    print(f\"\u26a0\ufe0f  ExperimentDB logging skipped: {e}\")\n",
    "                    print()\n",
    "    \n",
    "            print(\"\ud83d\udca1 Next Steps:\")\n",
    "            print(\"   \u2192 Continue to Training Dashboard (Cell 35) to visualize metrics\")\n",
    "            print(\"   \u2192 Check Best Model Summary (Cell 36) for detailed analysis\")\n",
    "            print(\"   \u2192 Export metrics to CSV (Cell 37)\")\n",
    "    \n",
    "        except FileNotFoundError as e:\n",
    "            print(f\"\u274c Recovery failed: {e}\")\n",
    "            print(\"   Check that checkpoint files exist in the directory\")\n",
    "        except ValueError as e:\n",
    "            print(f\"\u274c Recovery failed: {e}\")\n",
    "            print(\"   This checkpoint was created before v4.0 or training failed early\")\n",
    "        except Exception as e:\n",
    "            print(f\"\u274c Unexpected error: {e}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    ""
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title \ud83d\udd27 Extract Session Variables { display-mode: \"form\" }\n",
    "\n",
    "# Extract workspace_root, run_name, metrics_df from results dict\n",
    "# Works for both training (Cell 32) and recovery (Cell 33) workflows\n",
    "\n",
    "if 'results' in globals():\n",
    "    # Extract workspace_root (for file paths)\n",
    "    if 'workspace_root' not in globals():\n",
    "        workspace_root = results.get('workspace_root', './workspace')\n",
    "        print(f\"\u2705 workspace_root: {workspace_root}\")\n",
    "    \n",
    "    # Extract run_name (for file naming)\n",
    "    if 'run_name' not in globals():\n",
    "        run_name = results.get('run_name', 'training_run')\n",
    "        print(f\"\u2705 run_name: {run_name}\")\n",
    "    \n",
    "    # Extract metrics_df (for analysis)\n",
    "    if 'metrics_df' not in globals():\n",
    "        metrics_df = results.get('metrics_summary')\n",
    "        if metrics_df is not None:\n",
    "            print(f\"\u2705 metrics_df: {len(metrics_df)} epochs\")\n",
    "else:\n",
    "    print(\"\u26a0\ufe0f  'results' not found - run Cell 32 (Training) or Cell 33 (Recovery) first\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fd41698",
   "metadata": {},
   "source": [
    "<a id=\"section-7\"></a>\n",
    "# \ud83d\udcc8 Section 7: Analysis & Visualization\n",
    "\n",
    "Analyze training results with comprehensive dashboards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "632a6e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title \ud83d\udcc8 Training Dashboard (v3.6: With Drift Visualization) { display-mode: \"form\" }\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"TRAINING DASHBOARD GENERATION\")\n",
    "print(\"=\" * 70)\n",
    "print()\n",
    "\n",
    "# Check if required variables exist\n",
    "missing_vars = []\n",
    "if 'results' not in globals():\n",
    "    missing_vars.append('results')\n",
    "if 'metrics_df' not in globals() and ('results' not in globals() or 'metrics_summary' not in results):\n",
    "    missing_vars.append('metrics_df')\n",
    "if 'training_config' not in globals():\n",
    "    missing_vars.append('training_config')\n",
    "if 'workspace_root' not in globals():\n",
    "    missing_vars.append('workspace_root')\n",
    "\n",
    "if missing_vars:\n",
    "    print(f\"\u274c Missing required variables: {', '.join(missing_vars)}\")\n",
    "    print()\n",
    "    print(\"Please run either:\")\n",
    "    print(\"  1. Section 6 training cell (Cell 32), OR\")\n",
    "    print(\"  2. Checkpoint Recovery cell (Cell 33)\")\n",
    "    print()\n",
    "else:\n",
    "    # Extract metrics from results if not already in globals\n",
    "    if 'metrics_df' not in globals():\n",
    "        if 'results' in globals() and 'metrics_summary' in results:\n",
    "            metrics_df = results['metrics_summary']\n",
    "            print(f\"\u2705 Metrics loaded from results: {len(metrics_df)} epochs\")\n",
    "        else:\n",
    "            print(\"\u26a0\ufe0f  No metrics_df or results found\")\n",
    "            metrics_df = None\n",
    "    else:\n",
    "        print(f\"\u2705 Metrics loaded: {len(metrics_df)} epochs\")\n",
    "    \n",
    "    if metrics_df is not None:\n",
    "        from utils.visualization.dashboard import TrainingDashboard\n",
    "        import os\n",
    "        \n",
    "        # Create dashboard\n",
    "        print()\n",
    "        print(\"\ud83d\udcca Creating dashboard...\")\n",
    "        \n",
    "        # Check if drift_data exists (only present in live training, not recovery)\n",
    "        has_drift = 'drift_data' in globals() and drift_data is not None\n",
    "        \n",
    "        # Determine dashboard type\n",
    "        if has_drift:\n",
    "            print(\"   Type: Enhanced (10-panel with drift visualization)\")\n",
    "            dashboard_size = (20, 14)  # Larger for drift panels\n",
    "        else:\n",
    "            print(\"   Type: Standard (6-panel)\")\n",
    "            dashboard_size = (18, 12)\n",
    "        \n",
    "        dashboard = TrainingDashboard(figsize=dashboard_size)\n",
    "        \n",
    "        try:\n",
    "            if has_drift:\n",
    "                # v3.6: Enhanced dashboard with drift visualization\n",
    "                print(\"   Building 10-panel layout...\")\n",
    "                print(\"     - 6 training metric panels\")\n",
    "                print(\"     - 4 drift detection panels\")\n",
    "                \n",
    "                fig = dashboard.plot_with_drift(\n",
    "                    metrics_df=metrics_df,\n",
    "                    drift_data=drift_data,\n",
    "                    config=training_config,\n",
    "                    title=f\"Training Dashboard + Drift Analysis: {run_name}\"\n",
    "                )\n",
    "                \n",
    "                print(\"   \u2705 Enhanced dashboard created (10 panels)\")\n",
    "                \n",
    "            else:\n",
    "                # Standard 6-panel dashboard\n",
    "                print(\"   Building 6-panel layout...\")\n",
    "                \n",
    "                fig = dashboard.plot(\n",
    "                    metrics_df=metrics_df,\n",
    "                    config=training_config,\n",
    "                    title=f\"Training Dashboard: {run_name}\"\n",
    "                )\n",
    "                \n",
    "                print(\"   \u2705 Standard dashboard created (6 panels)\")\n",
    "            \n",
    "            # Save to Drive/workspace\n",
    "            results_dir = f'{workspace_root}/results'\n",
    "            os.makedirs(results_dir, exist_ok=True)\n",
    "            dashboard_path = f'{results_dir}/{run_name}_dashboard.png'\n",
    "            dashboard.save(dashboard_path, dpi=150)\n",
    "            \n",
    "            print()\n",
    "            print(f\"\ud83d\udcbe Dashboard saved to: {dashboard_path}\")\n",
    "            \n",
    "            # Display in notebook\n",
    "            import matplotlib.pyplot as plt\n",
    "            plt.show()\n",
    "            \n",
    "            print()\n",
    "            print(\"=\" * 70)\n",
    "            print(\"\u2705 DASHBOARD COMPLETE\")\n",
    "            print(\"=\" * 70)\n",
    "            print()\n",
    "            \n",
    "            if has_drift:\n",
    "                print(\"\ud83d\udcca Drift Analysis Summary:\")\n",
    "                print(f\"   Status: {drift_data['status'].upper()}\")\n",
    "                print(f\"   Metrics tracked: {len(drift_data['drift_scores'])}\")\n",
    "                print()\n",
    "                print(\"   Drift scores:\")\n",
    "                for metric, score in drift_data['drift_scores'].items():\n",
    "                    status_emoji = '\u2705' if score < 0.1 else '\u26a0\ufe0f ' if score < 0.2 else '\ud83d\udea8'\n",
    "                    print(f\"     {status_emoji} {metric}: {score:.4f}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print()\n",
    "            print(f\"\u274c Dashboard generation failed: {e}\")\n",
    "            print(\"   Check that metrics_df is properly formatted\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "    else:\n",
    "        print()\n",
    "        print(\"\u26a0\ufe0f  Skipping dashboard generation - no metrics available\")\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title \ud83d\udd0d Variable State Diagnostic (Check Training Session State) { display-mode: \"form\" }\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"TRAINING SESSION STATE DIAGNOSTIC\")\n",
    "print(\"=\" * 70)\n",
    "print()\n",
    "\n",
    "# Check key variables\n",
    "required_vars = {\n",
    "    'results': 'Training results dictionary',\n",
    "    'metrics_df': 'DataFrame with per-epoch metrics',\n",
    "    'training_config': 'Training configuration object',\n",
    "    'workspace_root': 'Workspace directory path',\n",
    "    'model': 'Trained model instance',\n",
    "}\n",
    "\n",
    "optional_vars = {\n",
    "    'config': 'Config alias (usually same as training_config)',\n",
    "    'drift_data': 'Drift detection results (live training only)',\n",
    "    'db': 'ExperimentDB instance',\n",
    "    'run_id': 'Current experiment run ID',\n",
    "}\n",
    "\n",
    "print(\"\ud83d\udccb Required Variables:\")\n",
    "print()\n",
    "all_present = True\n",
    "for var_name, description in required_vars.items():\n",
    "    exists = var_name in globals()\n",
    "    status = \"\u2705\" if exists else \"\u274c\"\n",
    "    print(f\"  {status} {var_name:<20} {description}\")\n",
    "    if not exists:\n",
    "        all_present = False\n",
    "\n",
    "print()\n",
    "print(\"\ud83d\udccb Optional Variables:\")\n",
    "print()\n",
    "for var_name, description in optional_vars.items():\n",
    "    exists = var_name in globals()\n",
    "    status = \"\u2705\" if exists else \"\u26aa\"\n",
    "    print(f\"  {status} {var_name:<20} {description}\")\n",
    "\n",
    "print()\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Provide guidance based on state\n",
    "if all_present:\n",
    "    print(\"\u2705 ALL REQUIRED VARIABLES PRESENT\")\n",
    "    print()\n",
    "    \n",
    "    # Show summary info\n",
    "    if 'metrics_df' in globals():\n",
    "        print(f\"\ud83d\udcca Session Summary:\")\n",
    "        print(f\"   Epochs: {len(metrics_df)}\")\n",
    "        if 'training_config' in globals():\n",
    "            print(f\"   Run Name: {training_config.run_name}\")\n",
    "        if 'workspace_root' in globals():\n",
    "            print(f\"   Workspace: {workspace_root}\")\n",
    "        if 'results' in globals() and 'checkpoint_path' in results:\n",
    "            print(f\"   Checkpoint: {results['checkpoint_path']}\")\n",
    "    \n",
    "    print()\n",
    "    print(\"\ud83d\udca1 You can proceed with:\")\n",
    "    print(\"   \u2192 Training Dashboard (Cell 35)\")\n",
    "    print(\"   \u2192 Best Model Summary (Cell 36)\")\n",
    "    print(\"   \u2192 Metrics CSV Export (Cell 37)\")\n",
    "else:\n",
    "    print(\"\u274c SOME REQUIRED VARIABLES MISSING\")\n",
    "    print()\n",
    "    print(\"\ud83d\udca1 To populate variables, run either:\")\n",
    "    print()\n",
    "    print(\"   Option 1: Fresh Training\")\n",
    "    print(\"     \u2192 Run Section 6 training cell (Cell 32)\")\n",
    "    print()\n",
    "    print(\"   Option 2: Recover from Checkpoint\")\n",
    "    print(\"     \u2192 Run Checkpoint Recovery cell (Cell 33)\")\n",
    "    print(\"     \u2192 Requires existing checkpoints from previous training\")\n",
    "\n",
    "print(\"=\" * 70)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d96e03d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if required variables exist\n",
    "if 'metrics_df' not in globals() or 'results' not in globals():\n",
    "    print(\"=\" * 60)\n",
    "    print(\"\u274c BEST EPOCH ANALYSIS - Variables Missing\")\n",
    "    print(\"=\" * 60)\n",
    "    print()\n",
    "    print(\"Required variables not found.\")\n",
    "    print()\n",
    "    print(\"Please run either:\")\n",
    "    print(\"  1. Section 6 training cell (Cell 32), OR\")\n",
    "    print(\"  2. Checkpoint Recovery cell (Cell 33)\")\n",
    "    print()\n",
    "    print(\"=\" * 60)\n",
    "else:\n",
    "    # Find best epoch based on validation loss\n",
    "    import os\n",
    "    \n",
    "    if 'val/loss' not in metrics_df.columns:\n",
    "        print(\"\u26a0\ufe0f  Warning: 'val/loss' column not found in metrics\")\n",
    "        print(\"   Using last epoch as best epoch\")\n",
    "        best_epoch_idx = metrics_df.index[-1]\n",
    "    else:\n",
    "        best_epoch_idx = metrics_df['val/loss'].idxmin()\n",
    "    \n",
    "    best_epoch = metrics_df.loc[best_epoch_idx]\n",
    "    \n",
    "    print(\"=\" * 60)\n",
    "    print(\" \" * 20 + \"BEST EPOCH ANALYSIS\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"{'Best Epoch:':<25} {int(best_epoch['epoch']) + 1}\")\n",
    "    \n",
    "    if 'val/loss' in best_epoch:\n",
    "        print(f\"{'Validation Loss:':<25} {best_epoch['val/loss']:.4f}\")\n",
    "    if 'val/perplexity' in best_epoch:\n",
    "        print(f\"{'Validation Perplexity:':<25} {best_epoch['val/perplexity']:.2f}\")\n",
    "    if 'train/loss' in best_epoch:\n",
    "        print(f\"{'Training Loss:':<25} {best_epoch['train/loss']:.4f}\")\n",
    "    if 'train/learning_rate' in best_epoch:\n",
    "        print(f\"{'Learning Rate:':<25} {best_epoch['train/learning_rate']:.2e}\")\n",
    "    \n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Load best checkpoint\n",
    "    best_checkpoint_path = results.get('checkpoint_path', 'checkpoint not available')\n",
    "    if isinstance(best_checkpoint_path, str) and best_checkpoint_path != 'checkpoint not available':\n",
    "        if os.path.exists(best_checkpoint_path):\n",
    "            print(f\"\\n\ud83d\udcbe Best checkpoint: {best_checkpoint_path}\")\n",
    "        else:\n",
    "            print(f\"\\n\u26a0\ufe0f  Best checkpoint path recorded but file not found:\")\n",
    "            print(f\"   {best_checkpoint_path}\")\n",
    "    else:\n",
    "        print(f\"\\n\u26a0\ufe0f  Best checkpoint not available in results\")\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0722848b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display metrics table\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Check if required variables exist\n",
    "if 'metrics_df' not in globals():\n",
    "    print(\"\u274c Error: metrics_df not found\")\n",
    "    print(\"   Please run either:\")\n",
    "    print(\"   - Section 6 training cell (Cell 32)\")\n",
    "    print(\"   - Checkpoint Recovery cell (Cell 33)\")\n",
    "else:\n",
    "    pd.set_option('display.max_rows', None)\n",
    "    pd.set_option('display.float_format', lambda x: f'{x:.4f}')\n",
    "    \n",
    "    display_cols = ['epoch', 'train/loss', 'val/loss', 'val/perplexity', 'train/learning_rate']\n",
    "    available_cols = [col for col in display_cols if col in metrics_df.columns]\n",
    "    \n",
    "    print(\"\\nTraining Metrics Summary:\")\n",
    "    print(metrics_df[available_cols].to_string(index=False))\n",
    "    \n",
    "    # Export to CSV with safety checks\n",
    "    try:\n",
    "        else:\n",
    "            run_name = run_name\n",
    "        \n",
    "        # Ensure results directory exists\n",
    "        results_dir = f'{workspace_root}/results'\n",
    "        os.makedirs(results_dir, exist_ok=True)\n",
    "        \n",
    "        csv_path = f'{results_dir}/{run_name}_metrics.csv'\n",
    "        metrics_df.to_csv(csv_path, index=False)\n",
    "        print(f\"\\n\u2705 Metrics exported to: {csv_path}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\n\u274c CSV export failed: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cfe5404",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(\"=\" * 60)\n",
    "    print(\" \" * 20 + \"GPU METRICS\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    gpu_cols = [col for col in metrics_df.columns if col.startswith('gpu/')]\n",
    "    if gpu_cols:\n",
    "        print(metrics_df[['epoch'] + gpu_cols].tail(5).to_string(index=False))\n",
    "\n",
    "        # Plot GPU utilization\n",
    "        import matplotlib.pyplot as plt\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "        if 'gpu/memory_allocated_mb' in metrics_df.columns:\n",
    "            ax1.plot(metrics_df['epoch'], metrics_df['gpu/memory_allocated_mb'])\n",
    "            ax1.set_xlabel('Epoch')\n",
    "            ax1.set_ylabel('GPU Memory (MB)')\n",
    "            ax1.set_title('GPU Memory Usage')\n",
    "            ax1.grid(True)\n",
    "\n",
    "        if 'gpu/utilization_percent' in metrics_df.columns:\n",
    "            ax2.plot(metrics_df['epoch'], metrics_df['gpu/utilization_percent'])\n",
    "            ax2.set_xlabel('Epoch')\n",
    "            ax2.set_ylabel('GPU Utilization (%)')\n",
    "            ax2.set_title('GPU Utilization')\n",
    "            ax2.grid(True)\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'{workspace_root}/results/{run_name}_gpu_metrics.png', dpi=100)\n",
    "        plt.show()\n",
    "        print(f\"\\n\u2705 GPU metrics saved\")\n",
    "    else:\n",
    "        print(\"\u26a0\ufe0f No GPU metrics collected during training\")\n",
    "    print(\"=\" * 60)\n",
    "else:\n",
    "    print(\"\u2139\ufe0f Training was performed on CPU (no GPU metrics available)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a6fdf23",
   "metadata": {},
   "source": [
    "<a id=\"section-8\"></a>\n",
    "# \ud83d\udcbe Section 8: Export & Results\n",
    "\n",
    "Download checkpoints, configs, and results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a039396b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from google.colab import files\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\" \" * 20 + \"EXPORT SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\n\ud83d\udcc1 Workspace: {workspace_root}\")\n",
    "print(f\"\\n\ud83d\udcca Results:\")\n",
    "print(f\"   - Dashboard: {run_name}_dashboard.png\")\n",
    "print(f\"   - Metrics CSV: {run_name}_metrics.csv\")\n",
    "print(f\"   - Config: {os.path.basename(config_path)}\")\n",
    "print(f\"\\n\ud83d\udcbe Checkpoints:\")\n",
    "\n",
    "checkpoint_dir = f\"{workspace_root}/checkpoints\"\n",
    "checkpoints = [f for f in os.listdir(checkpoint_dir) if f.startswith(run_name)]\n",
    "for ckpt in sorted(checkpoints):\n",
    "    ckpt_path = os.path.join(checkpoint_dir, ckpt)\n",
    "    size_mb = os.path.getsize(ckpt_path) / (1024 * 1024)\n",
    "    print(f\"   - {ckpt} ({size_mb:.1f} MB)\")\n",
    "\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1656431e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download results to local machine\n",
    "download_results = False  #@param {type:\"boolean\"}\n",
    "\n",
    "if download_results:\n",
    "    print(\"Downloading files...\")\n",
    "\n",
    "    # Download dashboard\n",
    "    dashboard_file = f'{workspace_root}/results/{config.run_name}_dashboard.png'\n",
    "    if os.path.exists(dashboard_file):\n",
    "        files.download(dashboard_file)\n",
    "\n",
    "    # Download metrics CSV\n",
    "    metrics_file = f'{workspace_root}/results/{config.run_name}_metrics.csv'\n",
    "    if os.path.exists(metrics_file):\n",
    "        files.download(metrics_file)\n",
    "\n",
    "    # Download config\n",
    "    if os.path.exists(config_path):\n",
    "        files.download(config_path)\n",
    "\n",
    "    # Download best checkpoint\n",
    "    if os.path.exists(best_checkpoint_path):\n",
    "        files.download(best_checkpoint_path)\n",
    "        print(f\"\u2705 Downloaded {os.path.basename(best_checkpoint_path)}\")\n",
    "\n",
    "    print(\"\u2705 Downloads complete\")\n",
    "else:\n",
    "    print(\"\u2139\ufe0f Downloads skipped. Files are saved in Google Drive.\")\n",
    "    print(f\"   Access them at: {workspace_root}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "l75ch0mse7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title \ud83d\udce6 Production Export Bundle (v3.5) { display-mode: \"form\" }\n",
    "\n",
    "if training_config.export_bundle:\n",
    "    print(\"=\" * 70)\n",
    "    print(\"PRODUCTION EXPORT BUNDLE GENERATION (v3.5)\")\n",
    "    print(\"=\" * 70)\n",
    "    print()\n",
    "    \n",
    "    print(\"\ud83d\udce6 Creating complete deployment bundle...\")\n",
    "    print(f\"   Formats: {', '.join(training_config.export_formats)}\")\n",
    "    print(f\"   Task: {task_spec.name}\")\n",
    "    print(f\"   Modality: {task_spec.modality}\")\n",
    "    print()\n",
    "    \n",
    "    try:\n",
    "        # Get best model from training results\n",
    "        if 'results' in globals() and 'model' in globals():\n",
    "            export_model = model\n",
    "            print(\"\u2705 Using trained model for export\")\n",
    "        else:\n",
    "            print(\"\u26a0\ufe0f  No trained model found, using current model state\")\n",
    "            export_model = model if 'model' in globals() else None\n",
    "        \n",
    "        if export_model is not None:\n",
    "            # Create export bundle\n",
    "            print()\n",
    "            print(\"\ud83d\udd27 Generating export artifacts...\")\n",
    "            print(\"   (This may take 1-2 minutes)\")\n",
    "            print()\n",
    "            \n",
    "            export_dir = create_export_bundle(\n",
    "                model=export_model,\n",
    "                config=config_obj if 'config_obj' in globals() else {},\n",
    "                task_spec=task_spec,\n",
    "                training_config=training_config,\n",
    "                export_base_dir=f'{workspace_root}/exports'\n",
    "            )\n",
    "            \n",
    "            print()\n",
    "            print(\"=\" * 70)\n",
    "            print(\"\u2705 EXPORT BUNDLE CREATED SUCCESSFULLY!\")\n",
    "            print(\"=\" * 70)\n",
    "            print()\n",
    "            print(f\"\ud83d\udcc1 Location: {export_dir}\")\n",
    "            print()\n",
    "            print(\"Bundle Contents:\")\n",
    "            print(\"-\" * 70)\n",
    "            print()\n",
    "            print(\"  \ud83d\udcc1 artifacts/\")\n",
    "            \n",
    "            for fmt in training_config.export_formats:\n",
    "                if fmt == \"onnx\":\n",
    "                    print(\"     \u251c\u2500\u2500 model.onnx (ONNX format)\")\n",
    "                elif fmt == \"torchscript\":\n",
    "                    print(\"     \u251c\u2500\u2500 model.torchscript.pt (TorchScript)\")\n",
    "                elif fmt == \"pytorch\":\n",
    "                    print(\"     \u251c\u2500\u2500 model.pytorch.pt (PyTorch state dict)\")\n",
    "            \n",
    "            print()\n",
    "            print(\"  \ud83d\udcc1 configs/\")\n",
    "            print(\"     \u251c\u2500\u2500 task_spec.json (task configuration)\")\n",
    "            print(\"     \u251c\u2500\u2500 training_config.json (training settings)\")\n",
    "            print(\"     \u2514\u2500\u2500 torchserve_config.json (TorchServe deployment)\")\n",
    "            print()\n",
    "            print(\"  \ud83d\udcc4 inference.py (standalone inference script)\")\n",
    "            print(\"  \ud83d\udcc4 README.md (quickstart guide)\")\n",
    "            print(\"  \ud83d\udc33 Dockerfile (container deployment)\")\n",
    "            print(\"  \ud83d\udccb requirements.txt (runtime dependencies)\")\n",
    "            print()\n",
    "            print(\"-\" * 70)\n",
    "            print()\n",
    "            print(\"QUICK START GUIDE\")\n",
    "            print(\"-\" * 70)\n",
    "            print()\n",
    "            \n",
    "            if task_spec.modality == \"vision\":\n",
    "                print(\"Local Inference:\")\n",
    "                print(f\"  cd {export_dir}\")\n",
    "                print(f\"  python inference.py --input image.jpg --model artifacts/model.onnx\")\n",
    "                print()\n",
    "                print(\"Docker Deployment:\")\n",
    "                print(f\"  cd {export_dir}\")\n",
    "                print(\"  docker build -t model-inference .\")\n",
    "                print(\"  docker run -p 8080:8080 model-inference\")\n",
    "                print()\n",
    "                print(\"Test the API:\")\n",
    "                print(\"  curl -X POST http://localhost:8080/predict \\\\\")\n",
    "                print(\"    -F 'image=@test_image.jpg'\")\n",
    "            else:\n",
    "                print(\"Local Inference:\")\n",
    "                print(f\"  cd {export_dir}\")\n",
    "                print(f\"  python inference.py --input 'Your text here' --model artifacts/model.onnx\")\n",
    "                print()\n",
    "                print(\"Docker Deployment:\")\n",
    "                print(f\"  cd {export_dir}\")\n",
    "                print(\"  docker build -t model-inference .\")\n",
    "                print(\"  docker run -p 8080:8080 model-inference\")\n",
    "                print()\n",
    "                print(\"Test the API:\")\n",
    "                print(\"  curl -X POST http://localhost:8080/predict \\\\\")\n",
    "                print(\"    -d '{\\\"text\\\": \\\"Your input text\\\"}'\")\n",
    "            \n",
    "            print()\n",
    "            print(\"=\" * 70)\n",
    "            print()\n",
    "            print(\"\ud83d\udca1 The export bundle includes everything needed for production:\")\n",
    "            print(\"   \u2705 Optimized model formats (ONNX, TorchScript)\")\n",
    "            print(\"   \u2705 Standalone inference script\")\n",
    "            print(\"   \u2705 Docker container definition\")\n",
    "            print(\"   \u2705 TorchServe deployment config\")\n",
    "            print(\"   \u2705 Complete documentation\")\n",
    "            print()\n",
    "            print(f\"\ud83d\udce6 Export bundle is ready in: {export_dir}\")\n",
    "            print()\n",
    "            \n",
    "        else:\n",
    "            print(\"\u274c No model available for export\")\n",
    "            print(\"   Please run training first (Section 6)\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print()\n",
    "        print(\"\u274c Export bundle generation failed!\")\n",
    "        print()\n",
    "        print(f\"Error: {e}\")\n",
    "        print()\n",
    "        print(\"Troubleshooting:\")\n",
    "        print(\"  - Ensure model is properly trained\")\n",
    "        print(\"  - Check that all required configs are available\")\n",
    "        print(\"  - Verify export formats are supported\")\n",
    "        print()\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "\n",
    "else:\n",
    "    print(\"=\" * 70)\n",
    "    print(\"EXPORT BUNDLE DISABLED\")\n",
    "    print(\"=\" * 70)\n",
    "    print()\n",
    "    print(\"\u2139\ufe0f  Production export bundle generation is disabled\")\n",
    "    print()\n",
    "    print(\"To enable:\")\n",
    "    print(\"  1. Go back to Section 4 (Training Configuration)\")\n",
    "    print(\"  2. Set export_bundle = True\")\n",
    "    print(\"  3. Re-run configuration and training\")\n",
    "    print()\n",
    "    print(\"\ud83d\udca1 Benefits of export bundles:\")\n",
    "    print(\"   - Production-ready deployment artifacts\")\n",
    "    print(\"   - Multiple model formats (ONNX, TorchScript, PyTorch)\")\n",
    "    print(\"   - Docker containerization\")\n",
    "    print(\"   - TorchServe integration\")\n",
    "    print(\"   - Complete documentation\")\n",
    "    print()\n",
    "    print(\"=\" * 70)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f00c7f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare with previous runs\n",
    "all_runs = db.list_runs(limit=10)\n",
    "\n",
    "if len(all_runs) > 1:\n",
    "    print(\"=\" * 60)\n",
    "    print(\" \" * 15 + \"COMPARISON WITH PREVIOUS RUNS\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    comparison_data = []\n",
    "    for run in all_runs:\n",
    "        comparison_data.append({\n",
    "            'run_name': run.get('run_name', 'unknown'),\n",
    "            'final_val_loss': run.get('metrics', {}).get('val/loss', float('nan')),\n",
    "            'final_perplexity': run.get('metrics', {}).get('val/perplexity', float('nan')),\n",
    "            'data_source': run.get('data_source', 'unknown'),\n",
    "            'timestamp': run.get('timestamp', 'unknown')\n",
    "        })\n",
    "\n",
    "    comparison_df = pd.DataFrame(comparison_data)\n",
    "    print(comparison_df.to_string(index=False))\n",
    "    print(\"=\" * 60)\n",
    "else:\n",
    "    print(\"\u2139\ufe0f No previous runs to compare (this is your first run)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61a901c0",
   "metadata": {},
   "source": [
    "<a id=\"section-9\"></a>\n",
    "# \ud83d\udd2c Section 9: Advanced Features\n",
    "\n",
    "Hyperparameter search, multi-run experiments, and optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f3d0b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter search configuration\n",
    "\n",
    "run_hp_search = False  #@param {type:\"boolean\"}\n",
    "n_trials = 10  #@param {type:\"integer\"}\n",
    "\n",
    "if run_hp_search:\n",
    "    print(\"\ud83d\udd0d Hyperparameter search configuration\")\n",
    "    print(f\"   Trials: {n_trials}\")\n",
    "    print(\"   Method: Grid search (sequential)\")\n",
    "    print()\n",
    "\n",
    "    # Define search space\n",
    "    hp_search_space = {\n",
    "        'learning_rate': [1e-5, 5e-5, 1e-4],\n",
    "        'batch_size': [4, 8, 16],\n",
    "        'warmup_ratio': [0.0, 0.1, 0.2],\n",
    "        'weight_decay': [0.0, 0.01, 0.1]\n",
    "    }\n",
    "\n",
    "    print(\"Search space:\")\n",
    "    for param, values in hp_search_space.items():\n",
    "        print(f\"   {param}: {values}\")\n",
    "    print()\n",
    "    print(\"\u26a0\ufe0f Note: Trials will run sequentially.\")\n",
    "    print(\"   For parallel execution, use Optuna, Ray Tune, or W&B Sweeps.\")\n",
    "else:\n",
    "    print(\"\u2139\ufe0f Hyperparameter search disabled\")\n",
    "    print(\"   Set 'run_hp_search = True' to enable\")\n",
    "    print()\n",
    "    print(\"\ud83d\udca1 For production hyperparameter optimization:\")\n",
    "    print(\"   \u2022 Optuna - Bayesian optimization with pruning\")\n",
    "    print(\"   \u2022 Ray Tune - Distributed multi-GPU search\")\n",
    "    print(\"   \u2022 W&B Sweeps - Cloud-based with automatic scaling\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c19ee7e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "if run_hp_search:\n",
    "    import itertools\n",
    "    import pandas as pd\n",
    "    from utils.training.training_config import TrainingConfigBuilder\n",
    "\n",
    "    print()\n",
    "    print(\"=\" * 70)\n",
    "    print(\"HYPERPARAMETER SEARCH EXECUTION\")\n",
    "    print(\"=\" * 70)\n",
    "    print()\n",
    "\n",
    "    # Generate all combinations\n",
    "    param_names = list(hp_search_space.keys())\n",
    "    param_values = list(hp_search_space.values())\n",
    "    all_combinations = list(itertools.product(*param_values))\n",
    "\n",
    "    # Limit to n_trials\n",
    "    trials = all_combinations[:n_trials]\n",
    "\n",
    "    print(f\"\ud83d\udd2c Running {len(trials)} trials...\")\n",
    "    print()\n",
    "\n",
    "    # Store results\n",
    "    trial_results = []\n",
    "\n",
    "    for trial_idx, trial_params in enumerate(trials):\n",
    "        # Create config for this trial\n",
    "        trial_config_dict = dict(zip(param_names, trial_params))\n",
    "\n",
    "        print(f\"Trial {trial_idx + 1}/{len(trials)}\")\n",
    "        print(f\"  Params: {trial_config_dict}\")\n",
    "\n",
    "        # Build training config with trial parameters\n",
    "        trial_training_config = (\n",
    "            TrainingConfigBuilder.from_config(training_config)\n",
    "            .with_training(\n",
    "                learning_rate=trial_config_dict.get('learning_rate', training_config.learning_rate),\n",
    "                batch_size=trial_config_dict.get('batch_size', training_config.batch_size),\n",
    "                warmup_ratio=trial_config_dict.get('warmup_ratio', training_config.warmup_ratio),\n",
    "                weight_decay=trial_config_dict.get('weight_decay', training_config.weight_decay)\n",
    "            )\n",
    "            .with_logging(run_name=f\"{training_config.run_name}_trial{trial_idx}\")\n",
    "            .build()\n",
    "        )\n",
    "\n",
    "        try:\n",
    "            # Create new trainer for this trial\n",
    "            trial_trainer = Trainer(\n",
    "                model=model,\n",
    "                config=config_obj,\n",
    "                training_config=trial_training_config,\n",
    "                task_spec=task_spec\n",
    "            )\n",
    "\n",
    "            # Run training\n",
    "            trial_result = trial_trainer.train(\n",
    "                train_data=train_data,\n",
    "                val_data=val_data\n",
    "            )\n",
    "\n",
    "            # Extract final validation loss\n",
    "            final_val_loss = None\n",
    "            if 'metrics_summary' in trial_result and not trial_result['metrics_summary'].empty:\n",
    "                final_metrics = trial_result['metrics_summary'].iloc[-1]\n",
    "                final_val_loss = final_metrics.get('val/loss', None)\n",
    "\n",
    "            # Store result\n",
    "            trial_results.append({\n",
    "                'trial': trial_idx,\n",
    "                **trial_config_dict,\n",
    "                'val_loss': final_val_loss,\n",
    "                'best_epoch': trial_result.get('best_epoch', -1),\n",
    "                'status': 'completed'\n",
    "            })\n",
    "\n",
    "            print(f\"  \u2705 Val Loss: {final_val_loss:.4f}\")\n",
    "\n",
    "            # Log to ExperimentDB if available\n",
    "            if 'db' in globals() and db is not None:\n",
    "                run_id = db.log_run(\n",
    "                    run_name=trial_training_config.run_name,\n",
    "                    config=trial_training_config.to_dict(),\n",
    "                    notes=f\"HP search trial {trial_idx}\",\n",
    "                    sweep_id=f\"{training_config.run_name}_hp_search\",\n",
    "                    sweep_params=trial_config_dict\n",
    "                )\n",
    "                for epoch_idx, loss in enumerate(trial_result['loss_history']):\n",
    "                    db.log_metric(run_id, 'train/loss', loss, epoch=epoch_idx)\n",
    "                db.update_run_status(run_id, 'completed')\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"  \u274c Failed: {e}\")\n",
    "            trial_results.append({\n",
    "                'trial': trial_idx,\n",
    "                **trial_config_dict,\n",
    "                'val_loss': None,\n",
    "                'best_epoch': -1,\n",
    "                'status': 'failed'\n",
    "            })\n",
    "\n",
    "        print()\n",
    "\n",
    "    # Create results DataFrame\n",
    "    hp_results_df = pd.DataFrame(trial_results)\n",
    "\n",
    "    # Find best trial\n",
    "    valid_results = hp_results_df[hp_results_df['val_loss'].notna()]\n",
    "    if not valid_results.empty:\n",
    "        best_trial = valid_results.loc[valid_results['val_loss'].idxmin()]\n",
    "\n",
    "        print(\"=\" * 70)\n",
    "        print(\"HYPERPARAMETER SEARCH RESULTS\")\n",
    "        print(\"=\" * 70)\n",
    "        print()\n",
    "        print(\"\ud83c\udfc6 Best Trial:\")\n",
    "        print(f\"   Trial: {best_trial['trial']}\")\n",
    "        print(f\"   Val Loss: {best_trial['val_loss']:.4f}\")\n",
    "        print()\n",
    "        print(\"Best Hyperparameters:\")\n",
    "        for param in param_names:\n",
    "            print(f\"   {param}: {best_trial[param]}\")\n",
    "        print()\n",
    "\n",
    "        print(\"All Trials:\")\n",
    "        print(hp_results_df.to_string(index=False))\n",
    "        print()\n",
    "\n",
    "        # Save results\n",
    "        results_path = f'{workspace_root}/results/{training_config.run_name}_hp_search.csv'\n",
    "        hp_results_df.to_csv(results_path, index=False)\n",
    "        print(f\"\u2705 Results saved to: {results_path}\")\n",
    "        print(\"=\" * 70)\n",
    "    else:\n",
    "        print(\"\u274c All trials failed - no valid results\")\n",
    "\n",
    "else:\n",
    "    print(\"\u23ed\ufe0f Hyperparameter search skipped\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f63affe7",
   "metadata": {},
   "source": [
    "## \ud83c\udf89 Training Complete!\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "1. **Review Results**: Check the dashboard in Section 6\n",
    "2. **Download Files**: Use Section 7 to download checkpoints\n",
    "3. **Compare Runs**: See Section 7 for comparison with previous experiments\n",
    "4. **Optimize**: Try hyperparameter search in Section 8\n",
    "\n",
    "### Workspace Structure\n",
    "\n",
    "All files are saved in Google Drive:\n",
    "```\n",
    "/content/drive/MyDrive/TransformerTraining/\n",
    "\u251c\u2500\u2500 checkpoints/     # Model weights (.pt files)\n",
    "\u251c\u2500\u2500 configs/         # Training configs (.json files)\n",
    "\u251c\u2500\u2500 results/         # Dashboards, metrics, plots\n",
    "\u251c\u2500\u2500 datasets/        # Cached datasets\n",
    "\u2514\u2500\u2500 experiments.db   # SQLite tracking database\n",
    "```\n",
    "\n",
    "### Resources\n",
    "\n",
    "- [Transformer Builder Documentation](https://transformer-builder.com/docs)\n",
    "- [Training Utilities Reference](https://github.com/matt-hans/transformer-builder-colab-templates)\n",
    "- [W&B Dashboard](https://wandb.ai) (if enabled)\n",
    "\n",
    "---\n",
    "\n",
    "**\ud83d\udca1 Tip**: Save this notebook to Google Drive for future use!"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}