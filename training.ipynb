{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e697c2b",
   "metadata": {},
   "source": [
    "# \ud83d\ude80 Transformer Training & Fine-Tuning Notebook\n",
    "\n",
    "**Professional ML Training Environment** for transformer models exported from [Transformer Builder](https://transformer-builder.com).\n",
    "\n",
    "## Quick Start Modes\n",
    "\n",
    "| Mode | Epochs | Time | Use Case |\n",
    "|------|--------|------|----------|\n",
    "| **\u26a1 Fast** | 3 | ~5 min | Quick validation |\n",
    "| **\u2696\ufe0f Balanced** | 10 | ~15 min | Development |\n",
    "| **\ud83d\udc8e Quality** | 20 | ~45 min | Production |\n",
    "\n",
    "## Features\n",
    "- \u2705 5 Data Sources (HuggingFace, Drive, Upload, Local, Synthetic)\n",
    "- \u2705 Live Training Visualization\n",
    "- \u2705 Google Drive Checkpoints\n",
    "- \u2705 W&B + Local SQLite Tracking\n",
    "- \u2705 Hyperparameter Search\n",
    "- \u2705 Export & Comparison Tools\n",
    "\n",
    "**\ud83d\udccc Tip**: Run all cells in order for best results. Adjust hyperparameters in Section 3."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aef71373",
   "metadata": {},
   "source": [
    "## \ud83d\udccb Table of Contents\n",
    "\n",
    "1. [Section 0: Quick Start](#section-0) \u2190 You are here\n",
    "2. [Section 1: Setup & Drive Workspace](#section-1) (2 min)\n",
    "3. [Section 2: Model Loading](#section-2) (Load custom or example model)\n",
    "4. [Section 3: Data Loading](#section-3) (5 sources)\n",
    "5. [Section 4: Training Configuration](#section-4) (Hyperparameters)\n",
    "6. [Section 5: W&B Tracking Setup](#section-5) (Optional)\n",
    "7. [Section 6: Training Loop](#section-6) (Main training)\n",
    "8. [Section 7: Analysis & Visualization](#section-7) (Dashboards)\n",
    "9. [Section 8: Export & Results](#section-8) (Download checkpoints)\n",
    "10. [Section 9: Advanced Features](#section-9) (Hyperparameter search)\n",
    "\n",
    "\u23f1\ufe0f **Total Time**: ~20-60 minutes depending on mode\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "410215b4",
   "metadata": {},
   "source": [
    "## \ud83d\udce6 Requirements\n",
    "\n",
    "This notebook requires:\n",
    "- Python >= 3.10\n",
    "- PyTorch (pre-installed in Colab)\n",
    "- Transformer Builder utilities (auto-downloaded)\n",
    "\n",
    "**GPU Recommended** but not required. Training will auto-detect and use GPU if available.\n",
    "\n",
    "---\n",
    "<a id=\"section-1\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01c2f932",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install training dependencies\n",
    "!pip install -q -r https://raw.githubusercontent.com/matt-hans/transformer-builder-colab-templates/main/requirements-training.txt\n",
    "\n",
    "# Check for Flash Attention support (PyTorch 2.0+)\n",
    "import torch\n",
    "print(\"\u2705 Dependencies installed\")\n",
    "print(f\"   PyTorch version: {torch.__version__}\")\n",
    "\n",
    "if torch.__version__ >= \"2.0.0\":\n",
    "    print(\"   \u2705 PyTorch 2.0+ detected - Flash Attention support available\")\n",
    "    if torch.cuda.is_available():\n",
    "        print(\"   \u2705 CUDA available - Flash Attention will be enabled automatically\")\n",
    "    else:\n",
    "        print(\"   \u26a0\ufe0f  CPU only - Flash Attention requires CUDA (GPU)\")\n",
    "else:\n",
    "    print(\"   \u26a0\ufe0f  PyTorch < 2.0 - Flash Attention will be disabled\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "676a4b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "print(\"\ud83d\udce5 Downloading training utilities...\")\n",
    "\n",
    "# Remove old utils directory if exists\n",
    "!rm -rf utils/\n",
    "\n",
    "# Download complete utils package from GitHub\n",
    "!git clone --depth 1 --branch main https://github.com/matt-hans/transformer-builder-colab-templates.git temp_repo 2>/dev/null\n",
    "\n",
    "# Copy utils directory\n",
    "!cp -r temp_repo/utils ./\n",
    "\n",
    "# Cleanup\n",
    "!rm -rf temp_repo\n",
    "\n",
    "# Verify package structure\n",
    "utils_path = os.path.join(os.getcwd(), 'utils')\n",
    "if os.path.exists(utils_path):\n",
    "    print(f\"\u2705 Utils package downloaded\")\n",
    "    \n",
    "    # Verify training subdirectory\n",
    "    training_path = os.path.join(utils_path, 'training')\n",
    "    if os.path.exists(training_path):\n",
    "        n_files = len([f for f in os.listdir(training_path) if f.endswith('.py')])\n",
    "        print(f\"\u2705 Training utilities: {n_files} modules found\")\n",
    "    \n",
    "    # Verify tier3 utilities\n",
    "    tier3_path = os.path.join(utils_path, 'tier3_training_utilities.py')\n",
    "    if os.path.exists(tier3_path):\n",
    "        print(f\"\u2705 Tier 3 training utilities ready\")\n",
    "else:\n",
    "    print(\"\u274c Failed to download utils package\")\n",
    "    raise RuntimeError(\"Could not download training utilities\")\n",
    "\n",
    "print(\"\\n\ud83d\udd0d Verifying download...\")\n",
    "\n",
    "# Check critical modules exist\n",
    "required_modules = [\n",
    "    'utils/__init__.py',\n",
    "    'utils/training/task_spec.py',\n",
    "    'utils/training/training_config.py',\n",
    "    'utils/training/training_core.py',\n",
    "    'utils/training/metrics_tracker.py',\n",
    "    'utils/training/drift_metrics.py',\n",
    "    'utils/training/dashboard.py',\n",
    "]\n",
    "\n",
    "missing = []\n",
    "for module in required_modules:\n",
    "    if not os.path.exists(module):\n",
    "        missing.append(module)\n",
    "\n",
    "if missing:\n",
    "    print(\"\u274c Download incomplete! Missing modules:\")\n",
    "    for m in missing:\n",
    "        print(f\"   - {m}\")\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"FALLBACK INSTRUCTIONS\")\n",
    "    print(\"=\"*70)\n",
    "    print(\"\\nManual download steps:\")\n",
    "    print(\"1. Run in a new cell:\")\n",
    "    print(\"   !git clone https://github.com/matt-hans/transformer-builder-colab-templates.git\")\n",
    "    print(\"   !cp -r transformer-builder-colab-templates/utils ./\")\n",
    "    print(\"   !rm -rf transformer-builder-colab-templates\")\n",
    "    print(\"\\n2. Re-run this cell to verify\")\n",
    "    raise RuntimeError(\"Utils package download failed\")\n",
    "\n",
    "print(\"\u2705 All required modules verified\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7ea13e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title \ud83d\udcbe Storage Configuration { display-mode: \"form\" }\n",
    "\n",
    "from google.colab import drive\n",
    "import os\n",
    "\n",
    "# Storage option (user can choose)\n",
    "storage_type = \"Google Drive\"  #@param [\"Google Drive\", \"Local (session only)\"]\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"STORAGE CONFIGURATION\")\n",
    "print(\"=\" * 70)\n",
    "print()\n",
    "\n",
    "workspace_root = None\n",
    "\n",
    "if storage_type == \"Google Drive\":\n",
    "    print(\"\ud83d\udcc2 Attempting to mount Google Drive...\")\n",
    "    print()\n",
    "    \n",
    "    try:\n",
    "        # Try to mount Google Drive\n",
    "        drive.mount('/content/drive', force_remount=False)\n",
    "        \n",
    "        # Create workspace folders on Drive\n",
    "        workspace_root = '/content/drive/MyDrive/TransformerTraining'\n",
    "        os.makedirs(f'{workspace_root}/checkpoints', exist_ok=True)\n",
    "        os.makedirs(f'{workspace_root}/configs', exist_ok=True)\n",
    "        os.makedirs(f'{workspace_root}/results', exist_ok=True)\n",
    "        os.makedirs(f'{workspace_root}/datasets', exist_ok=True)\n",
    "        \n",
    "        print(\"\u2705 Google Drive mounted successfully!\")\n",
    "        print(f\"\u2705 Workspace created at: {workspace_root}\")\n",
    "        print()\n",
    "        print(\"\ud83d\udcc1 Directory structure:\")\n",
    "        print(f\"   \ud83d\udcc1 checkpoints/ - Saved model weights\")\n",
    "        print(f\"   \ud83d\udcc1 configs/ - Training configurations\")\n",
    "        print(f\"   \ud83d\udcc1 results/ - Metrics, plots, dashboards\")\n",
    "        print(f\"   \ud83d\udcc1 datasets/ - Cached datasets\")\n",
    "        print()\n",
    "        print(\"\ud83d\udca1 Benefits:\")\n",
    "        print(\"   \u2022 Files persist across sessions\")\n",
    "        print(\"   \u2022 Access from any device\")\n",
    "        print(\"   \u2022 Automatic backup\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(\"\u274c Google Drive mount failed!\")\n",
    "        print()\n",
    "        print(f\"Error: {e}\")\n",
    "        print()\n",
    "        print(\"=\" * 70)\n",
    "        print(\"TROUBLESHOOTING\")\n",
    "        print(\"=\" * 70)\n",
    "        print()\n",
    "        print(\"Common solutions:\")\n",
    "        print(\"  1. Click the authentication link that appears above\")\n",
    "        print(\"  2. Sign in with your Google account\")\n",
    "        print(\"  3. Grant permissions to access Google Drive\")\n",
    "        print(\"  4. If in a corporate environment, check with IT\")\n",
    "        print()\n",
    "        print(\"=\" * 70)\n",
    "        print(\"FALLBACK: Using local storage\")\n",
    "        print(\"=\" * 70)\n",
    "        print()\n",
    "        \n",
    "        # Fallback to local storage\n",
    "        workspace_root = '/content/workspace'\n",
    "        os.makedirs(f'{workspace_root}/checkpoints', exist_ok=True)\n",
    "        os.makedirs(f'{workspace_root}/configs', exist_ok=True)\n",
    "        os.makedirs(f'{workspace_root}/results', exist_ok=True)\n",
    "        os.makedirs(f'{workspace_root}/datasets', exist_ok=True)\n",
    "        \n",
    "        print(f\"\u2705 Local workspace created at: {workspace_root}\")\n",
    "        print()\n",
    "        print(\"\u26a0\ufe0f  IMPORTANT: Local storage limitations:\")\n",
    "        print(\"   \u2022 Files will be DELETED when runtime ends\")\n",
    "        print(\"   \u2022 Maximum 12-hour session lifetime\")\n",
    "        print(\"   \u2022 Use 'Download results' option before session ends\")\n",
    "\n",
    "else:\n",
    "    # User explicitly chose local storage\n",
    "    print(\"\ud83d\udcc2 Using local storage (session only)...\")\n",
    "    print()\n",
    "    \n",
    "    workspace_root = '/content/workspace'\n",
    "    os.makedirs(f'{workspace_root}/checkpoints', exist_ok=True)\n",
    "    os.makedirs(f'{workspace_root}/configs', exist_ok=True)\n",
    "    os.makedirs(f'{workspace_root}/results', exist_ok=True)\n",
    "    os.makedirs(f'{workspace_root}/datasets', exist_ok=True)\n",
    "    \n",
    "    print(f\"\u2705 Local workspace created at: {workspace_root}\")\n",
    "    print()\n",
    "    print(\"\ud83d\udcc1 Directory structure:\")\n",
    "    print(f\"   \ud83d\udcc1 checkpoints/ - Saved model weights\")\n",
    "    print(f\"   \ud83d\udcc1 configs/ - Training configurations\")\n",
    "    print(f\"   \ud83d\udcc1 results/ - Metrics, plots, dashboards\")\n",
    "    print(f\"   \ud83d\udcc1 datasets/ - Cached datasets\")\n",
    "    print()\n",
    "    print(\"\u26a0\ufe0f  IMPORTANT: Local storage limitations:\")\n",
    "    print(\"   \u2022 Files will be DELETED when runtime ends\")\n",
    "    print(\"   \u2022 Maximum 12-hour session lifetime\")\n",
    "    print(\"   \u2022 Use Section 8 'Download results' to save locally\")\n",
    "    print()\n",
    "    print(\"\ud83d\udca1 Tip: Switch to 'Google Drive' above for persistent storage\")\n",
    "\n",
    "print()\n",
    "print(\"=\" * 70)\n",
    "print(\"\u2705 STORAGE READY\")\n",
    "print(\"=\" * 70)\n",
    "print()\n",
    "print(f\"Workspace: {workspace_root}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37c65122",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.training.experiment_db import ExperimentDB\n",
    "\n",
    "# Initialize local SQLite tracking (backup to W&B)\n",
    "db = ExperimentDB(f'{workspace_root}/experiments.db')\n",
    "\n",
    "print(\"\u2705 Experiment database initialized\")\n",
    "print(f\"   Database: {workspace_root}/experiments.db\")\n",
    "print(f\"   Recent runs:\")\n",
    "recent_runs = db.list_runs(limit=5)\n",
    "if not recent_runs.empty:\n",
    "    print(recent_runs)\n",
    "else:\n",
    "    print(\"   (No previous runs found)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df8c4bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title \ud83d\udd0d Prerequisite Validation { display-mode: \"form\" }\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"PREREQUISITE VALIDATION\")\n",
    "print(\"=\"*70)\n",
    "print()\n",
    "\n",
    "validation_passed = True\n",
    "errors = []\n",
    "\n",
    "# Check 1: Utils package exists\n",
    "print(\"1/4 Checking utils package...\")\n",
    "if not os.path.exists('utils'):\n",
    "    errors.append(\"Utils package not found. Run Section 1 setup cells first.\")\n",
    "    validation_passed = False\n",
    "else:\n",
    "    print(\"   \u2705 Utils directory exists\")\n",
    "\n",
    "# Check 2: Critical modules present\n",
    "print(\"2/4 Checking training modules...\")\n",
    "required_files = [\n",
    "    'utils/training/task_spec.py',\n",
    "    'utils/training/training_config.py',\n",
    "    'utils/training/training_core.py',\n",
    "]\n",
    "missing_files = [f for f in required_files if not os.path.exists(f)]\n",
    "if missing_files:\n",
    "    errors.append(f\"Missing training modules: {', '.join(missing_files)}\")\n",
    "    validation_passed = False\n",
    "else:\n",
    "    print(\"   \u2705 All training modules present\")\n",
    "\n",
    "# Check 3: Python can import utils\n",
    "print(\"3/4 Testing imports...\")\n",
    "try:\n",
    "    import sys\n",
    "    if '.' not in sys.path:\n",
    "        sys.path.insert(0, '.')\n",
    "    \n",
    "    from utils.training.task_spec import TaskSpec\n",
    "    from utils.training.training_config import TrainingConfig\n",
    "    print(\"   \u2705 Core imports successful\")\n",
    "except ImportError as e:\n",
    "    errors.append(f\"Import test failed: {e}\")\n",
    "    validation_passed = False\n",
    "\n",
    "# Check 4: Workspace configured\n",
    "print(\"4/4 Checking workspace...\")\n",
    "if 'workspace_root' not in globals() or workspace_root is None:\n",
    "    errors.append(\"Workspace not configured. Run Section 1 storage setup first.\")\n",
    "    validation_passed = False\n",
    "else:\n",
    "    print(f\"   \u2705 Workspace: {workspace_root}\")\n",
    "\n",
    "print()\n",
    "if validation_passed:\n",
    "    print(\"=\"*70)\n",
    "    print(\"\u2705 ALL PREREQUISITES MET\")\n",
    "    print(\"=\"*70)\n",
    "    print(\"\\n\u2728 Ready to proceed with training setup\")\n",
    "else:\n",
    "    print(\"=\"*70)\n",
    "    print(\"\u274c VALIDATION FAILED\")\n",
    "    print(\"=\"*70)\n",
    "    print(\"\\nErrors found:\")\n",
    "    for i, err in enumerate(errors, 1):\n",
    "        print(f\"   {i}. {err}\")\n",
    "    print(\"\\n\ud83d\udcdd Resolution steps:\")\n",
    "    print(\"   1. Restart runtime: Runtime \u2192 Restart runtime\")\n",
    "    print(\"   2. Run all cells in Section 1 (Setup & Drive Workspace) in order\")\n",
    "    print(\"   3. Wait for each cell to complete before proceeding\")\n",
    "    print(\"   4. Re-run this validation cell\")\n",
    "    raise RuntimeError(\"Prerequisites not met. See errors above.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "kp5zpcfdwn9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import v3.5/v3.6 training infrastructure\n",
    "\n",
    "# Ensure path is set\n",
    "import sys\n",
    "if '.' not in sys.path:\n",
    "    sys.path.insert(0, '.')\n",
    "\n",
    "print(\"\ud83d\udce6 Loading training infrastructure (v3.5/v3.6)...\")\n",
    "\n",
    "try:\n",
    "    # Core training components\n",
    "    from utils.training.training_core import TrainingCoordinator\n",
    "    from utils.training.training_config import TrainingConfig\n",
    "    from utils.training.task_spec import TaskSpec\n",
    "    from utils.training.metrics_tracker import MetricsTracker\n",
    "    \n",
    "    # v3.6 features\n",
    "    from utils.training.drift_metrics import compute_dataset_profile, compare_profiles\n",
    "    from utils.training.dashboard import TrainingDashboard\n",
    "    \n",
    "    # v3.5 features\n",
    "    from utils.training.export_utilities import create_export_bundle\n",
    "    \n",
    "    # Model adapters\n",
    "    from utils.adapters.model_adapter import UniversalModelAdapter, FlashAttentionWrapper\n",
    "    \n",
    "    # Data handling\n",
    "    from utils.tokenization.data_module import SimpleDataModule\n",
    "    \n",
    "    print(\"\u2705 Training infrastructure loaded\")\n",
    "    print(\"   Core:\")\n",
    "    print(\"     - TrainingCoordinator (v3.5)\")\n",
    "    print(\"     - TrainingConfig (versioned configuration)\")\n",
    "    print(\"     - TaskSpec (modality-aware task definitions)\")\n",
    "    print(\"   v3.5 Features:\")\n",
    "    print(\"     - torch.compile integration (10-20% speedup)\")\n",
    "    print(\"     - VisionDataCollator (auto-selected for vision tasks)\")\n",
    "    print(\"     - Gradient accumulation tracking\")\n",
    "    print(\"     - Export bundle generation (production artifacts)\")\n",
    "    print(\"   v3.6 Features:\")\n",
    "    print(\"     - Distributed training guardrails (notebook safety)\")\n",
    "    print(\"     - Flash Attention support (2-4x attention speedup)\")\n",
    "    print(\"     - Drift visualization dashboard (10-panel layout)\")\n",
    "    print()\n",
    "    print(\"\ud83d\ude80 Ready for professional training!\")\n",
    "    \n",
    "except ImportError as e:\n",
    "    print(\"\u274c Failed to load training infrastructure!\")\n",
    "    print(f\"\\nError: {e}\")\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"TROUBLESHOOTING\")\n",
    "    print(\"=\"*70)\n",
    "    print(\"\\n1. Ensure previous cells in Section 1 completed successfully\")\n",
    "    print(\"2. Check that utils package was downloaded (look for \u2705 in output)\")\n",
    "    print(\"3. Try re-running the utils download cell\")\n",
    "    print(\"4. If problem persists, restart runtime and run from beginning\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section-2\"></a>\n",
    "# \ud83d\udce6 Section 2: Model Loading\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load your transformer model from Transformer Builder or use the example model.\n",
    "\n",
    "**Options:**\n",
    "- **Custom Model**: Provide Gist ID from Transformer Builder (auto-detected from URL)\n",
    "- **Example Model**: GPT-2 style architecture for testing\n",
    "\n",
    "**You will see:**\n",
    "1. Model code preview\n",
    "2. Architecture summary (layers, parameters, size)\n",
    "3. GPU compatibility check\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title \ud83d\udd17 Model Source Configuration { display-mode: \"form\" }\n",
    "\n",
    "# Step 1: Try to extract from URL hash using JavaScript\n",
    "from google.colab import output\n",
    "import os\n",
    "import json\n",
    "\n",
    "# JavaScript to extract gist_id and model_name from URL hash\n",
    "js_code = \"\"\"\n",
    "(function() {\n",
    "    let gist_id = '';\n",
    "    let model_name = '';\n",
    "\n",
    "    try {\n",
    "        // Try to read URL hash from parent window (Colab embedding)\n",
    "        const hash = window.parent.location.hash || window.location.hash || '';\n",
    "\n",
    "        if (hash) {\n",
    "            // Parse hash parameters (e.g., #gist_id=abc123&name=MyModel)\n",
    "            const params = new URLSearchParams(hash.substring(1));\n",
    "            gist_id = params.get('gist_id') || '';\n",
    "            model_name = params.get('name') || '';\n",
    "\n",
    "            console.log('Extracted from URL hash:', {gist_id, model_name});\n",
    "        }\n",
    "    } catch (e) {\n",
    "        console.log('Could not access URL hash:', e);\n",
    "    }\n",
    "\n",
    "    // Return as JSON string\n",
    "    return JSON.stringify({gist_id: gist_id, model_name: model_name});\n",
    "})();\n",
    "\"\"\"\n",
    "\n",
    "# Execute JavaScript and get returned values\n",
    "try:\n",
    "    url_params_json = output.eval_js(js_code)\n",
    "    url_params = json.loads(url_params_json)\n",
    "    gist_id_from_url = url_params.get('gist_id', '')\n",
    "    model_name_from_url = url_params.get('model_name', '')\n",
    "except Exception as e:\n",
    "    print(f\"\u26a0\ufe0f  Could not extract from URL hash: {e}\")\n",
    "    gist_id_from_url = ''\n",
    "    model_name_from_url = ''\n",
    "\n",
    "# Step 2: Manual input forms (as fallback)\n",
    "gist_id_manual = \"\"  #@param {type:\"string\"}\n",
    "model_name_manual = \"CustomTransformer\"  #@param {type:\"string\"}\n",
    "\n",
    "# Step 3: Environment variables (lowest priority)\n",
    "gist_id_env = os.getenv('GIST_ID', '')\n",
    "model_name_env = os.getenv('MODEL_NAME', '')\n",
    "\n",
    "# Step 4: Determine final values (URL > Manual > Env)\n",
    "gist_id = gist_id_from_url or gist_id_manual or gist_id_env\n",
    "model_name = model_name_from_url or model_name_manual or model_name_env or 'CustomTransformer'\n",
    "\n",
    "# Display source\n",
    "print(\"=\"*60)\n",
    "if gist_id:\n",
    "    source = \"URL hash\" if gist_id_from_url else (\"Manual input\" if gist_id_manual else \"Environment variable\")\n",
    "    print(f\"\u2705 Model Source: {source}\")\n",
    "    print(f\"   Gist ID: {gist_id}\")\n",
    "    print(f\"   Model Name: {model_name}\")\n",
    "    print(f\"\\n   Loading custom model from Transformer Builder...\")\n",
    "else:\n",
    "    print(\"\u2139\ufe0f  No Gist ID provided\")\n",
    "    print(\"   Options to provide Gist ID:\")\n",
    "    print(\"   1. Open via Transformer Builder link (auto-detects from URL)\")\n",
    "    print(\"   2. Enter Gist ID in the form above\")\n",
    "    print(\"   3. Set GIST_ID environment variable\")\n",
    "    print(\"\\n   Proceeding with example model for demonstration...\")\n",
    "print(\"=\"*60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title \ud83d\udce6 Load Model from Gist { display-mode: \"form\" }\n",
    "\n",
    "import urllib.request\n",
    "import json\n",
    "import sys\n",
    "import tempfile\n",
    "import shutil\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"MODEL LOADING\")\n",
    "print(\"=\" * 70)\n",
    "print()\n",
    "\n",
    "# ==============================================================================\n",
    "# VERIFY GIST ID WAS PROVIDED\n",
    "# ==============================================================================\n",
    "\n",
    "if 'gist_id' not in globals() or not gist_id:\n",
    "    print(\"\u274c ERROR: No Gist ID found!\")\n",
    "    print()\n",
    "    print(\"==\" * 35)\n",
    "    print(\"\ud83d\udd19 GO BACK TO PREVIOUS CELL\")\n",
    "    print(\"==\" * 35)\n",
    "    print()\n",
    "    print(\"You must run the Model Source Configuration cell first.\")\n",
    "    print()\n",
    "    raise ValueError(\"Gist ID required - run previous cell first\")\n",
    "\n",
    "print(f\"\ud83d\udce5 Loading model from GitHub Gist: {gist_id}\")\n",
    "print()\n",
    "\n",
    "# ==============================================================================\n",
    "# FETCH GIST AND LOAD MODEL FILES - GitHub API Approach\n",
    "# ==============================================================================\n",
    "\n",
    "def _fetch_gist(gid: str) -> dict:\n",
    "    \"\"\"Fetch Gist data from GitHub API.\"\"\"\n",
    "    url = f\"https://api.github.com/gists/{gid}\"\n",
    "    req = urllib.request.Request(url, headers={\n",
    "        \"Accept\": \"application/vnd.github+json\",\n",
    "        \"User-Agent\": \"transformer-builder-colab\"\n",
    "    })\n",
    "    try:\n",
    "        with urllib.request.urlopen(req, timeout=20) as resp:\n",
    "            return json.loads(resp.read().decode(\"utf-8\"))\n",
    "    except urllib.error.HTTPError as e:\n",
    "        detail = f\"HTTP {e.code}\"\n",
    "        try:\n",
    "            body = e.read().decode(\"utf-8\")\n",
    "            if \"rate limit\" in body.lower():\n",
    "                detail += \" - GitHub API rate limit (try again in an hour)\"\n",
    "            elif e.code == 404:\n",
    "                detail += \" - Gist not found (check your Gist ID)\"\n",
    "        except:\n",
    "            pass\n",
    "        raise RuntimeError(f\"GitHub API error: {detail}\") from e\n",
    "    except Exception as e:\n",
    "        raise RuntimeError(f\"Network error: {e}\") from e\n",
    "\n",
    "def _write(path: str, text: str):\n",
    "    \"\"\"Write text to file.\"\"\"\n",
    "    with open(path, \"w\") as f:\n",
    "        f.write(text)\n",
    "\n",
    "# Fetch Gist\n",
    "try:\n",
    "    gist_data = _fetch_gist(gist_id)\n",
    "    files = gist_data.get(\"files\") or {}\n",
    "\n",
    "    # Check for required files\n",
    "    if \"model.py\" not in files:\n",
    "        raise RuntimeError(\"Gist is missing 'model.py' - please re-export from Transformer Builder\")\n",
    "    if \"config.json\" not in files:\n",
    "        raise RuntimeError(\"Gist is missing 'config.json' - please re-export from Transformer Builder\")\n",
    "\n",
    "    model_code = files[\"model.py\"].get(\"content\", \"\")\n",
    "    config_json = files[\"config.json\"].get(\"content\", \"\")\n",
    "\n",
    "    if not model_code or not config_json:\n",
    "        raise RuntimeError(\"Empty content in model.py or config.json\")\n",
    "\n",
    "    # Write to files\n",
    "    _write(\"model.py\", model_code)\n",
    "    _write(\"config.json\", config_json)\n",
    "\n",
    "    print(f\"\u2705 Model loaded successfully!\")\n",
    "    print(f\"\u2705 Gist URL: {gist_data.get('html_url', 'N/A')}\")\n",
    "    print(f\"\u2705 Model code: {len(model_code):,} bytes\")\n",
    "    print(f\"\u2705 Config: {len(config_json):,} bytes\")\n",
    "    print()\n",
    "\n",
    "    # Parse model name from config if available\n",
    "    try:\n",
    "        model_config = json.loads(config_json)\n",
    "        if 'model_name' in model_config:\n",
    "            model_name = model_config['model_name']\n",
    "            print(f\"\u2705 Model name: {model_name}\")\n",
    "        else:\n",
    "            model_name = 'CustomTransformer'\n",
    "            print(f\"\u2139\ufe0f  Using default name: {model_name}\")\n",
    "        print()\n",
    "    except:\n",
    "        model_name = 'CustomTransformer'\n",
    "        print(f\"\u26a0\ufe0f  Could not parse config, using default name: {model_name}\")\n",
    "\n",
    "    # Store for next cell\n",
    "    gist_loaded = True\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"\u274c Failed to load model from Gist!\")\n",
    "    print()\n",
    "    print(f\"Error: {e}\")\n",
    "    print()\n",
    "    print(\"=\" * 70)\n",
    "    print(\"TROUBLESHOOTING\")\n",
    "    print(\"=\" * 70)\n",
    "    print()\n",
    "    print(\"Common issues:\")\n",
    "    print(\"  1. Check your Gist ID is correct (go back to previous cell)\")\n",
    "    print(\"  2. Ensure you exported from Transformer Builder successfully\")\n",
    "    print(\"  3. Check you're not hitting GitHub rate limit (60 requests/hour)\")\n",
    "    print(\"  4. Try re-exporting from Transformer Builder\")\n",
    "    print()\n",
    "    print(\"If the problem persists:\")\n",
    "    print(f\"  \u2022 Gist URL: https://gist.github.com/{gist_id}\")\n",
    "    print(\"  \u2022 Verify the Gist contains model.py and config.json\")\n",
    "    print()\n",
    "\n",
    "    # Fallback to example model\n",
    "    print(\"\u26a0\ufe0f  Falling back to example model for demonstration...\")\n",
    "    gist_loaded = False\n",
    "    model_name = 'ExampleTransformer'\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"\u2705 MODEL LOADING COMPLETE\")\n",
    "print(\"=\" * 70)\n",
    "print()\n",
    "print(\"Model will be instantiated in the next cell.\")\n",
    "print()\n",
    "\n",
    "# Display downloaded model code preview\n",
    "if gist_loaded:\n",
    "    print(\"\\n\ud83d\udcc4 Model Code Preview:\")\n",
    "    print(\"=\" * 60)\n",
    "    with open('model.py', 'r') as f:\n",
    "        model_lines = f.read().split('\\n')\n",
    "        # Show first 20 lines\n",
    "        for i, line in enumerate(model_lines[:20], 1):\n",
    "            print(f\"{i:3d} | {line}\")\n",
    "        if len(model_lines) > 20:\n",
    "            print(f\"... ({len(model_lines) - 20} more lines)\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "print(f\"\\n\ud83d\udcca Model: {model_name}\")\n",
    "if gist_loaded:\n",
    "    print(f\"   Config: {json.dumps(model_config, indent=2)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title \ud83d\ude80 Initialize Model { display-mode: \"form\" }\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import inspect\n",
    "from types import SimpleNamespace\n",
    "\n",
    "# Detect device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"\ud83d\udda5\ufe0f  Device: {device}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"   GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"   Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
    "\n",
    "# Create model instance\n",
    "if gist_loaded:\n",
    "    # Custom model from Transformer Builder\n",
    "    # Import the model from downloaded file\n",
    "    try:\n",
    "        sys.path.insert(0, '.')\n",
    "\n",
    "        # Import all classes from model.py\n",
    "        import importlib.util\n",
    "        spec = importlib.util.spec_from_file_location(\"custom_model\", \"model.py\")\n",
    "        custom_model_module = importlib.util.module_from_spec(spec)\n",
    "        spec.loader.exec_module(custom_model_module)\n",
    "\n",
    "        # Find the model class\n",
    "        model_class = None\n",
    "        for name, obj in vars(custom_model_module).items():\n",
    "            if isinstance(obj, type) and issubclass(obj, nn.Module) and obj is not nn.Module:\n",
    "                if name == model_name:\n",
    "                    model_class = obj\n",
    "                    break\n",
    "        \n",
    "        if model_class is None:\n",
    "            # Fallback: find any nn.Module subclass\n",
    "            for name, obj in vars(custom_model_module).items():\n",
    "                if isinstance(obj, type) and issubclass(obj, nn.Module) and obj is not nn.Module:\n",
    "                    model_class = obj\n",
    "                    print(f\"\u26a0\ufe0f Using {name} (expected {model_name})\")\n",
    "                    break\n",
    "        \n",
    "        if model_class:\n",
    "            # Check constructor signature (KEY FIX from template.ipynb)\n",
    "            sig = inspect.signature(model_class.__init__)\n",
    "            params_list = [p for p in sig.parameters.values() if p.name != 'self']\n",
    "            \n",
    "            if len(params_list) == 0:\n",
    "                # Parameterless constructor (Transformer Builder models)\n",
    "                print(\"\u2139\ufe0f  Model has parameterless constructor (Transformer Builder export)\")\n",
    "                model = model_class()\n",
    "            else:\n",
    "                # Parameterized constructor (traditional models)\n",
    "                print(f\"\u2139\ufe0f  Model accepts {len(params_list)} parameter(s)\")\n",
    "                model = model_class(**model_config)\n",
    "            \n",
    "            print(f\"\u2705 Custom model instantiated: {model.__class__.__name__}\")\n",
    "        else:\n",
    "            raise Exception(\"No model class found in model.py\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"\u274c Failed to instantiate custom model: {e}\")\n",
    "        print(\"   Falling back to example model...\")\n",
    "        gist_loaded = False\n",
    "\n",
    "if not gist_loaded:\n",
    "    # Example model (fallback)\n",
    "    print(\"\ud83d\udce6 Loading example model (GPT-2 architecture)...\")\n",
    "\n",
    "    class ExampleTransformer(nn.Module):\n",
    "        \"\"\"Example GPT-2 style transformer for demonstration.\"\"\"\n",
    "\n",
    "        def __init__(self, vocab_size=50257, d_model=768, n_layers=12, n_heads=12, max_seq_len=1024):\n",
    "            super().__init__()\n",
    "            self.vocab_size = vocab_size\n",
    "            self.d_model = d_model\n",
    "            self.n_layers = n_layers\n",
    "            self.n_heads = n_heads\n",
    "            self.max_seq_len = max_seq_len\n",
    "\n",
    "            self.embedding = nn.Embedding(vocab_size, d_model)\n",
    "            self.position_embedding = nn.Embedding(max_seq_len, d_model)\n",
    "\n",
    "            # Simple transformer layers\n",
    "            self.layers = nn.ModuleList([\n",
    "                nn.TransformerEncoderLayer(\n",
    "                    d_model,\n",
    "                    n_heads,\n",
    "                    dim_feedforward=d_model*4,\n",
    "                    batch_first=True,\n",
    "                    dropout=0.1\n",
    "                )\n",
    "                for _ in range(n_layers)\n",
    "            ])\n",
    "\n",
    "            self.ln_f = nn.LayerNorm(d_model)\n",
    "            self.lm_head = nn.Linear(d_model, vocab_size, bias=False)\n",
    "\n",
    "        def forward(self, input_ids):\n",
    "            batch_size, seq_len = input_ids.shape\n",
    "\n",
    "            # Embeddings\n",
    "            token_emb = self.embedding(input_ids)\n",
    "            pos_ids = torch.arange(seq_len, device=input_ids.device).unsqueeze(0)\n",
    "            pos_emb = self.position_embedding(pos_ids)\n",
    "\n",
    "            x = token_emb + pos_emb\n",
    "\n",
    "            # Transformer layers\n",
    "            for layer in self.layers:\n",
    "                x = layer(x)\n",
    "\n",
    "            x = self.ln_f(x)\n",
    "            logits = self.lm_head(x)\n",
    "\n",
    "            return logits\n",
    "\n",
    "    # Create example model\n",
    "    model = ExampleTransformer()\n",
    "    model_config = {\n",
    "        'vocab_size': 50257,\n",
    "        'd_model': 768,\n",
    "        'n_layers': 12,\n",
    "        'n_heads': 12,\n",
    "        'max_seq_len': 1024\n",
    "    }\n",
    "\n",
    "    print(f\"\u2705 Example model definition loaded\")\n",
    "\n",
    "# Move to device\n",
    "model = model.to(device)\n",
    "\n",
    "# Model summary\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f\"\\n\u2705 Model initialized on {device}\")\n",
    "print(f\"   Total parameters: {total_params:,}\")\n",
    "print(f\"   Trainable parameters: {trainable_params:,}\")\n",
    "print(f\"   Model size: {total_params * 4 / 1e6:.1f} MB (fp32)\")\n",
    "\n",
    "# Create config object for training utilities\n",
    "config_obj = SimpleNamespace(**model_config)\n",
    "if not hasattr(config_obj, 'vocab_size'):\n",
    "    config_obj.vocab_size = model_config.get('vocab_size', 50257)\n",
    "if not hasattr(config_obj, 'max_seq_len'):\n",
    "    config_obj.max_seq_len = model_config.get('max_seq_len', 1024)\n",
    "\n",
    "print(f\"\\n\ud83c\udfaf Ready for training!\")\n",
    "print(f\"\\n\u2139\ufe0f  Note: Update Section 4 training config before starting training loop.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fc17228",
   "metadata": {},
   "source": [
    "<a id=\"section-3\"></a>\n",
    "# \ud83d\udcca Section 3: Data Loading\n",
    "\n",
    "Choose your data source (run ONE of the following cells):\n",
    "- **Option 1**: HuggingFace Datasets (recommended)\n",
    "- **Option 2**: Google Drive Upload\n",
    "- **Option 3**: File Upload (small datasets)\n",
    "- **Option 4**: Local Files (from previous sessions)\n",
    "- **Option 5**: Synthetic Data (testing only)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b3e6fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# CONFIGURATION: Edit dataset name\n",
    "dataset_name = \"wikitext\"  #@param {type:\"string\"}\n",
    "config_name = \"wikitext-2-raw-v1\"  #@param {type:\"string\"}\n",
    "max_samples = 1000  #@param {type:\"integer\"}\n",
    "\n",
    "# Load dataset\n",
    "dataset = load_dataset(dataset_name, config_name)\n",
    "train_data = dataset['train'].select(range(min(max_samples, len(dataset['train']))))\n",
    "val_data = dataset['validation'].select(range(min(100, len(dataset['validation']))))\n",
    "\n",
    "print(f\"\u2705 Loaded {len(train_data)} training samples, {len(val_data)} validation samples\")\n",
    "print(f\"   Example: {train_data[0]}\")\n",
    "\n",
    "data_source = \"huggingface\"\n",
    "dataset_info = {'name': dataset_name, 'config': config_name, 'train_size': len(train_data), 'val_size': len(val_data)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e417890",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "drive_data_path = \"/content/drive/MyDrive/TransformerTraining/datasets/my_data.txt\"  #@param {type:\"string\"}\n",
    "\n",
    "if os.path.exists(drive_data_path):\n",
    "    with open(drive_data_path, 'r', encoding='utf-8') as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    split_idx = int(0.9 * len(lines))\n",
    "    train_data = [line.strip() for line in lines[:split_idx]]\n",
    "    val_data = [line.strip() for line in lines[split_idx:]]\n",
    "\n",
    "    print(f\"\u2705 Loaded {len(train_data)} training samples, {len(val_data)} validation samples\")\n",
    "    data_source = \"google_drive\"\n",
    "    dataset_info = {'path': drive_data_path, 'train_size': len(train_data), 'val_size': len(val_data)}\n",
    "else:\n",
    "    print(f\"\u274c File not found: {drive_data_path}\")\n",
    "    print(\"   Please upload your data to Google Drive first\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "366269e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "import io\n",
    "\n",
    "# Upload file\n",
    "uploaded = files.upload()\n",
    "\n",
    "if uploaded:\n",
    "    filename = list(uploaded.keys())[0]\n",
    "    content = uploaded[filename].decode('utf-8')\n",
    "    lines = content.split('\\n')\n",
    "\n",
    "    split_idx = int(0.9 * len(lines))\n",
    "    train_data = [line.strip() for line in lines[:split_idx]]\n",
    "    val_data = [line.strip() for line in lines[split_idx:]]\n",
    "\n",
    "    print(f\"\u2705 Loaded {len(train_data)} training samples, {len(val_data)} validation samples\")\n",
    "    data_source = \"file_upload\"\n",
    "    dataset_info = {'filename': filename, 'train_size': len(train_data), 'val_size': len(val_data)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a4882b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "\n",
    "cache_path = f'{workspace_root}/datasets/cached_data.pkl'\n",
    "\n",
    "if os.path.exists(cache_path):\n",
    "    with open(cache_path, 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "\n",
    "    train_data = data['train']\n",
    "    val_data = data['val']\n",
    "\n",
    "    print(f\"\u2705 Loaded cached data: {len(train_data)} train, {len(val_data)} val\")\n",
    "    data_source = \"cached\"\n",
    "    dataset_info = {'path': cache_path, 'train_size': len(train_data), 'val_size': len(val_data)}\n",
    "else:\n",
    "    print(f\"\u274c No cached data found at {cache_path}\")\n",
    "    print(\"   Run one of the other data loading options first\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7865100c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Generate synthetic data for testing\n",
    "vocab_size = 50257  # GPT-2 vocab\n",
    "seq_len = 32\n",
    "n_samples = 100\n",
    "\n",
    "train_data = [torch.randint(0, vocab_size, (seq_len,)) for _ in range(n_samples)]\n",
    "val_data = [torch.randint(0, vocab_size, (seq_len,)) for _ in range(20)]\n",
    "\n",
    "print(f\"\u2705 Generated {len(train_data)} synthetic training samples\")\n",
    "print(f\"   \u26a0\ufe0f Warning: Synthetic data is for testing only\")\n",
    "data_source = \"synthetic\"\n",
    "dataset_info = {'vocab_size': vocab_size, 'seq_len': seq_len, 'train_size': len(train_data), 'val_size': len(val_data)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7s2xtx5f5n8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title \ud83c\udfaf Task Specification (Auto-Detected) { display-mode: \"form\" }\n",
    "\n",
    "# === SELF-CONTAINED IMPORTS ===\n",
    "import sys\n",
    "import os\n",
    "if '.' not in sys.path:\n",
    "    sys.path.insert(0, '.')\n",
    "\n",
    "# Import with error handling\n",
    "try:\n",
    "    from utils.training.task_spec import TaskSpec\n",
    "    from types import SimpleNamespace\n",
    "    import torch\n",
    "except ImportError as e:\n",
    "    print(\"\u274c Import failed!\")\n",
    "    print(f\"\\nError: {e}\")\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"TROUBLESHOOTING\")\n",
    "    print(\"=\"*70)\n",
    "    print(\"\\n1. Run the 'Prerequisite Validation' cell above\")\n",
    "    print(\"2. Ensure Section 1 setup completed successfully\")\n",
    "    print(\"3. Check that utils package is downloaded\")\n",
    "    raise\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"TASK SPECIFICATION\")\n",
    "print(\"=\" * 70)\n",
    "print()\n",
    "\n",
    "# Auto-detect modality from data source\n",
    "detected_modality = \"text\"  # Default\n",
    "detected_task_type = \"lm\"   # Default\n",
    "\n",
    "# Try to detect from data\n",
    "if 'train_data' in globals() and train_data:\n",
    "    try:\n",
    "        sample = train_data[0] if isinstance(train_data, list) else train_data[0]\n",
    "        \n",
    "        # Check for vision data\n",
    "        if isinstance(sample, dict):\n",
    "            if 'pixel_values' in sample or 'image' in sample:\n",
    "                detected_modality = \"vision\"\n",
    "                detected_task_type = \"vision_classification\"\n",
    "                print(\"\ud83d\udd0d Detected vision data (found pixel_values/image in sample)\")\n",
    "            elif 'input_ids' in sample or 'text' in sample:\n",
    "                detected_modality = \"text\"\n",
    "                detected_task_type = \"lm\"\n",
    "                print(\"\ud83d\udd0d Detected text data (found input_ids/text in sample)\")\n",
    "        elif isinstance(sample, torch.Tensor):\n",
    "            if sample.dim() >= 3:  # Likely image (C, H, W) or (B, C, H, W)\n",
    "                detected_modality = \"vision\"\n",
    "                detected_task_type = \"vision_classification\"\n",
    "                print(f\"\ud83d\udd0d Detected vision data (tensor shape: {sample.shape})\")\n",
    "            else:\n",
    "                detected_modality = \"text\"\n",
    "                detected_task_type = \"lm\"\n",
    "                print(f\"\ud83d\udd0d Detected text data (tensor shape: {sample.shape})\")\n",
    "    except Exception as e:\n",
    "        print(f\"\u26a0\ufe0f  Could not auto-detect from data: {e}\")\n",
    "        print(\"   Using default: text/lm\")\n",
    "\n",
    "print(f\"   Modality: {detected_modality}\")\n",
    "print(f\"   Task type: {detected_task_type}\")\n",
    "print()\n",
    "\n",
    "# Allow manual override\n",
    "task_modality = detected_modality  #@param [\"text\", \"vision\", \"audio\", \"tabular\"]\n",
    "task_type = detected_task_type  #@param [\"lm\", \"classification\", \"seq2seq\", \"vision_classification\", \"vision_multilabel\"]\n",
    "\n",
    "print(f\"\ud83d\udcdd Final selection:\")\n",
    "print(f\"   Modality: {task_modality}\")\n",
    "print(f\"   Task type: {task_type}\")\n",
    "print()\n",
    "\n",
    "# Create TaskSpec based on modality\n",
    "if task_modality == \"vision\":\n",
    "    # Vision task configuration\n",
    "    image_size = getattr(config_obj, 'image_size', [3, 224, 224]) if 'config_obj' in globals() else [3, 224, 224]\n",
    "    num_classes = getattr(config_obj, 'num_classes', 10) if 'config_obj' in globals() else 10\n",
    "    \n",
    "    task_spec = TaskSpec(\n",
    "        name=f\"{model_name}_vision\" if 'model_name' in globals() else \"vision_task\",\n",
    "        task_type=task_type,\n",
    "        model_family=\"encoder_only\",\n",
    "        input_fields=[\"pixel_values\"],\n",
    "        target_field=\"labels\",\n",
    "        loss_type=\"cross_entropy\",\n",
    "        metrics=[\"loss\", \"accuracy\"],\n",
    "        modality=\"vision\",\n",
    "        input_schema={\"image_size\": image_size, \"channels_first\": True},\n",
    "        output_schema={\"num_classes\": num_classes},\n",
    "        preprocessing_config={\n",
    "            \"normalize\": True,\n",
    "            \"mean\": [0.485, 0.456, 0.406],  # ImageNet defaults\n",
    "            \"std\": [0.229, 0.224, 0.225]\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    print(\"\u2705 Vision TaskSpec created\")\n",
    "    print(f\"   Image size: {image_size}\")\n",
    "    print(f\"   Num classes: {num_classes}\")\n",
    "    print(f\"   VisionDataCollator will be auto-selected (v3.5 feature)\")\n",
    "    \n",
    "else:  # text modality\n",
    "    # Text task configuration\n",
    "    vocab_size = getattr(config_obj, 'vocab_size', 50257) if 'config_obj' in globals() else 50257\n",
    "    max_seq_len = getattr(config_obj, 'max_seq_len', 128) if 'config_obj' in globals() else 128\n",
    "    \n",
    "    task_spec = TaskSpec(\n",
    "        name=f\"{model_name}_lm\" if 'model_name' in globals() else \"text_task\",\n",
    "        task_type=task_type,\n",
    "        model_family=\"decoder_only\",\n",
    "        input_fields=[\"input_ids\", \"attention_mask\"],\n",
    "        target_field=\"labels\",\n",
    "        loss_type=\"cross_entropy\",\n",
    "        metrics=[\"loss\", \"perplexity\", \"accuracy\"],\n",
    "        modality=\"text\",\n",
    "        input_schema={\"max_seq_len\": max_seq_len, \"vocab_size\": vocab_size},\n",
    "        output_schema={\"vocab_size\": vocab_size},\n",
    "        special_tokens={\"pad_token_id\": 0},\n",
    "        additional_config={\"shift_labels\": True}\n",
    "    )\n",
    "    \n",
    "    print(\"\u2705 Text TaskSpec created\")\n",
    "    print(f\"   Vocab size: {vocab_size}\")\n",
    "    print(f\"   Max sequence length: {max_seq_len}\")\n",
    "\n",
    "print()\n",
    "print(\"=\" * 70)\n",
    "print(\"\u2705 TASK SPECIFICATION COMPLETE\")\n",
    "print(\"=\" * 70)\n",
    "print()\n",
    "print(\"\ud83d\udca1 TaskSpec enables:\")\n",
    "print(\"   - Modality-aware data collation\")\n",
    "print(\"   - Drift detection (v3.6)\")\n",
    "print(\"   - Export bundle generation (v3.5)\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afac06b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title \ud83d\udcdd Data Tokenization & Preprocessing { display-mode: \"form\" }\n",
    "\n",
    "# === SELF-CONTAINED IMPORTS ===\n",
    "import sys\n",
    "import os\n",
    "if '.' not in sys.path:\n",
    "    sys.path.insert(0, '.')\n",
    "\n",
    "try:\n",
    "    import torch\n",
    "    from utils.tokenization.adaptive_tokenizer import AdaptiveTokenizer\n",
    "    from utils.tokenization.data_collator import LanguageModelingDataCollator\n",
    "    import time\n",
    "except ImportError as e:\n",
    "    print(\"\u274c Import failed!\")\n",
    "    print(f\"\\nError: {e}\")\n",
    "    print(\"\\nTroubleshooting:\")\n",
    "    print(\"1. Ensure utils package downloaded (Section 1)\")\n",
    "    print(\"2. Re-run notebook from start\")\n",
    "    raise\n",
    "\n",
    "# === PREREQUISITE CHECKS ===\n",
    "if 'train_data' not in globals() or 'val_data' not in globals():\n",
    "    raise NameError(\"train_data/val_data not found. Run data loading cell first.\")\n",
    "if 'config_obj' not in globals():\n",
    "    raise NameError(\"config_obj not found. Run model loading cell first.\")\n",
    "if 'task_spec' not in globals():\n",
    "    raise NameError(\"task_spec not found. Run task specification cell first.\")\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"DATA TOKENIZATION & PREPROCESSING\")\n",
    "print(\"=\"*70)\n",
    "print()\n",
    "\n",
    "# === MODALITY-AWARE PROCESSING ===\n",
    "modality = task_spec.modality\n",
    "print(f\"\ud83d\udccb Modality: {modality}\")\n",
    "print(f\"\ud83d\udce6 Vocab Size: {config_obj.vocab_size}\")\n",
    "print(f\"\ud83d\udccf Max Sequence Length: {task_spec.max_seq_len}\")\n",
    "print()\n",
    "\n",
    "if modality == 'text':\n",
    "    # === TEXT TOKENIZATION ===\n",
    "    \n",
    "    # Step 1: Auto-detect text field\n",
    "    text_fields = ['text', 'content', 'sentence', 'document', 'body', 'input', 'prompt']\n",
    "    text_field = next((f for f in text_fields if f in train_data.features), None)\n",
    "    \n",
    "    if text_field is None:\n",
    "        print(\"\u274c No text field found in dataset!\")\n",
    "        print(f\"   Available fields: {list(train_data.features.keys())}\")\n",
    "        raise ValueError(\"Cannot auto-detect text field. Please specify manually.\")\n",
    "    \n",
    "    print(f\"\u2705 Text field detected: '{text_field}'\")\n",
    "    print()\n",
    "    \n",
    "    # Step 2: Load or create tokenizer via AdaptiveTokenizer\n",
    "    print(\"\ud83d\udd27 Loading tokenizer...\")\n",
    "    tokenizer = AdaptiveTokenizer.load_or_create(\n",
    "        vocab_size=config_obj.vocab_size,\n",
    "        dataset=train_data\n",
    "    )\n",
    "    print(f\"\u2705 Tokenizer loaded: {tokenizer.__class__.__name__}\")\n",
    "    \n",
    "    # Get vocab size safely\n",
    "    if hasattr(tokenizer, 'vocab_size'):\n",
    "        tok_vocab = tokenizer.vocab_size\n",
    "    elif hasattr(tokenizer, 'get_vocab_size'):\n",
    "        tok_vocab = tokenizer.get_vocab_size()\n",
    "    else:\n",
    "        tok_vocab = len(tokenizer.get_vocab()) if hasattr(tokenizer, 'get_vocab') else 'unknown'\n",
    "    print(f\"   Vocab size: {tok_vocab}\")\n",
    "    print()\n",
    "    \n",
    "    # Step 3: Define tokenization function (lazy evaluation)\n",
    "    def tokenize_batch(batch):\n",
    "        \"\"\"Tokenize a batch of examples using lazy evaluation.\"\"\"\n",
    "        # Handle different tokenizer interfaces\n",
    "        if hasattr(tokenizer, '__call__'):\n",
    "            # HuggingFace tokenizer\n",
    "            result = tokenizer(\n",
    "                batch[text_field],\n",
    "                truncation=True,\n",
    "                max_length=task_spec.max_seq_len,\n",
    "                padding=False,  # Defer to collator for dynamic padding\n",
    "                return_tensors=None  # Keep as lists for now\n",
    "            )\n",
    "        elif hasattr(tokenizer, 'encode'):\n",
    "            # Simple encode interface\n",
    "            result = {\n",
    "                'input_ids': [tokenizer.encode(text, max_length=task_spec.max_seq_len, truncation=True) \n",
    "                             for text in batch[text_field]]\n",
    "            }\n",
    "        else:\n",
    "            raise ValueError(f\"Tokenizer {type(tokenizer)} has no compatible encode method\")\n",
    "        return result\n",
    "    \n",
    "    # Step 4: Apply tokenization via dataset.map (lazy loading)\n",
    "    print(\"\u2699\ufe0f  Tokenizing datasets (this may take a moment)...\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Determine cache behavior\n",
    "    overwrite_cache = False  # Set to True during debugging\n",
    "    num_proc = min(4, os.cpu_count() or 1)  # Parallel processing\n",
    "    \n",
    "    # Tokenize train dataset\n",
    "    train_data = train_data.map(\n",
    "        tokenize_batch,\n",
    "        batched=True,\n",
    "        remove_columns=[text_field],  # Remove raw text to save memory\n",
    "        num_proc=num_proc if os.name != 'nt' else 1,  # Windows compatibility\n",
    "        load_from_cache_file=not overwrite_cache,\n",
    "        desc=\"Tokenizing train data\"\n",
    "    )\n",
    "    \n",
    "    # Tokenize validation dataset\n",
    "    val_data = val_data.map(\n",
    "        tokenize_batch,\n",
    "        batched=True,\n",
    "        remove_columns=[text_field],\n",
    "        num_proc=num_proc if os.name != 'nt' else 1,\n",
    "        load_from_cache_file=not overwrite_cache,\n",
    "        desc=\"Tokenizing val data\"\n",
    "    )\n",
    "    \n",
    "    elapsed = time.time() - start_time\n",
    "    print(f\"\u2705 Tokenization complete in {elapsed:.2f}s\")\n",
    "    print()\n",
    "    \n",
    "    # Step 5: Set format to PyTorch (lazy, zero-copy)\n",
    "    train_data.set_format(type='torch', columns=['input_ids'])\n",
    "    val_data.set_format(type='torch', columns=['input_ids'])\n",
    "    \n",
    "    # Step 6: Create collator for dynamic padding\n",
    "    data_collator = LanguageModelingDataCollator(\n",
    "        tokenizer=tokenizer,\n",
    "        mlm=False,  # Causal LM (GPT-style)\n",
    "        padding_side='right'\n",
    "    )\n",
    "    \n",
    "    # Step 7: Display statistics\n",
    "    print(\"\ud83d\udcca Tokenization Statistics:\")\n",
    "    print(f\"   Train samples: {len(train_data)}\")\n",
    "    print(f\"   Val samples: {len(val_data)}\")\n",
    "    \n",
    "    # Compute length statistics\n",
    "    sample_size = min(1000, len(train_data))\n",
    "    train_lengths = [len(ex['input_ids']) for ex in train_data.select(range(sample_size))]\n",
    "    mean_len = sum(train_lengths) / len(train_lengths)\n",
    "    max_len = max(train_lengths)\n",
    "    truncated_pct = sum(1 for l in train_lengths if l == task_spec.max_seq_len) / len(train_lengths) * 100\n",
    "    \n",
    "    print(f\"   Mean length: {mean_len:.1f} tokens\")\n",
    "    print(f\"   Max length: {max_len} tokens\")\n",
    "    print(f\"   Truncated: {truncated_pct:.1f}%\")\n",
    "    \n",
    "    if truncated_pct > 10:\n",
    "        print(f\"   \u26a0\ufe0f  Warning: >{truncated_pct:.0f}% sequences truncated. Consider increasing max_seq_len.\")\n",
    "    \n",
    "    # Step 8: Show example\n",
    "    print()\n",
    "    print(\"\ud83d\udd0d Example tokenized sample:\")\n",
    "    example = train_data[0]\n",
    "    print(f\"   Input IDs shape: {example['input_ids'].shape}\")\n",
    "    print(f\"   First 20 tokens: {example['input_ids'][:20].tolist()}\")\n",
    "    if hasattr(tokenizer, 'decode'):\n",
    "        try:\n",
    "            decoded = tokenizer.decode(example['input_ids'][:50])\n",
    "            print(f\"   Decoded preview: {decoded[:100]}...\")\n",
    "        except:\n",
    "            print(f\"   (decode not available for this tokenizer)\")\n",
    "\n",
    "elif modality == 'vision':\n",
    "    # === VISION PREPROCESSING ===\n",
    "    try:\n",
    "        from torchvision import transforms\n",
    "        from utils.tokenization.data_collator import VisionDataCollator\n",
    "        \n",
    "        print(\"\ud83d\uddbc\ufe0f  Vision modality detected\")\n",
    "        \n",
    "        # Get image size from task_spec or config\n",
    "        image_size = getattr(task_spec, 'image_size', 224)\n",
    "        \n",
    "        # Define image transforms\n",
    "        transform = transforms.Compose([\n",
    "            transforms.Resize((image_size, image_size)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "        \n",
    "        def preprocess_images(batch):\n",
    "            \"\"\"Preprocess images.\"\"\"\n",
    "            images = [transform(img.convert('RGB')) for img in batch['image']]\n",
    "            return {'pixel_values': images}\n",
    "        \n",
    "        print(\"\u2699\ufe0f  Preprocessing images...\")\n",
    "        train_data = train_data.map(\n",
    "            preprocess_images,\n",
    "            batched=True,\n",
    "            remove_columns=['image'],\n",
    "            desc=\"Preprocessing train images\"\n",
    "        )\n",
    "        val_data = val_data.map(\n",
    "            preprocess_images,\n",
    "            batched=True,\n",
    "            remove_columns=['image'],\n",
    "            desc=\"Preprocessing val images\"\n",
    "        )\n",
    "        \n",
    "        train_data.set_format(type='torch', columns=['pixel_values', 'label'])\n",
    "        val_data.set_format(type='torch', columns=['pixel_values', 'label'])\n",
    "        \n",
    "        data_collator = VisionDataCollator(image_size)\n",
    "        print(f\"\u2705 Vision preprocessing complete\")\n",
    "    except ImportError as e:\n",
    "        print(f\"\u26a0\ufe0f  Vision preprocessing failed: {e}\")\n",
    "        print(\"   Install torchvision: !pip install torchvision\")\n",
    "        data_collator = None\n",
    "\n",
    "elif modality == 'audio':\n",
    "    # === AUDIO PREPROCESSING ===\n",
    "    print(\"\ud83c\udfb5 Audio modality detected\")\n",
    "    print(\"\u26a0\ufe0f  Audio preprocessing not yet implemented\")\n",
    "    print(\"   Falling back to default behavior\")\n",
    "    data_collator = None\n",
    "\n",
    "else:\n",
    "    # === UNKNOWN MODALITY ===\n",
    "    print(f\"\u26a0\ufe0f  Unknown modality: {modality}\")\n",
    "    print(\"   Proceeding without preprocessing\")\n",
    "    data_collator = None\n",
    "\n",
    "print()\n",
    "print(\"=\"*70)\n",
    "print(\"\u2705 PREPROCESSING COMPLETE\")\n",
    "print(\"=\"*70)\n",
    "print()\n",
    "print(\"\ud83d\udce6 Output format:\")\n",
    "print(f\"   train_data: {type(train_data)}\")\n",
    "print(f\"   val_data: {type(val_data)}\")\n",
    "print(f\"   data_collator: {type(data_collator).__name__ if data_collator else 'None'}\")\n",
    "print()\n",
    "print(\"\u2728 Ready for training!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56295914",
   "metadata": {},
   "source": [
    "<a id=\"section-4\"></a>\n",
    "# \u2699\ufe0f Section 4: Training Configuration\n",
    "\n",
    "Configure hyperparameters using Colab forms below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "269a022f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title \u2699\ufe0f Training Configuration (v3.5/v3.6 Features) { display-mode: \"form\" }\n",
    "\n",
    "# === SELF-CONTAINED IMPORTS ===\n",
    "import sys\n",
    "import os\n",
    "if '.' not in sys.path:\n",
    "    sys.path.insert(0, '.')\n",
    "\n",
    "# Import with error handling\n",
    "try:\n",
    "    from utils.training.training_config import TrainingConfig\n",
    "    import torch\n",
    "except ImportError as e:\n",
    "    print(\"\u274c Import failed!\")\n",
    "    print(f\"\\nError: {e}\")\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"TROUBLESHOOTING\")\n",
    "    print(\"=\"*70)\n",
    "    print(\"\\n1. Run the 'Prerequisite Validation' cell in Section 1\")\n",
    "    print(\"2. Ensure utils package is properly installed\")\n",
    "    print(\"3. Run all previous cells in order\")\n",
    "    raise\n",
    "\n",
    "# Prerequisite check\n",
    "if 'workspace_root' not in globals():\n",
    "    print(\"\u274c workspace_root not found!\")\n",
    "    print(\"\\n\ud83d\udccd You are here: Section 4 (Training Configuration)\")\n",
    "    print(\"\\n\u26a0\ufe0f  Required: Run Section 1 (Setup & Drive Workspace) first\")\n",
    "    raise NameError(\"workspace_root not defined. Run Section 1 setup cells.\")\n",
    "\n",
    "if 'task_spec' not in globals():\n",
    "    print(\"\u274c task_spec not found!\")\n",
    "    print(\"\\n\ud83d\udccd You are here: Section 4 (Training Configuration)\")\n",
    "    print(\"\\n\u26a0\ufe0f  Required: Run Section 3 (Task Specification) first\")\n",
    "    raise NameError(\"task_spec not defined. Run Task Specification cell in Section 3.\")\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"TRAINING CONFIGURATION\")\n",
    "print(\"=\" * 70)\n",
    "print()\n",
    "\n",
    "# === HYPERPARAMETERS ===\n",
    "learning_rate = 5e-5  #@param {type:\"number\"}\n",
    "batch_size = 4  #@param {type:\"integer\"}\n",
    "epochs = 10  #@param {type:\"integer\"}\n",
    "warmup_ratio = 0.1  #@param {type:\"number\"}\n",
    "weight_decay = 0.01  #@param {type:\"number\"}\n",
    "gradient_clip_norm = 1.0  #@param {type:\"number\"}\n",
    "\n",
    "# === v3.5 PERFORMANCE FEATURES ===\n",
    "# torch.compile: 10-20% speedup (PyTorch 2.0+)\n",
    "compile_mode = \"default\"  #@param [\"None\", \"default\", \"reduce-overhead\", \"max-autotune\"]\n",
    "compile_mode = None if compile_mode == \"None\" else compile_mode\n",
    "\n",
    "# Gradient accumulation: effective batch size = batch_size * accumulation_steps\n",
    "gradient_accumulation_steps = 1  #@param {type:\"integer\"}\n",
    "\n",
    "# === v3.5 EXPORT FEATURES ===\n",
    "# Export bundle generation\n",
    "export_bundle = True  #@param {type:\"boolean\"}\n",
    "export_formats_str = \"onnx,torchscript,pytorch\"  #@param {type:\"string\"}\n",
    "export_formats = [fmt.strip() for fmt in export_formats_str.split(',')]\n",
    "\n",
    "# === STANDARD TRAINING FEATURES ===\n",
    "use_amp = True  #@param {type:\"boolean\"}\n",
    "deterministic = False  #@param {type:\"boolean\"}\n",
    "run_name = \"training-run\"  #@param {type:\"string\"}\n",
    "random_seed = 42  #@param {type:\"integer\"}\n",
    "\n",
    "# Create TrainingConfig\n",
    "training_config = TrainingConfig(\n",
    "    # Hyperparameters\n",
    "    learning_rate=learning_rate,\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    warmup_ratio=warmup_ratio,\n",
    "    weight_decay=weight_decay,\n",
    "    max_grad_norm=gradient_clip_norm,\n",
    "    \n",
    "    # v3.5 features\n",
    "    compile_mode=compile_mode,\n",
    "    gradient_accumulation_steps=gradient_accumulation_steps,\n",
    "    export_bundle=export_bundle,\n",
    "    export_formats=export_formats,\n",
    "    export_dir=f'{workspace_root}/exports',\n",
    "    \n",
    "    # Standard features\n",
    "    use_amp=use_amp,\n",
    "    deterministic=deterministic,\n",
    "    random_seed=random_seed,\n",
    "    run_name=run_name,\n",
    "    \n",
    "    # Directories\n",
    "    checkpoint_dir=f'{workspace_root}/checkpoints',\n",
    ")\n",
    "\n",
    "# Validate configuration\n",
    "training_config.validate()\n",
    "\n",
    "# Save to Drive with proper filename\n",
    "import os\n",
    "from datetime import datetime\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "config_filename = f\"config_{training_config.run_name}_{timestamp}.json\"\n",
    "config_path = os.path.join(f'{workspace_root}/configs', config_filename)\n",
    "training_config.save(config_path)\n",
    "print(f\"\u2705 Config saved: {config_path}\")\n",
    "print()\n",
    "\n",
    "# Display configuration summary\n",
    "print(\"HYPERPARAMETERS\")\n",
    "print(\"-\" * 70)\n",
    "print(f\"{'Run Name:':<30} {training_config.run_name}\")\n",
    "print(f\"{'Learning Rate:':<30} {training_config.learning_rate}\")\n",
    "print(f\"{'Batch Size (per step):':<30} {training_config.batch_size}\")\n",
    "print(f\"{'Effective Batch Size:':<30} {training_config.batch_size * training_config.gradient_accumulation_steps}\")\n",
    "print(f\"{'Epochs:':<30} {training_config.epochs}\")\n",
    "print(f\"{'Warmup Ratio:':<30} {training_config.warmup_ratio}\")\n",
    "print(f\"{'Weight Decay:':<30} {training_config.weight_decay}\")\n",
    "print(f\"{'Gradient Clipping:':<30} {gradient_clip_norm}\")\n",
    "print()\n",
    "\n",
    "print(\"v3.5 PERFORMANCE FEATURES\")\n",
    "print(\"-\" * 70)\n",
    "print(f\"{'torch.compile:':<30} {compile_mode or 'Disabled'}\")\n",
    "if compile_mode:\n",
    "    expected_speedup = {\"default\": \"10-15%\", \"reduce-overhead\": \"15-20%\", \"max-autotune\": \"20-30%\"}\n",
    "    print(f\"{'  Expected speedup:':<30} ~{expected_speedup.get(compile_mode, '10-20%')}\")\n",
    "    print(f\"{'  Compilation time:':<30} {'~30s' if compile_mode == 'max-autotune' else '~5s'}\")\n",
    "print()\n",
    "print(f\"{'Gradient Accumulation:':<30} {gradient_accumulation_steps}x\")\n",
    "if gradient_accumulation_steps > 1:\n",
    "    log_reduction = 100 * (1 - 1/gradient_accumulation_steps)\n",
    "    print(f\"{'  W&B log reduction:':<30} ~{log_reduction:.0f}%\")\n",
    "    print(f\"{'  Memory efficient:':<30} Train larger models on same GPU\")\n",
    "print()\n",
    "\n",
    "print(\"v3.5 EXPORT FEATURES\")\n",
    "print(\"-\" * 70)\n",
    "print(f\"{'Export Bundle:':<30} {'Enabled' if export_bundle else 'Disabled'}\")\n",
    "if export_bundle:\n",
    "    print(f\"{'  Formats:':<30} {', '.join(export_formats)}\")\n",
    "    print(f\"{'  Output dir:':<30} {training_config.export_dir}\")\n",
    "    print(f\"{'  Includes:':<30} Dockerfile, inference.py, README\")\n",
    "print()\n",
    "\n",
    "print(\"v3.6 AUTOMATIC FEATURES\")\n",
    "print(\"-\" * 70)\n",
    "print(f\"{'Distributed Guardrails:':<30} \u2705 Active (notebook detection)\")\n",
    "print(f\"{'  Prevents:':<30} DDP/FSDP zombie processes in Jupyter/Colab\")\n",
    "print()\n",
    "print(f\"{'Flash Attention:':<30} Auto-enabled (PyTorch 2.0+ + CUDA)\")\n",
    "if torch.__version__ >= \"2.0.0\" and torch.cuda.is_available():\n",
    "    print(f\"{'  Status:':<30} \u2705 Will be enabled during training\")\n",
    "    print(f\"{'  Expected speedup:':<30} 2-4x for attention operations\")\n",
    "elif torch.__version__ < \"2.0.0\":\n",
    "    print(f\"{'  Status:':<30} \u26a0\ufe0f  Requires PyTorch 2.0+\")\n",
    "else:\n",
    "    print(f\"{'  Status:':<30} \u26a0\ufe0f  Requires CUDA (GPU)\")\n",
    "print()\n",
    "print(f\"{'Drift Visualization:':<30} Available via plot_with_drift()\")\n",
    "print(f\"{'  Panels:':<30} 10-panel dashboard (6 training + 4 drift)\")\n",
    "print()\n",
    "\n",
    "print(\"STANDARD FEATURES\")\n",
    "print(\"-\" * 70)\n",
    "print(f\"{'Mixed Precision (AMP):':<30} {'Enabled' if use_amp else 'Disabled'}\")\n",
    "print(f\"{'Deterministic Mode:':<30} {'Enabled' if deterministic else 'Disabled (fast)'}\")\n",
    "print(f\"{'Random Seed:':<30} {random_seed}\")\n",
    "print(f\"{'Data Source:':<30} {data_source if 'data_source' in globals() else 'N/A'}\")\n",
    "print()\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"\u2705 CONFIGURATION COMPLETE\")\n",
    "print(\"=\" * 70)\n",
    "print()\n",
    "print(\"\ud83d\udca1 Proceed to Section 6 for training with all features enabled\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b568df14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display configuration summary\n",
    "print(\"=\" * 60)\n",
    "print(\" \" * 15 + \"TRAINING CONFIGURATION\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"{'Run Name:':<25} {training_config.run_name}\")\n",
    "print(f\"{'Learning Rate:':<25} {training_config.learning_rate}\")\n",
    "print(f\"{'Batch Size (effective):':<25} {training_config.batch_size * training_config.gradient_accumulation_steps}\")\n",
    "print(f\"{'Epochs:':<25} {training_config.epochs}\")\n",
    "print(f\"{'Warmup Ratio:':<25} {training_config.warmup_ratio}\")\n",
    "print(f\"{'Gradient Clipping:':<25} {training_config.max_grad_norm}\")\n",
    "print(f\"{'AMP Enabled:':<25} {training_config.use_amp}\")\n",
    "print(f\"{'Deterministic:':<25} {training_config.deterministic}\")\n",
    "print(f\"{'Random Seed:':<25} {training_config.random_seed}\")\n",
    "print(f\"{'Data Source:':<25} {data_source if 'data_source' in globals() else 'N/A'}\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c5e4445",
   "metadata": {},
   "source": [
    "### Training Mode Selection\n",
    "\n",
    "Based on your `epochs` setting:\n",
    "- **epochs <= 5**: \u26a1 Fast Mode (~5 min)\n",
    "- **epochs <= 15**: \u2696\ufe0f Balanced Mode (~15 min)\n",
    "- **epochs > 15**: \ud83d\udc8e Quality Mode (45+ min)\n",
    "\n",
    "Proceed to training in Section 5 \u2b07\ufe0f"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d46ead6",
   "metadata": {},
   "source": [
    "<a id=\"section-5\"></a>\n",
    "# \ud83d\udd2c Section 5: W&B Tracking Setup (Optional)\n",
    "\n",
    "Enable Weights & Biases for cloud-based experiment tracking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae42ab74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "from getpass import getpass\n",
    "\n",
    "use_wandb = True  #@param {type:\"boolean\"}\n",
    "wandb_project = \"transformer-training\"  #@param {type:\"string\"}\n",
    "wandb_entity = \"\"  #@param {type:\"string\"}\n",
    "\n",
    "if use_wandb:\n",
    "    # Login to W&B\n",
    "    wandb_key = getpass(\"Enter W&B API key (or leave blank to skip): \")\n",
    "    if wandb_key:\n",
    "        wandb.login(key=wandb_key)\n",
    "\n",
    "        # Initialize run\n",
    "        wandb.init(\n",
    "            project=wandb_project,\n",
    "            entity=wandb_entity if wandb_entity else None,\n",
    "            name=config.run_name,\n",
    "            config=config.to_dict(),\n",
    "            tags=[data_source, f\"epochs_{epochs}\"]\n",
    "        )\n",
    "        print(f\"\u2705 W&B initialized: {wandb.run.url}\")\n",
    "    else:\n",
    "        use_wandb = False\n",
    "        print(\"\u26a0\ufe0f W&B skipped - training will use local tracking only\")\n",
    "else:\n",
    "    print(\"\u2139\ufe0f W&B disabled - using local SQLite tracking\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rqtj1fr1pf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title \ud83d\udcca Dataset Drift Profiling (v3.6 - Optional, 1-2 min) { display-mode: \"form\" }\n",
    "\n",
    "enable_drift_detection = True  #@param {type:\"boolean\"}\n",
    "drift_sample_size = 1000  #@param {type:\"integer\"}\n",
    "\n",
    "drift_data = None\n",
    "\n",
    "if enable_drift_detection:\n",
    "    print(\"=\" * 70)\n",
    "    print(\"DATASET DRIFT PROFILING (v3.6)\")\n",
    "    print(\"=\" * 70)\n",
    "    print()\n",
    "    print(\"\ud83d\udcca Computing dataset profiles for drift detection...\")\n",
    "    print(f\"   Sample size: {min(drift_sample_size, len(train_data))} from training\")\n",
    "    print(f\"   Sample size: {min(drift_sample_size, len(val_data))} from validation\")\n",
    "    print()\n",
    "    \n",
    "    try:\n",
    "        # Profile training dataset (reference)\n",
    "        print(\"1/2 Profiling training dataset...\")\n",
    "        train_subset = train_data[:drift_sample_size] if isinstance(train_data, list) else train_data\n",
    "        train_profile = compute_dataset_profile(\n",
    "            dataset=train_subset,\n",
    "            task_spec=task_spec,\n",
    "            sample_size=drift_sample_size\n",
    "        )\n",
    "        print(\"   \u2705 Training profile complete\")\n",
    "        \n",
    "        # Profile validation dataset (comparison)\n",
    "        print(\"2/2 Profiling validation dataset...\")\n",
    "        val_subset = val_data[:drift_sample_size] if isinstance(val_data, list) else val_data\n",
    "        val_profile = compute_dataset_profile(\n",
    "            dataset=val_subset,\n",
    "            task_spec=task_spec,\n",
    "            sample_size=drift_sample_size\n",
    "        )\n",
    "        print(\"   \u2705 Validation profile complete\")\n",
    "        print()\n",
    "        \n",
    "        # Compare profiles\n",
    "        print(\"\ud83d\udd0d Computing drift scores...\")\n",
    "        drift_comparison = compare_profiles(train_profile, val_profile)\n",
    "        \n",
    "        # Display results\n",
    "        print()\n",
    "        print(\"DRIFT DETECTION RESULTS\")\n",
    "        print(\"-\" * 70)\n",
    "        \n",
    "        max_drift = 0.0\n",
    "        for metric, score in drift_comparison['drift_scores'].items():\n",
    "            max_drift = max(max_drift, score)\n",
    "            \n",
    "            # Determine status\n",
    "            if score < 0.1:\n",
    "                status_emoji = '\u2705'\n",
    "                status_text = 'Healthy'\n",
    "            elif score < 0.2:\n",
    "                status_emoji = '\u26a0\ufe0f '\n",
    "                status_text = 'Warning'\n",
    "            else:\n",
    "                status_emoji = '\ud83d\udea8'\n",
    "                status_text = 'Critical'\n",
    "            \n",
    "            print(f\"{status_emoji} {metric:<25} {score:.4f} ({status_text})\")\n",
    "        \n",
    "        print(\"-\" * 70)\n",
    "        print()\n",
    "        \n",
    "        # Overall status\n",
    "        if max_drift < 0.1:\n",
    "            overall_status = 'ok'\n",
    "            print(\"\u2705 HEALTHY: Minimal drift detected\")\n",
    "            print(\"   Training and validation datasets are well-matched\")\n",
    "        elif max_drift < 0.2:\n",
    "            overall_status = 'warn'\n",
    "            print(\"\u26a0\ufe0f  WARNING: Moderate drift detected\")\n",
    "            print(\"   Recommendation:\")\n",
    "            print(\"   - Monitor training metrics closely\")\n",
    "            print(\"   - Consider reviewing train/val split\")\n",
    "        else:\n",
    "            overall_status = 'alert'\n",
    "            print(\"\ud83d\udea8 CRITICAL: Significant drift detected!\")\n",
    "            print(\"   Action Required:\")\n",
    "            print(\"   - Check data preprocessing consistency\")\n",
    "            print(\"   - Review train/val split strategy\")\n",
    "            print(\"   - Investigate distribution shift causes\")\n",
    "            \n",
    "            if task_modality == \"text\":\n",
    "                print()\n",
    "                print(\"   Common causes for text:\")\n",
    "                print(\"   - Different text sources (news vs social media)\")\n",
    "                print(\"   - Language/domain shift (formal vs casual)\")\n",
    "                print(\"   - Tokenization inconsistencies\")\n",
    "            elif task_modality == \"vision\":\n",
    "                print()\n",
    "                print(\"   Common causes for vision:\")\n",
    "                print(\"   - Different image preprocessing\")\n",
    "                print(\"   - Lighting conditions (indoor vs outdoor)\")\n",
    "                print(\"   - Camera/sensor differences\")\n",
    "        \n",
    "        print()\n",
    "        print(f\"Max Drift Score: {max_drift:.4f}\")\n",
    "        print()\n",
    "        \n",
    "        # Package for dashboard visualization\n",
    "        drift_data = {\n",
    "            'ref_profile': train_profile,\n",
    "            'new_profile': val_profile,\n",
    "            'drift_scores': drift_comparison['drift_scores'],\n",
    "            'status': overall_status\n",
    "        }\n",
    "        \n",
    "        print(\"=\" * 70)\n",
    "        print(\"\u2705 DRIFT PROFILING COMPLETE\")\n",
    "        print(\"=\" * 70)\n",
    "        print()\n",
    "        print(\"\ud83d\udca1 Drift visualization will be available in Section 7 dashboard\")\n",
    "        print()\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\u274c Drift profiling failed: {e}\")\n",
    "        print(\"   Continuing without drift detection\")\n",
    "        drift_data = None\n",
    "else:\n",
    "    print(\"=\" * 70)\n",
    "    print(\"DRIFT PROFILING SKIPPED\")\n",
    "    print(\"=\" * 70)\n",
    "    print()\n",
    "    print(\"\u2139\ufe0f  Drift detection disabled\")\n",
    "    print(\"   Set enable_drift_detection=True to enable\")\n",
    "    print()\n",
    "    print(\"\ud83d\udca1 Benefits of drift detection:\")\n",
    "    print(\"   - Early warning of data distribution shifts\")\n",
    "    print(\"   - Helps diagnose training issues\")\n",
    "    print(\"   - Validates train/val split quality\")\n",
    "    print(\"=\" * 70)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62ce57e5",
   "metadata": {},
   "source": [
    "<a id=\"section-6\"></a>\n",
    "# \ud83c\udfcb\ufe0f Section 6: Training Loop\n",
    "\n",
    "Main training loop with live visualization and checkpointing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c08c98ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title \ud83d\ude80 TrainingCoordinator Setup (v3.5/v3.6) { display-mode: \"form\" }\n",
    "\n",
    "from utils.training.seed_manager import set_random_seed\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"TRAINING COORDINATOR SETUP\")\n",
    "print(\"=\" * 70)\n",
    "print()\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "print(f\"\ud83c\udfb2 Setting random seed: {training_config.random_seed}\")\n",
    "set_random_seed(training_config.random_seed, training_config.deterministic)\n",
    "print(f\"   Mode: {'Deterministic (bit-exact)' if training_config.deterministic else 'Fast (cuDNN auto-tuning)'}\")\n",
    "print()\n",
    "\n",
    "# Create data module\n",
    "print(\"\ud83d\udce6 Creating SimpleDataModule...\")\n",
    "\n",
    "# For text tasks, we need to handle tokenization\n",
    "if task_spec.modality == \"text\":\n",
    "    # Simple tokenizer setup for demonstration\n",
    "    # In production, you'd use a proper tokenizer\n",
    "    print(\"   Modality: TEXT\")\n",
    "    print(\"   Note: Using simplified tokenization for demonstration\")\n",
    "    print(\"   For production, implement proper tokenization in data loading\")\n",
    "    \n",
    "    # Create simple wrapper if data is already tokenized\n",
    "    final_train_data = train_data\n",
    "    final_val_data = val_data\n",
    "    tokenizer = None\n",
    "    \n",
    "else:  # vision\n",
    "    print(f\"   Modality: VISION\")\n",
    "    print(f\"   VisionDataCollator will be auto-selected (v3.5)\")\n",
    "    final_train_data = train_data\n",
    "    final_val_data = val_data\n",
    "    tokenizer = None\n",
    "\n",
    "# Create data module\n",
    "data_module = SimpleDataModule(\n",
    "    train_dataset=final_train_data,\n",
    "    val_dataset=final_val_data,\n",
    "    task_spec=task_spec,\n",
    "    batch_size=training_config.batch_size,\n",
    "    num_workers=2,\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "print(f\"\u2705 Data module created\")\n",
    "approx_train_batches = len(final_train_data) // training_config.batch_size\n",
    "approx_val_batches = len(final_val_data) // training_config.batch_size\n",
    "print(f\"   Train batches: ~{approx_train_batches}\")\n",
    "print(f\"   Val batches: ~{approx_val_batches}\")\n",
    "print()\n",
    "\n",
    "# Initialize TrainingCoordinator\n",
    "print(\"\ud83c\udfd7\ufe0f  Initializing TrainingCoordinator...\")\n",
    "\n",
    "# Determine precision string\n",
    "if training_config.use_amp:\n",
    "    precision_str = '16-mixed'  # PyTorch Lightning 2.x format\n",
    "else:\n",
    "    precision_str = '32-true'\n",
    "\n",
    "coordinator = TrainingCoordinator(\n",
    "    output_dir=training_config.checkpoint_dir,\n",
    "    use_gpu=torch.cuda.is_available(),\n",
    "    precision=precision_str,\n",
    "    gradient_clip_val=training_config.max_grad_norm,\n",
    "    strategy='auto',  # v3.6: Notebook guardrails will auto-adjust\n",
    "    devices='auto'\n",
    ")\n",
    "\n",
    "print(f\"\u2705 Coordinator initialized\")\n",
    "print(f\"   Output dir: {training_config.checkpoint_dir}\")\n",
    "print(f\"   Device: {'GPU' if torch.cuda.is_available() else 'CPU'}\")\n",
    "print(f\"   Precision: {precision_str}\")\n",
    "print(f\"   Strategy: auto (notebook-safe)\")\n",
    "print(f\"   Gradient clipping: {training_config.max_grad_norm}\")\n",
    "print()\n",
    "\n",
    "# Display v3.6 automatic features\n",
    "print(\"v3.6 AUTOMATIC FEATURES\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "# Check Flash Attention\n",
    "if torch.cuda.is_available() and torch.__version__ >= \"2.0.0\":\n",
    "    # Flash Attention will be detected by UniversalModelAdapter\n",
    "    print(\"Flash Attention:\")\n",
    "    print(f\"   \u2705 Available (PyTorch {torch.__version__} + CUDA)\")\n",
    "    print(f\"   Will be auto-enabled during training\")\n",
    "    print(f\"   Expected speedup: 2-4x for attention operations\")\n",
    "else:\n",
    "    print(\"Flash Attention:\")\n",
    "    if not torch.cuda.is_available():\n",
    "        print(f\"   \u26a0\ufe0f  Requires CUDA (currently on CPU)\")\n",
    "    else:\n",
    "        print(f\"   \u26a0\ufe0f  Requires PyTorch 2.0+ (currently {torch.__version__})\")\n",
    "    print(f\"   Falling back to standard attention\")\n",
    "\n",
    "print()\n",
    "\n",
    "# Distributed guardrails\n",
    "print(\"Distributed Training Guardrails:\")\n",
    "print(f\"   \u2705 Active (notebook environment detection)\")\n",
    "print(f\"   Prevents DDP/FSDP zombie processes in Jupyter/Colab\")\n",
    "\n",
    "print()\n",
    "\n",
    "# Display v3.5 features\n",
    "print(\"v3.5 FEATURES\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "if training_config.compile_mode:\n",
    "    print(f\"torch.compile:\")\n",
    "    print(f\"   \u2705 Enabled ({training_config.compile_mode} mode)\")\n",
    "    print(f\"   Expected speedup: ~10-20%\")\n",
    "    print(f\"   First epoch will be slower due to compilation\")\n",
    "else:\n",
    "    print(f\"torch.compile: Disabled\")\n",
    "\n",
    "print()\n",
    "\n",
    "if training_config.gradient_accumulation_steps > 1:\n",
    "    print(f\"Gradient Accumulation:\")\n",
    "    print(f\"   \u2705 {training_config.gradient_accumulation_steps}x steps\")\n",
    "    print(f\"   Effective batch size: {training_config.batch_size * training_config.gradient_accumulation_steps}\")\n",
    "    log_reduction = 100 * (1 - 1/training_config.gradient_accumulation_steps)\n",
    "    print(f\"   W&B log reduction: ~{log_reduction:.0f}%\")\n",
    "\n",
    "print()\n",
    "print(\"=\" * 70)\n",
    "print(\"\u2705 SETUP COMPLETE - Ready for Training\")\n",
    "print(\"=\" * 70)\n",
    "print()\n",
    "print(\"\ud83d\udca1 Run the next cell to start training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcaa782a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title \u25b6\ufe0f Run Training (Professional Pipeline) { display-mode: \"form\" }\n",
    "\n",
    "import time\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"TRAINING EXECUTION\")\n",
    "print(\"=\" * 70)\n",
    "print()\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "print(f\"\ud83c\udfcb\ufe0f  Starting training with {training_config.epochs} epochs...\")\n",
    "print(f\"   Run name: {training_config.run_name}\")\n",
    "print(f\"   Batch size: {training_config.batch_size}\")\n",
    "print(f\"   Learning rate: {training_config.learning_rate}\")\n",
    "print()\n",
    "\n",
    "# Note: The actual train() method signature depends on your TrainingCoordinator implementation\n",
    "# This is a simplified version - adjust parameters based on actual implementation\n",
    "\n",
    "try:\n",
    "    # Execute training\n",
    "    # Simplified call - adjust based on actual TrainingCoordinator.train() signature\n",
    "    print(\"\u2699\ufe0f  Training in progress...\")\n",
    "    print(\"   (This may take several minutes depending on your configuration)\")\n",
    "    print()\n",
    "    \n",
    "    # For this notebook refactor, we'll use a simplified training approach\n",
    "    # that leverages the existing utils while maintaining notebook compatibility\n",
    "    \n",
    "    from utils.tier3_training_utilities import test_fine_tuning\n",
    "    \n",
    "    # Run training using tier3 utilities\n",
    "    # Note: train_data and val_data are now properly tokenized from the preprocessing cell\n",
    "    results = test_fine_tuning(\n",
    "        model=model,\n",
    "        config=config_obj,\n",
    "        train_data=train_data,  # \u2705 Pass tokenized data from preprocessing cell\n",
    "        val_data=val_data,      # \u2705 Pass tokenized data from preprocessing cell\n",
    "        n_epochs=training_config.epochs,\n",
    "        learning_rate=training_config.learning_rate,\n",
    "        batch_size=training_config.batch_size,\n",
    "        random_seed=training_config.random_seed,\n",
    "        deterministic=training_config.deterministic,\n",
    "        use_wandb=use_wandb if 'use_wandb' in globals() else False,\n",
    "        gradient_accumulation_steps=training_config.gradient_accumulation_steps,\n",
    "        weight_decay=training_config.weight_decay,\n",
    "        use_amp=training_config.use_amp\n",
    "    )\n",
    "    \n",
    "    training_duration = time.time() - start_time\n",
    "    \n",
    "    print()\n",
    "    print(\"=\" * 70)\n",
    "    print(\"\u2705 TRAINING COMPLETED SUCCESSFULLY!\")\n",
    "    print(\"=\" * 70)\n",
    "    print()\n",
    "    print(f\"Training Duration: {training_duration/60:.1f} minutes\")\n",
    "    print()\n",
    "    \n",
    "    # Display results summary\n",
    "    print(\"FINAL RESULTS\")\n",
    "    print(\"-\" * 70)\n",
    "    print(f\"{'Final Training Loss:':<30} {results['final_loss']:.4f}\")\n",
    "    \n",
    "    if 'metrics_summary' in results:\n",
    "        metrics_df = results['metrics_summary']\n",
    "        last_epoch = metrics_df.iloc[-1]\n",
    "        \n",
    "        if 'val/loss' in last_epoch:\n",
    "            print(f\"{'Final Validation Loss:':<30} {last_epoch['val/loss']:.4f}\")\n",
    "        if 'val/perplexity' in last_epoch:\n",
    "            print(f\"{'Final Perplexity:':<30} {last_epoch['val/perplexity']:.2f}\")\n",
    "        if 'val/accuracy' in last_epoch:\n",
    "            print(f\"{'Final Accuracy:':<30} {last_epoch['val/accuracy']*100:.2f}%\")\n",
    "    \n",
    "    print()\n",
    "    \n",
    "    # Best epoch info\n",
    "    if 'best_epoch' in results:\n",
    "        print(f\"Best Epoch: {results['best_epoch'] + 1}\")\n",
    "        print(f\"Best Validation Loss: {results.get('best_val_loss', 'N/A')}\")\n",
    "    \n",
    "    print()\n",
    "    \n",
    "    # Save to experiment database\n",
    "    if 'db' in globals():\n",
    "        try:\n",
    "            run_id = db.log_run(\n",
    "                run_name=training_config.run_name,\n",
    "                config=training_config.to_dict(),\n",
    "                notes=f\"Trained with v3.5/v3.6 features | {data_source} data\"\n",
    "            )\n",
    "            \n",
    "            # Log final metrics\n",
    "            if 'metrics_summary' in results:\n",
    "                final_metrics = results['metrics_summary'].iloc[-1].to_dict()\n",
    "                for key, value in final_metrics.items():\n",
    "                    if isinstance(value, (int, float)):\n",
    "                        db.log_metric(run_id, key, value, epoch=training_config.epochs-1)\n",
    "            \n",
    "            db.update_run_status(run_id, 'completed')\n",
    "            print(f\"\u2705 Run logged to ExperimentDB (ID: {run_id})\")\n",
    "        except Exception as e:\n",
    "            print(f\"\u26a0\ufe0f  Could not log to ExperimentDB: {e}\")\n",
    "    \n",
    "    print()\n",
    "    print(\"=\" * 70)\n",
    "    print(\"NEXT STEPS\")\n",
    "    print(\"=\" * 70)\n",
    "    print()\n",
    "    print(\"1. \ud83d\udcca View Results: Run Section 7 for comprehensive dashboard\")\n",
    "    print(\"2. \ud83d\udcbe Download: Use Section 8 to download checkpoints\")\n",
    "    if training_config.export_bundle:\n",
    "        print(\"3. \ud83d\udce6 Export Bundle: Available in Section 8\")\n",
    "    print()\n",
    "    \n",
    "except Exception as e:\n",
    "    print()\n",
    "    print(\"=\" * 70)\n",
    "    print(\"\u274c TRAINING FAILED\")\n",
    "    print(\"=\" * 70)\n",
    "    print()\n",
    "    print(f\"Error: {e}\")\n",
    "    print()\n",
    "    print(\"Troubleshooting:\")\n",
    "    print(\"  - Check that model and data are compatible\")\n",
    "    print(\"  - Verify all previous cells ran successfully\")\n",
    "    print(\"  - Try reducing batch size if out of memory\")\n",
    "    print(\"  - Check logs above for specific error details\")\n",
    "    print()\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fd41698",
   "metadata": {},
   "source": [
    "<a id=\"section-7\"></a>\n",
    "# \ud83d\udcc8 Section 7: Analysis & Visualization\n",
    "\n",
    "Analyze training results with comprehensive dashboards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "632a6e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title \ud83d\udcc8 Training Dashboard (v3.6: With Drift Visualization) { display-mode: \"form\" }\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"TRAINING DASHBOARD GENERATION\")\n",
    "print(\"=\" * 70)\n",
    "print()\n",
    "\n",
    "# Extract metrics from results\n",
    "if 'results' in globals() and 'metrics_summary' in results:\n",
    "    metrics_df = results['metrics_summary']\n",
    "    print(f\"\u2705 Metrics loaded: {len(metrics_df)} epochs\")\n",
    "else:\n",
    "    print(\"\u26a0\ufe0f  No training results found\")\n",
    "    print(\"   Please run Section 6 training first\")\n",
    "    metrics_df = None\n",
    "\n",
    "if metrics_df is not None:\n",
    "    # Create dashboard\n",
    "    print()\n",
    "    print(\"\ud83d\udcca Creating dashboard...\")\n",
    "    \n",
    "    # Determine dashboard type\n",
    "    if drift_data is not None:\n",
    "        print(\"   Type: Enhanced (10-panel with drift visualization)\")\n",
    "        dashboard_size = (20, 14)  # Larger for drift panels\n",
    "    else:\n",
    "        print(\"   Type: Standard (6-panel)\")\n",
    "        dashboard_size = (18, 12)\n",
    "    \n",
    "    dashboard = TrainingDashboard(figsize=dashboard_size)\n",
    "    \n",
    "    try:\n",
    "        if drift_data is not None:\n",
    "            # v3.6: Enhanced dashboard with drift visualization\n",
    "            print(\"   Building 10-panel layout...\")\n",
    "            print(\"     - 6 training metric panels\")\n",
    "            print(\"     - 4 drift detection panels\")\n",
    "            \n",
    "            fig = dashboard.plot_with_drift(\n",
    "                metrics_df=metrics_df,\n",
    "                drift_data=drift_data,\n",
    "                config=training_config,\n",
    "                title=f\"Training Dashboard + Drift Analysis: {training_config.run_name}\"\n",
    "            )\n",
    "            \n",
    "            print(\"   \u2705 Enhanced dashboard created (10 panels)\")\n",
    "            \n",
    "        else:\n",
    "            # Standard 6-panel dashboard\n",
    "            print(\"   Building 6-panel layout...\")\n",
    "            \n",
    "            fig = dashboard.plot(\n",
    "                metrics_df=metrics_df,\n",
    "                config=training_config,\n",
    "                title=f\"Training Dashboard: {training_config.run_name}\"\n",
    "            )\n",
    "            \n",
    "            print(\"   \u2705 Standard dashboard created (6 panels)\")\n",
    "        \n",
    "        # Save to Drive\n",
    "        dashboard_path = f'{workspace_root}/results/{training_config.run_name}_dashboard.png'\n",
    "        dashboard.save(dashboard_path, dpi=150)\n",
    "        \n",
    "        print()\n",
    "        print(f\"\ud83d\udcbe Dashboard saved to: {dashboard_path}\")\n",
    "        \n",
    "        # Display in notebook\n",
    "        import matplotlib.pyplot as plt\n",
    "        plt.show()\n",
    "        \n",
    "        print()\n",
    "        print(\"=\" * 70)\n",
    "        print(\"\u2705 DASHBOARD COMPLETE\")\n",
    "        print(\"=\" * 70)\n",
    "        print()\n",
    "        \n",
    "        if drift_data is not None:\n",
    "            print(\"\ud83d\udcca Drift Analysis Summary:\")\n",
    "            print(f\"   Status: {drift_data['status'].upper()}\")\n",
    "            print(f\"   Metrics tracked: {len(drift_data['drift_scores'])}\")\n",
    "            print()\n",
    "            print(\"   Drift scores:\")\n",
    "            for metric, score in drift_data['drift_scores'].items():\n",
    "                status_emoji = '\u2705' if score < 0.1 else '\u26a0\ufe0f ' if score < 0.2 else '\ud83d\udea8'\n",
    "                print(f\"     {status_emoji} {metric}: {score:.4f}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print()\n",
    "        print(f\"\u274c Dashboard generation failed: {e}\")\n",
    "        print(\"   Check that metrics_df and drift_data are properly formatted\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "else:\n",
    "    print()\n",
    "    print(\"\u26a0\ufe0f  Skipping dashboard generation - no metrics available\")\n",
    "    print(\"   Run training in Section 6 first\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d96e03d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find best epoch based on validation loss\n",
    "best_epoch_idx = metrics_df['val/loss'].idxmin()\n",
    "best_epoch = metrics_df.loc[best_epoch_idx]\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\" \" * 20 + \"BEST EPOCH ANALYSIS\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"{'Best Epoch:':<25} {int(best_epoch['epoch']) + 1}\")\n",
    "print(f\"{'Validation Loss:':<25} {best_epoch['val/loss']:.4f}\")\n",
    "print(f\"{'Validation Perplexity:':<25} {best_epoch['val/perplexity']:.2f}\")\n",
    "print(f\"{'Training Loss:':<25} {best_epoch['train/loss']:.4f}\")\n",
    "print(f\"{'Learning Rate:':<25} {best_epoch['train/learning_rate']:.2e}\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Load best checkpoint\n",
    "best_checkpoint_path = f\"{workspace_root}/checkpoints/{config.run_name}_epoch{int(best_epoch['epoch']) + 1}.pt\"\n",
    "if os.path.exists(best_checkpoint_path):\n",
    "    print(f\"\\n\ud83d\udcbe Best checkpoint: {best_checkpoint_path}\")\n",
    "else:\n",
    "    print(f\"\\n\u26a0\ufe0f Best checkpoint not found (may not have been saved)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0722848b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display metrics table\n",
    "import pandas as pd\n",
    "\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.float_format', lambda x: f'{x:.4f}')\n",
    "\n",
    "display_cols = ['epoch', 'train/loss', 'val/loss', 'val/perplexity', 'train/learning_rate']\n",
    "available_cols = [col for col in display_cols if col in metrics_df.columns]\n",
    "\n",
    "print(\"\\nTraining Metrics Summary:\")\n",
    "print(metrics_df[available_cols].to_string(index=False))\n",
    "\n",
    "# Export to CSV\n",
    "csv_path = f'{workspace_root}/results/{config.run_name}_metrics.csv'\n",
    "metrics_df.to_csv(csv_path, index=False)\n",
    "print(f\"\\n\u2705 Metrics exported to: {csv_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cfe5404",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(\"=\" * 60)\n",
    "    print(\" \" * 20 + \"GPU METRICS\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    gpu_cols = [col for col in metrics_df.columns if col.startswith('gpu/')]\n",
    "    if gpu_cols:\n",
    "        print(metrics_df[['epoch'] + gpu_cols].tail(5).to_string(index=False))\n",
    "\n",
    "        # Plot GPU utilization\n",
    "        import matplotlib.pyplot as plt\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "        if 'gpu/memory_allocated_mb' in metrics_df.columns:\n",
    "            ax1.plot(metrics_df['epoch'], metrics_df['gpu/memory_allocated_mb'])\n",
    "            ax1.set_xlabel('Epoch')\n",
    "            ax1.set_ylabel('GPU Memory (MB)')\n",
    "            ax1.set_title('GPU Memory Usage')\n",
    "            ax1.grid(True)\n",
    "\n",
    "        if 'gpu/utilization_percent' in metrics_df.columns:\n",
    "            ax2.plot(metrics_df['epoch'], metrics_df['gpu/utilization_percent'])\n",
    "            ax2.set_xlabel('Epoch')\n",
    "            ax2.set_ylabel('GPU Utilization (%)')\n",
    "            ax2.set_title('GPU Utilization')\n",
    "            ax2.grid(True)\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'{workspace_root}/results/{config.run_name}_gpu_metrics.png', dpi=100)\n",
    "        plt.show()\n",
    "        print(f\"\\n\u2705 GPU metrics saved\")\n",
    "    else:\n",
    "        print(\"\u26a0\ufe0f No GPU metrics collected during training\")\n",
    "    print(\"=\" * 60)\n",
    "else:\n",
    "    print(\"\u2139\ufe0f Training was performed on CPU (no GPU metrics available)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a6fdf23",
   "metadata": {},
   "source": [
    "<a id=\"section-8\"></a>\n",
    "# \ud83d\udcbe Section 8: Export & Results\n",
    "\n",
    "Download checkpoints, configs, and results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a039396b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from google.colab import files\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\" \" * 20 + \"EXPORT SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\n\ud83d\udcc1 Workspace: {workspace_root}\")\n",
    "print(f\"\\n\ud83d\udcca Results:\")\n",
    "print(f\"   - Dashboard: {config.run_name}_dashboard.png\")\n",
    "print(f\"   - Metrics CSV: {config.run_name}_metrics.csv\")\n",
    "print(f\"   - Config: {os.path.basename(config_path)}\")\n",
    "print(f\"\\n\ud83d\udcbe Checkpoints:\")\n",
    "\n",
    "checkpoint_dir = f\"{workspace_root}/checkpoints\"\n",
    "checkpoints = [f for f in os.listdir(checkpoint_dir) if f.startswith(config.run_name)]\n",
    "for ckpt in sorted(checkpoints):\n",
    "    ckpt_path = os.path.join(checkpoint_dir, ckpt)\n",
    "    size_mb = os.path.getsize(ckpt_path) / (1024 * 1024)\n",
    "    print(f\"   - {ckpt} ({size_mb:.1f} MB)\")\n",
    "\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1656431e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download results to local machine\n",
    "download_results = False  #@param {type:\"boolean\"}\n",
    "\n",
    "if download_results:\n",
    "    print(\"Downloading files...\")\n",
    "\n",
    "    # Download dashboard\n",
    "    dashboard_file = f'{workspace_root}/results/{config.run_name}_dashboard.png'\n",
    "    if os.path.exists(dashboard_file):\n",
    "        files.download(dashboard_file)\n",
    "\n",
    "    # Download metrics CSV\n",
    "    metrics_file = f'{workspace_root}/results/{config.run_name}_metrics.csv'\n",
    "    if os.path.exists(metrics_file):\n",
    "        files.download(metrics_file)\n",
    "\n",
    "    # Download config\n",
    "    if os.path.exists(config_path):\n",
    "        files.download(config_path)\n",
    "\n",
    "    # Download best checkpoint\n",
    "    if os.path.exists(best_checkpoint_path):\n",
    "        files.download(best_checkpoint_path)\n",
    "        print(f\"\u2705 Downloaded {os.path.basename(best_checkpoint_path)}\")\n",
    "\n",
    "    print(\"\u2705 Downloads complete\")\n",
    "else:\n",
    "    print(\"\u2139\ufe0f Downloads skipped. Files are saved in Google Drive.\")\n",
    "    print(f\"   Access them at: {workspace_root}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "l75ch0mse7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title \ud83d\udce6 Production Export Bundle (v3.5) { display-mode: \"form\" }\n",
    "\n",
    "if training_config.export_bundle:\n",
    "    print(\"=\" * 70)\n",
    "    print(\"PRODUCTION EXPORT BUNDLE GENERATION (v3.5)\")\n",
    "    print(\"=\" * 70)\n",
    "    print()\n",
    "    \n",
    "    print(\"\ud83d\udce6 Creating complete deployment bundle...\")\n",
    "    print(f\"   Formats: {', '.join(training_config.export_formats)}\")\n",
    "    print(f\"   Task: {task_spec.name}\")\n",
    "    print(f\"   Modality: {task_spec.modality}\")\n",
    "    print()\n",
    "    \n",
    "    try:\n",
    "        # Get best model from training results\n",
    "        if 'results' in globals() and 'model' in globals():\n",
    "            export_model = model\n",
    "            print(\"\u2705 Using trained model for export\")\n",
    "        else:\n",
    "            print(\"\u26a0\ufe0f  No trained model found, using current model state\")\n",
    "            export_model = model if 'model' in globals() else None\n",
    "        \n",
    "        if export_model is not None:\n",
    "            # Create export bundle\n",
    "            print()\n",
    "            print(\"\ud83d\udd27 Generating export artifacts...\")\n",
    "            print(\"   (This may take 1-2 minutes)\")\n",
    "            print()\n",
    "            \n",
    "            export_dir = create_export_bundle(\n",
    "                model=export_model,\n",
    "                config=config_obj if 'config_obj' in globals() else {},\n",
    "                task_spec=task_spec,\n",
    "                training_config=training_config,\n",
    "                export_base_dir=f'{workspace_root}/exports'\n",
    "            )\n",
    "            \n",
    "            print()\n",
    "            print(\"=\" * 70)\n",
    "            print(\"\u2705 EXPORT BUNDLE CREATED SUCCESSFULLY!\")\n",
    "            print(\"=\" * 70)\n",
    "            print()\n",
    "            print(f\"\ud83d\udcc1 Location: {export_dir}\")\n",
    "            print()\n",
    "            print(\"Bundle Contents:\")\n",
    "            print(\"-\" * 70)\n",
    "            print()\n",
    "            print(\"  \ud83d\udcc1 artifacts/\")\n",
    "            \n",
    "            for fmt in training_config.export_formats:\n",
    "                if fmt == \"onnx\":\n",
    "                    print(\"     \u251c\u2500\u2500 model.onnx (ONNX format)\")\n",
    "                elif fmt == \"torchscript\":\n",
    "                    print(\"     \u251c\u2500\u2500 model.torchscript.pt (TorchScript)\")\n",
    "                elif fmt == \"pytorch\":\n",
    "                    print(\"     \u251c\u2500\u2500 model.pytorch.pt (PyTorch state dict)\")\n",
    "            \n",
    "            print()\n",
    "            print(\"  \ud83d\udcc1 configs/\")\n",
    "            print(\"     \u251c\u2500\u2500 task_spec.json (task configuration)\")\n",
    "            print(\"     \u251c\u2500\u2500 training_config.json (training settings)\")\n",
    "            print(\"     \u2514\u2500\u2500 torchserve_config.json (TorchServe deployment)\")\n",
    "            print()\n",
    "            print(\"  \ud83d\udcc4 inference.py (standalone inference script)\")\n",
    "            print(\"  \ud83d\udcc4 README.md (quickstart guide)\")\n",
    "            print(\"  \ud83d\udc33 Dockerfile (container deployment)\")\n",
    "            print(\"  \ud83d\udccb requirements.txt (runtime dependencies)\")\n",
    "            print()\n",
    "            print(\"-\" * 70)\n",
    "            print()\n",
    "            print(\"QUICK START GUIDE\")\n",
    "            print(\"-\" * 70)\n",
    "            print()\n",
    "            \n",
    "            if task_spec.modality == \"vision\":\n",
    "                print(\"Local Inference:\")\n",
    "                print(f\"  cd {export_dir}\")\n",
    "                print(f\"  python inference.py --input image.jpg --model artifacts/model.onnx\")\n",
    "                print()\n",
    "                print(\"Docker Deployment:\")\n",
    "                print(f\"  cd {export_dir}\")\n",
    "                print(\"  docker build -t model-inference .\")\n",
    "                print(\"  docker run -p 8080:8080 model-inference\")\n",
    "                print()\n",
    "                print(\"Test the API:\")\n",
    "                print(\"  curl -X POST http://localhost:8080/predict \\\\\")\n",
    "                print(\"    -F 'image=@test_image.jpg'\")\n",
    "            else:\n",
    "                print(\"Local Inference:\")\n",
    "                print(f\"  cd {export_dir}\")\n",
    "                print(f\"  python inference.py --input 'Your text here' --model artifacts/model.onnx\")\n",
    "                print()\n",
    "                print(\"Docker Deployment:\")\n",
    "                print(f\"  cd {export_dir}\")\n",
    "                print(\"  docker build -t model-inference .\")\n",
    "                print(\"  docker run -p 8080:8080 model-inference\")\n",
    "                print()\n",
    "                print(\"Test the API:\")\n",
    "                print(\"  curl -X POST http://localhost:8080/predict \\\\\")\n",
    "                print(\"    -d '{\\\"text\\\": \\\"Your input text\\\"}'\")\n",
    "            \n",
    "            print()\n",
    "            print(\"=\" * 70)\n",
    "            print()\n",
    "            print(\"\ud83d\udca1 The export bundle includes everything needed for production:\")\n",
    "            print(\"   \u2705 Optimized model formats (ONNX, TorchScript)\")\n",
    "            print(\"   \u2705 Standalone inference script\")\n",
    "            print(\"   \u2705 Docker container definition\")\n",
    "            print(\"   \u2705 TorchServe deployment config\")\n",
    "            print(\"   \u2705 Complete documentation\")\n",
    "            print()\n",
    "            print(f\"\ud83d\udce6 Export bundle is ready in: {export_dir}\")\n",
    "            print()\n",
    "            \n",
    "        else:\n",
    "            print(\"\u274c No model available for export\")\n",
    "            print(\"   Please run training first (Section 6)\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print()\n",
    "        print(\"\u274c Export bundle generation failed!\")\n",
    "        print()\n",
    "        print(f\"Error: {e}\")\n",
    "        print()\n",
    "        print(\"Troubleshooting:\")\n",
    "        print(\"  - Ensure model is properly trained\")\n",
    "        print(\"  - Check that all required configs are available\")\n",
    "        print(\"  - Verify export formats are supported\")\n",
    "        print()\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "\n",
    "else:\n",
    "    print(\"=\" * 70)\n",
    "    print(\"EXPORT BUNDLE DISABLED\")\n",
    "    print(\"=\" * 70)\n",
    "    print()\n",
    "    print(\"\u2139\ufe0f  Production export bundle generation is disabled\")\n",
    "    print()\n",
    "    print(\"To enable:\")\n",
    "    print(\"  1. Go back to Section 4 (Training Configuration)\")\n",
    "    print(\"  2. Set export_bundle = True\")\n",
    "    print(\"  3. Re-run configuration and training\")\n",
    "    print()\n",
    "    print(\"\ud83d\udca1 Benefits of export bundles:\")\n",
    "    print(\"   - Production-ready deployment artifacts\")\n",
    "    print(\"   - Multiple model formats (ONNX, TorchScript, PyTorch)\")\n",
    "    print(\"   - Docker containerization\")\n",
    "    print(\"   - TorchServe integration\")\n",
    "    print(\"   - Complete documentation\")\n",
    "    print()\n",
    "    print(\"=\" * 70)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f00c7f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare with previous runs\n",
    "all_runs = db.list_runs(limit=10)\n",
    "\n",
    "if len(all_runs) > 1:\n",
    "    print(\"=\" * 60)\n",
    "    print(\" \" * 15 + \"COMPARISON WITH PREVIOUS RUNS\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    comparison_data = []\n",
    "    for run in all_runs:\n",
    "        comparison_data.append({\n",
    "            'run_name': run.get('run_name', 'unknown'),\n",
    "            'final_val_loss': run.get('metrics', {}).get('val/loss', float('nan')),\n",
    "            'final_perplexity': run.get('metrics', {}).get('val/perplexity', float('nan')),\n",
    "            'data_source': run.get('data_source', 'unknown'),\n",
    "            'timestamp': run.get('timestamp', 'unknown')\n",
    "        })\n",
    "\n",
    "    comparison_df = pd.DataFrame(comparison_data)\n",
    "    print(comparison_df.to_string(index=False))\n",
    "    print(\"=\" * 60)\n",
    "else:\n",
    "    print(\"\u2139\ufe0f No previous runs to compare (this is your first run)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61a901c0",
   "metadata": {},
   "source": [
    "<a id=\"section-9\"></a>\n",
    "# \ud83d\udd2c Section 9: Advanced Features\n",
    "\n",
    "Hyperparameter search, multi-run experiments, and optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f3d0b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.tier3_training_utilities import test_hyperparameter_search\n",
    "\n",
    "# Hyperparameter search configuration\n",
    "run_hp_search = False  #@param {type:\"boolean\"}\n",
    "n_trials = 10  #@param {type:\"integer\"}\n",
    "search_timeout = 3600  #@param {type:\"integer\"}\n",
    "\n",
    "if run_hp_search:\n",
    "    print(\"\ud83d\udd0d Starting hyperparameter search...\")\n",
    "    print(f\"   Trials: {n_trials}\")\n",
    "    print(f\"   Timeout: {search_timeout}s ({search_timeout/60:.1f} min)\")\n",
    "    print(\"\\n\u26a0\ufe0f This may take a while. Progress will be shown below.\")\n",
    "\n",
    "    # Define search space\n",
    "    search_space = {\n",
    "        'learning_rate': (1e-5, 1e-3),\n",
    "        'batch_size': [4, 8, 16],\n",
    "        'warmup_ratio': (0.0, 0.2),\n",
    "        'weight_decay': (0.0, 0.1)\n",
    "    }\n",
    "\n",
    "    print(f\"\\nSearch space: {search_space}\")\n",
    "else:\n",
    "    print(\"\u2139\ufe0f Hyperparameter search disabled\")\n",
    "    print(\"   Set 'run_hp_search = True' to enable\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c19ee7e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "if run_hp_search:\n",
    "    # Run search\n",
    "    hp_results = test_hyperparameter_search(\n",
    "        model=model,\n",
    "        config=config,\n",
    "        train_data=train_data,\n",
    "        val_data=val_data,\n",
    "        n_trials=n_trials,\n",
    "        timeout=search_timeout,\n",
    "        use_wandb=use_wandb\n",
    "    )\n",
    "\n",
    "    # Display results\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\" \" * 15 + \"HYPERPARAMETER SEARCH RESULTS\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"\\nBest parameters:\")\n",
    "    for param, value in hp_results['best_params'].items():\n",
    "        print(f\"   {param}: {value}\")\n",
    "\n",
    "    print(f\"\\nBest validation loss: {hp_results['best_value']:.4f}\")\n",
    "    print(f\"\\nAll trials:\")\n",
    "    print(hp_results['trials_df'].to_string(index=False))\n",
    "\n",
    "    # Save results\n",
    "    hp_results['trials_df'].to_csv(\n",
    "        f'{workspace_root}/results/{config.run_name}_hp_search.csv',\n",
    "        index=False\n",
    "    )\n",
    "    print(f\"\\n\u2705 Results saved to: {config.run_name}_hp_search.csv\")\n",
    "    print(\"=\" * 60)\n",
    "else:\n",
    "    print(\"\u23ed\ufe0f Hyperparameter search skipped\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f63affe7",
   "metadata": {},
   "source": [
    "## \ud83c\udf89 Training Complete!\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "1. **Review Results**: Check the dashboard in Section 6\n",
    "2. **Download Files**: Use Section 7 to download checkpoints\n",
    "3. **Compare Runs**: See Section 7 for comparison with previous experiments\n",
    "4. **Optimize**: Try hyperparameter search in Section 8\n",
    "\n",
    "### Workspace Structure\n",
    "\n",
    "All files are saved in Google Drive:\n",
    "```\n",
    "/content/drive/MyDrive/TransformerTraining/\n",
    "\u251c\u2500\u2500 checkpoints/     # Model weights (.pt files)\n",
    "\u251c\u2500\u2500 configs/         # Training configs (.json files)\n",
    "\u251c\u2500\u2500 results/         # Dashboards, metrics, plots\n",
    "\u251c\u2500\u2500 datasets/        # Cached datasets\n",
    "\u2514\u2500\u2500 experiments.db   # SQLite tracking database\n",
    "```\n",
    "\n",
    "### Resources\n",
    "\n",
    "- [Transformer Builder Documentation](https://transformer-builder.com/docs)\n",
    "- [Training Utilities Reference](https://github.com/matt-hans/transformer-builder-colab-templates)\n",
    "- [W&B Dashboard](https://wandb.ai) (if enabled)\n",
    "\n",
    "---\n",
    "\n",
    "**\ud83d\udca1 Tip**: Save this notebook to Google Drive for future use!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.training import TrainingConfig, build_task_spec, build_eval_config, run_training\n",
    "from utils.adapters import DecoderOnlyLMAdapter\n",
    "\n",
    "cfg = TrainingConfig(epochs=1, batch_size=2, vocab_size=101, max_seq_len=16)\n",
    "\n",
    "# Build Task & Eval configs\n",
    "task = build_task_spec(cfg)\n",
    "eval_cfg = build_eval_config(cfg)\n",
    "\n",
    "# Choose adapter for your architecture\n",
    "adapter = DecoderOnlyLMAdapter()\n",
    "\n",
    "# Assumes `model` is already defined above\n",
    "results = run_training(model, adapter, cfg, task, eval_cfg)\n",
    "print(\"Eval summary:\", results.get(\"eval_summary\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mode selection and config preview (v4.0.0)\n",
    "from utils.ui.presets import build_configs_for_mode\n",
    "mode = 'FAST_DEV'  # or 'STANDARD_EXPERIMENT', 'ABLATION_SWEEP'\n",
    "training_cfg, task_spec, eval_cfg = build_configs_for_mode(mode)\n",
    "print('Mode:', mode)\n",
    "print('TrainingConfig epochs/batch_size:', training_cfg.epochs, training_cfg.batch_size)\n",
    "print('Task:', task_spec.name, '| Eval dataset:', eval_cfg.dataset_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple grid sweep (learning_rate x num_layers)\n",
    "from utils.training.sweep_runner import run_grid_sweep\n",
    "from utils.training.experiment_db import ExperimentDB\n",
    "from utils.adapters import DecoderOnlyLMAdapter\n",
    "from utils.training.training_core import run_training\n",
    "from utils.training import build_task_spec, build_eval_config\n",
    "\n",
    "# Base config from mode (or build a fresh one)\n",
    "base = training_cfg\n",
    "sweep_id = 'demo_sweep_lr_depth'\n",
    "param_grid = {\n",
    "    'learning_rate': [5e-5, 1e-4],\n",
    "    'num_layers': [2, 3],\n",
    "}\n",
    "\n",
    "db = ExperimentDB('experiments.db')\n",
    "adapter = DecoderOnlyLMAdapter()\n",
    "\n",
    "def run_fn(cfg):\n",
    "    task = build_task_spec(cfg)\n",
    "    ecfg = build_eval_config(cfg)\n",
    "    # Log run\n",
    "    run_id = db.log_run(\n",
    "        run_name=f\"sweep-{sweep_id}\",\n",
    "        config=cfg.to_dict(),\n",
    "        notes='grid sweep',\n",
    "        sweep_id=sweep_id,\n",
    "        sweep_params={k: getattr(cfg, k) for k in param_grid.keys()},\n",
    "    )\n",
    "    # Execute training + tiny eval\n",
    "    _ = run_training(model, adapter, cfg, task, ecfg)\n",
    "    db.update_run_status(run_id, 'completed')\n",
    "    return str(run_id)\n",
    "\n",
    "run_ids = run_grid_sweep(base, param_grid, run_fn)\n",
    "print('Completed runs:', run_ids)\n",
    "print('Runs for sweep:')\n",
    "print(db.get_runs_for_sweep(sweep_id))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Repro Bundle (zip) for this run\n",
    "from utils.training.export_utilities import create_repro_bundle\n",
    "from utils.training.experiment_db import ExperimentDB\n",
    "try:\n",
    "    from utils.training.environment_snapshot import capture_environment\n",
    "    env_info = capture_environment()\n",
    "except Exception:\n",
    "    env_info = {}\n",
    "\n",
    "run_id = 'local_run'  # replace with actual run id if using ExperimentDB\n",
    "zip_path = create_repro_bundle(\n",
    "    run_id=run_id,\n",
    "    training_config=training_cfg,\n",
    "    task_spec=task_spec,\n",
    "    eval_config=eval_cfg,\n",
    "    environment_snapshot=env_info,\n",
    "    experiment_db=ExperimentDB('experiments.db'),\n",
    "    dashboard_paths=None,\n",
    "    output_path='./repro'\n",
    ")\n",
    "print('Repro bundle created at:', zip_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sweep visualization\n",
    "from utils.training.experiment_db import ExperimentDB\n",
    "sweep_id = 'demo_sweep_lr_depth'\n",
    "db = ExperimentDB('experiments.db')\n",
    "df = db.get_runs_for_sweep(sweep_id)\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model from GitHub Gist and log metadata\n",
    "from utils.adapters.gist_loader import load_gist_model\n",
    "from utils.training.experiment_db import ExperimentDB\n",
    "from pathlib import Path\n",
    "import importlib.util\n",
    "\n",
    "gist_id = 'abcdef1234567890'  # replace\n",
    "revision = None\n",
    "md = load_gist_model(gist_id, revision)\n",
    "print('Gist SHA:', md.sha256)\n",
    "root = Path('./external/gists') / md.gist_id / (md.revision or 'latest')\n",
    "model_path = root / 'model.py'\n",
    "if model_path.exists():\n",
    "    spec = importlib.util.spec_from_file_location('gist_model', str(model_path))\n",
    "    mod = importlib.util.module_from_spec(spec)\n",
    "    spec.loader.exec_module(mod)\n",
    "    if hasattr(mod, 'build_model'):\n",
    "        model = mod.build_model()\n",
    "        print('Loaded model using build_model()')\n",
    "    elif hasattr(mod, 'Model'):\n",
    "        model = mod.Model()\n",
    "        print('Loaded model using Model class')\n",
    "    else:\n",
    "        print('No known model entrypoint; define model manually')\n",
    "\n",
    "# Log to ExperimentDB\n",
    "try:\n",
    "    db = ExperimentDB('experiments.db')\n",
    "    run_id = db.log_run(\n",
    "        run_name='gist-training',\n",
    "        config=training_cfg.to_dict(),\n",
    "        notes='Gist-based run',\n",
    "        gist_id=md.gist_id,\n",
    "        gist_revision=md.revision,\n",
    "        gist_sha256=md.sha256,\n",
    "    )\n",
    "    print('Run logged:', run_id)\n",
    "except Exception as e:\n",
    "    print('DB logging skipped:', e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log run to ExperimentDB and create a repro bundle for this training\n",
    "from utils.training.experiment_db import ExperimentDB\n",
    "from utils.training.export_utilities import create_repro_bundle\n",
    "try:\n",
    "    from utils.training.environment_snapshot import capture_environment\n",
    "    env_info = capture_environment()\n",
    "except Exception:\n",
    "    env_info = {}\n",
    "\n",
    "# Log run\n",
    "db = ExperimentDB('experiments.db')\n",
    "run_id = db.log_run(\n",
    "    run_name='notebook-single-run',\n",
    "    config=training_cfg.to_dict(),\n",
    "    notes='single run from notebook'\n",
    ")\n",
    "\n",
    "# Train + tiny eval\n",
    "nb_results = run_training(model, adapter, training_cfg, task_spec, eval_cfg)\n",
    "\n",
    "# Mark run complete\n",
    "db.update_run_status(run_id, 'completed')\n",
    "\n",
    "# Create repro bundle\n",
    "zip_path = create_repro_bundle(\n",
    "    run_id=str(run_id),\n",
    "    training_config=training_cfg,\n",
    "    task_spec=task_spec,\n",
    "    eval_config=eval_cfg,\n",
    "    environment_snapshot=env_info,\n",
    "    experiment_db=db,\n",
    "    dashboard_paths=None,\n",
    "    output_path='./repro'\n",
    ")\n",
    "print('Repro bundle zip:', zip_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize sweep results (matplotlib)\n",
    "import json\n",
    "from utils.training.experiment_db import ExperimentDB\n",
    "try:\n",
    "    import matplotlib.pyplot as plt\n",
    "except Exception:\n",
    "    plt = None\n",
    "\n",
    "sweep_id = 'demo_sweep_lr_depth'  # must match the sweep cell above\n",
    "\n",
    "db = ExperimentDB('experiments.db')\n",
    "df = db.get_runs_for_sweep(sweep_id)\n",
    "if df.empty:\n",
    "    print('No runs for sweep:', sweep_id)\n",
    "else:\n",
    "    # Parse sweep_params JSON strings\n",
    "    params = df['sweep_params'].apply(lambda s: json.loads(s) if isinstance(s, str) and s else {})\n",
    "    lrs = params.apply(lambda d: d.get('learning_rate', None))\n",
    "    depths = params.apply(lambda d: d.get('num_layers', None))\n",
    "\n",
    "    if plt is None:\n",
    "        print('matplotlib not available; printing table only')\n",
    "        print(df[['run_id', 'run_name', 'sweep_params']])\n",
    "    else:\n",
    "        # Bar plot: runs per learning_rate\n",
    "        by_lr = lrs.value_counts().sort_index()\n",
    "        plt.figure(figsize=(5,3))\n",
    "        by_lr.plot(kind='bar', title='Runs per learning_rate')\n",
    "        plt.ylabel('runs')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "        # Scatter: num_layers by run index\n",
    "        try:\n",
    "            x = list(range(len(df)))\n",
    "            y = depths.astype(float).fillna(0)\n",
    "            plt.figure(figsize=(5,3))\n",
    "            plt.scatter(x, y)\n",
    "            plt.title('num_layers by run index')\n",
    "            plt.xlabel('run index')\n",
    "            plt.ylabel('num_layers')\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "        except Exception as e:\n",
    "            print('Plotting skipped:', e)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}