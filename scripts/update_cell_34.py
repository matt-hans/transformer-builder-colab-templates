#!/usr/bin/env python3
"""Update Cell 34 source with full implementation."""

import json
from pathlib import Path

NOTEBOOK_PATH = Path('training.ipynb')
CELL_INDEX = 34

# Full Cell 34 source code (Tasks 3-7: all sections)
CELL_34_SOURCE = [
    "# @title üîß Optional: Load Model Weights from Checkpoint { display-mode: \"form\" }\n",
    "\n",
    "# =============================================================================\n",
    "# LOAD MODEL WEIGHTS FROM CHECKPOINT\n",
    "# =============================================================================\n",
    "# This cell loads model weights from a checkpoint into an existing model instance.\n",
    "#\n",
    "# Prerequisites:\n",
    "#   1. Run Cell 13 (Initialize Model) first to create 'model' variable\n",
    "#   2. Run Cell 32 (Training) OR Cell 33 (Recovery) to have checkpoints\n",
    "#\n",
    "# Use Cases:\n",
    "#   - Inference on trained model\n",
    "#   - Continue training from checkpoint\n",
    "#   - Evaluate model on test data\n",
    "# =============================================================================\n",
    "\n",
    "from pathlib import Path\n",
    "from utils.training.engine.recovery import list_checkpoints\n",
    "import torch\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"LOAD MODEL WEIGHTS FROM CHECKPOINT\")\n",
    "print(\"=\" * 70)\n",
    "print()\n",
    "\n",
    "# Validate prerequisites\n",
    "if 'model' not in globals():\n",
    "    print(\"‚ùå Model instance not found!\")\n",
    "    print()\n",
    "    print(\"üí° To fix:\")\n",
    "    print(\"   1. Run Cell 13 (Initialize Model) to create 'model' variable\")\n",
    "    print(\"   2. Re-run this cell\")\n",
    "    print()\n",
    "    print(\"=\" * 70)\n",
    "\n",
    "else:\n",
    "    # Scan checkpoint directory\n",
    "    checkpoint_dir = './checkpoints'\n",
    "    checkpoints = list_checkpoints(checkpoint_dir)\n",
    "    \n",
    "    if not checkpoints:\n",
    "        print(\"‚ùå No checkpoints found in ./checkpoints/\")\n",
    "        print()\n",
    "        print(\"üí° To fix:\")\n",
    "        print(\"   1. Run Cell 32 (Run Training) to create checkpoints\")\n",
    "        print(\"   2. Or verify checkpoint directory path\")\n",
    "        print()\n",
    "        print(\"=\" * 70)\n",
    "    \n",
    "    else:\n",
    "        # Determine which checkpoint to load\n",
    "        if 'results' in globals() and 'checkpoint_path' in results:\n",
    "            # Use checkpoint from Cell 33 (Checkpoint Recovery)\n",
    "            checkpoint_path = results['checkpoint_path']\n",
    "            selection_method = \"From Cell 33 (Checkpoint Recovery)\"\n",
    "        else:\n",
    "            # Auto-select best checkpoint (first in list = best val_loss)\n",
    "            checkpoint_path = checkpoints[0]['path']\n",
    "            selection_method = \"Auto-selected (Best val_loss)\"\n",
    "        \n",
    "        print(\"=\" * 70)\n",
    "        print(\"AVAILABLE CHECKPOINTS\")\n",
    "        print(\"=\" * 70)\n",
    "        print()\n",
    "        \n",
    "        # Display checkpoint list\n",
    "        for i, ckpt in enumerate(checkpoints[:10]):  # Show top 10\n",
    "            # Mark selected checkpoint\n",
    "            marker = \"‚Üí\" if ckpt['path'] == checkpoint_path else \" \"\n",
    "            \n",
    "            print(f\"{marker} [{i}] Epoch {ckpt['epoch']:2d} | \"\n",
    "                  f\"Step {ckpt['global_step']:5d} | \"\n",
    "                  f\"train_loss={ckpt['train_loss']:.4f} | \"\n",
    "                  f\"val_loss={ckpt['val_loss']:.4f}\")\n",
    "            print(f\"     {ckpt['filename']}\")\n",
    "            print()\n",
    "        \n",
    "        if len(checkpoints) > 10:\n",
    "            print(f\"... and {len(checkpoints) - 10} more checkpoints\")\n",
    "            print()\n",
    "        \n",
    "        print(f\"üìÇ Selected: {Path(checkpoint_path).name}\")\n",
    "        print(f\"üîç Selection Method: {selection_method}\")\n",
    "        print()\n",
    "        \n",
    "        # Manual override option (commented)\n",
    "        print(\"# Override: Uncomment and modify to load different checkpoint\")\n",
    "        print(\"# checkpoint_path = checkpoints[2]['path']  # Load epoch 7 checkpoint\")\n",
    "        print()\n",
    "        \n",
    "        # Load checkpoint and weights\n",
    "        try:\n",
    "            print(\"=\" * 70)\n",
    "            print(\"LOADING MODEL WEIGHTS\")\n",
    "            print(\"=\" * 70)\n",
    "            print()\n",
    "            \n",
    "            # Load checkpoint\n",
    "            print(f\"üìÇ Loading checkpoint: {Path(checkpoint_path).name}\")\n",
    "            checkpoint = torch.load(checkpoint_path, map_location='cpu', weights_only=False)\n",
    "            \n",
    "            # Extract model weights\n",
    "            model_state_dict = checkpoint['model_state_dict']\n",
    "            \n",
    "            # Load weights into model (strict=True ensures architecture match)\n",
    "            model.load_state_dict(model_state_dict, strict=True)\n",
    "            \n",
    "            print(\"‚úÖ Weights loaded successfully!\")\n",
    "            print()\n",
    "            \n",
    "            # Determine target device\n",
    "            device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "            \n",
    "            # Move model to device\n",
    "            model = model.to(device)\n",
    "            \n",
    "            # Set to evaluation mode (disables dropout, batchnorm updates)\n",
    "            model.eval()\n",
    "            \n",
    "            print(f\"üìç Device: {device}\")\n",
    "            print(f\"üéØ Mode: Evaluation (dropout/batchnorm frozen)\")\n",
    "            print()\n",
    "            \n",
    "            # Display checkpoint info\n",
    "            print(\"=\" * 70)\n",
    "            print(\"CHECKPOINT INFO\")\n",
    "            print(\"=\" * 70)\n",
    "            print()\n",
    "            \n",
    "            epoch = checkpoint.get('epoch', 'Unknown')\n",
    "            global_step = checkpoint.get('global_step', 'Unknown')\n",
    "            metrics = checkpoint.get('metrics', {})\n",
    "            timestamp = checkpoint.get('timestamp', 'Unknown')\n",
    "            \n",
    "            print(f\"üìä Training Progress:\")\n",
    "            print(f\"   Epoch: {epoch}\")\n",
    "            print(f\"   Global Step: {global_step}\")\n",
    "            print(f\"   Timestamp: {timestamp}\")\n",
    "            print()\n",
    "            \n",
    "            print(f\"üìà Metrics:\")\n",
    "            if 'train_loss' in metrics:\n",
    "                print(f\"   Train Loss: {metrics['train_loss']:.4f}\")\n",
    "            if 'val_loss' in metrics:\n",
    "                print(f\"   Val Loss: {metrics['val_loss']:.4f}\")\n",
    "            if 'learning_rate' in metrics:\n",
    "                print(f\"   Learning Rate: {metrics['learning_rate']:.6f}\")\n",
    "            print()\n",
    "            \n",
    "            # Display model info\n",
    "            print(\"=\" * 70)\n",
    "            print(\"MODEL INFO\")\n",
    "            print(\"=\" * 70)\n",
    "            print()\n",
    "            \n",
    "            # Count parameters\n",
    "            total_params = sum(p.numel() for p in model.parameters())\n",
    "            trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "            frozen_params = total_params - trainable_params\n",
    "            \n",
    "            print(f\"üß† Parameters:\")\n",
    "            print(f\"   Total: {total_params:,}\")\n",
    "            print(f\"   Trainable: {trainable_params:,}\")\n",
    "            print(f\"   Frozen: {frozen_params:,}\")\n",
    "            print()\n",
    "            \n",
    "            print(f\"üíæ Memory:\")\n",
    "            print(f\"   Model Size: {total_params * 4 / 1024**2:.2f} MB (FP32)\")\n",
    "            print()\n",
    "            \n",
    "            # Display architecture preview\n",
    "            print(\"=\" * 70)\n",
    "            print(\"ARCHITECTURE PREVIEW\")\n",
    "            print(\"=\" * 70)\n",
    "            print()\n",
    "            \n",
    "            print(\"üìê First 5 layers:\")\n",
    "            for i, (name, param) in enumerate(model.named_parameters()):\n",
    "                if i >= 5:\n",
    "                    break\n",
    "                print(f\"   {i+1}. {name}\")\n",
    "                print(f\"      Shape: {list(param.shape)}\")\n",
    "                print(f\"      Device: {param.device}\")\n",
    "                print()\n",
    "            \n",
    "            total_layers = sum(1 for _ in model.named_parameters())\n",
    "            if total_layers > 5:\n",
    "                print(f\"   ... and {total_layers - 5} more layers\")\n",
    "                print()\n",
    "            \n",
    "            # Next steps guidance\n",
    "            print(\"=\" * 70)\n",
    "            print(\"NEXT STEPS\")\n",
    "            print(\"=\" * 70)\n",
    "            print()\n",
    "            print(\"üí° Model is ready for:\")\n",
    "            print(\"   ‚Üí Inference on test data\")\n",
    "            print(\"   ‚Üí Evaluation/benchmarking\")\n",
    "            print(\"   ‚Üí Feature extraction\")\n",
    "            print()\n",
    "            print(\"üîÑ To resume training:\")\n",
    "            print(\"   model.train()  # Switch to training mode\")\n",
    "            print(\"   # Then run training loop\")\n",
    "            print()\n",
    "            print(\"=\" * 70)\n",
    "            \n",
    "        except RuntimeError as e:\n",
    "            if \"size mismatch\" in str(e) or \"Missing key\" in str(e) or \"Unexpected key\" in str(e):\n",
    "                print(\"‚ùå ERROR: Model architecture mismatch!\")\n",
    "                print()\n",
    "                print(\"üí° Possible causes:\")\n",
    "                print(\"   1. Model config in Cell 13 differs from training config\")\n",
    "                print(\"   2. Checkpoint is from a different model architecture\")\n",
    "                print(\"   3. Model definition was modified after training\")\n",
    "                print()\n",
    "                print(\"üîß To fix:\")\n",
    "                print(\"   1. Verify config in Cell 13 matches training config\")\n",
    "                print(\"   2. Check model definition hasn't changed\")\n",
    "                print(\"   3. Try loading a different checkpoint\")\n",
    "                print()\n",
    "                print(f\"üìã Technical details: {e}\")\n",
    "                print()\n",
    "                print(\"=\" * 70)\n",
    "            else:\n",
    "                # Re-raise unexpected RuntimeError\n",
    "                raise\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå ERROR: Failed to load checkpoint!\")\n",
    "            print()\n",
    "            print(\"üí° Possible causes:\")\n",
    "            print(\"   1. Checkpoint file is corrupted\")\n",
    "            print(\"   2. Incompatible PyTorch versions\")\n",
    "            print(\"   3. Insufficient memory\")\n",
    "            print()\n",
    "            print(\"üîß To fix:\")\n",
    "            print(\"   1. Try loading a different checkpoint\")\n",
    "            print(\"   2. Verify checkpoint file is not corrupted\")\n",
    "            print(\"   3. Restart runtime and try again\")\n",
    "            print()\n",
    "            print(f\"üìã Technical details: {e}\")\n",
    "            print()\n",
    "            print(\"=\" * 70)\n",
    "\n",
]

def update_cell_34_source(source_lines):
    """Update Cell 34 with new source code."""
    with open(NOTEBOOK_PATH, 'r') as f:
        nb = json.load(f)

    # Update Cell 34 source
    nb['cells'][CELL_INDEX]['source'] = source_lines

    # Save notebook
    with open(NOTEBOOK_PATH, 'w') as f:
        json.dump(nb, f, indent=1)

    print(f"‚úÖ Updated Cell {CELL_INDEX}")
    print(f"   Lines of source: {len(source_lines)}")

if __name__ == "__main__":
    update_cell_34_source(CELL_34_SOURCE)
