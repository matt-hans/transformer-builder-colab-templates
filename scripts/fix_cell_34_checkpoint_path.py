#!/usr/bin/env python3
"""Fix Cell 34 to use intelligent checkpoint directory discovery."""

import json
from pathlib import Path

NOTEBOOK_PATH = Path('training.ipynb')
CELL_INDEX = 34

# Updated Cell 34 source with intelligent checkpoint discovery
UPDATED_SOURCE = [
    "# @title üîß Optional: Load Model Weights from Checkpoint { display-mode: \"form\" }\n",
    "\n",
    "# =============================================================================\n",
    "# LOAD MODEL WEIGHTS FROM CHECKPOINT\n",
    "# =============================================================================\n",
    "# This cell loads model weights from a checkpoint into an existing model instance.\n",
    "#\n",
    "# Prerequisites:\n",
    "#   1. Run Cell 13 (Initialize Model) first to create 'model' variable\n",
    "#   2. Run Cell 32 (Training) OR Cell 33 (Recovery) to have checkpoints\n",
    "#\n",
    "# Use Cases:\n",
    "#   - Inference on trained model\n",
    "#   - Continue training from checkpoint\n",
    "#   - Evaluate model on test data\n",
    "# =============================================================================\n",
    "\n",
    "from pathlib import Path\n",
    "from utils.training.engine.recovery import list_checkpoints\n",
    "import torch\n",
    "import os\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"LOAD MODEL WEIGHTS FROM CHECKPOINT\")\n",
    "print(\"=\" * 70)\n",
    "print()\n",
    "\n",
    "# Validate prerequisites\n",
    "if 'model' not in globals():\n",
    "    print(\"‚ùå Model instance not found!\")\n",
    "    print()\n",
    "    print(\"üí° To fix:\")\n",
    "    print(\"   1. Run Cell 13 (Initialize Model) to create 'model' variable\")\n",
    "    print(\"   2. Re-run this cell\")\n",
    "    print()\n",
    "    print(\"=\" * 70)\n",
    "\n",
    "else:\n",
    "    # Intelligent checkpoint directory discovery\n",
    "    # Try to reuse ckpt_dir from Cell 33 (Recovery), otherwise search common locations\n",
    "    if 'ckpt_dir' in globals() and ckpt_dir is not None:\n",
    "        checkpoint_dir = ckpt_dir\n",
    "        print(f\"üìÇ Using checkpoint directory from Cell 33: {checkpoint_dir}\")\n",
    "        print()\n",
    "    else:\n",
    "        # Fallback: search common checkpoint locations\n",
    "        checkpoint_search_paths = [\n",
    "            './checkpoints',\n",
    "            './training_output/checkpoints',\n",
    "            './tmp_training_output/checkpoints',\n",
    "            '/content/workspace/checkpoints'\n",
    "        ]\n",
    "        \n",
    "        checkpoint_dir = None\n",
    "        for path in checkpoint_search_paths:\n",
    "            if os.path.exists(path):\n",
    "                checkpoint_dir = path\n",
    "                print(f\"üìÇ Found checkpoint directory: {checkpoint_dir}\")\n",
    "                print()\n",
    "                break\n",
    "        \n",
    "        if checkpoint_dir is None:\n",
    "            # Final fallback (will show error message below)\n",
    "            checkpoint_dir = './checkpoints'\n",
    "    \n",
    "    checkpoints = list_checkpoints(checkpoint_dir)\n",
    "    \n",
    "    if not checkpoints:\n",
    "        print(f\"‚ùå No checkpoints found in {checkpoint_dir}\")\n",
    "        print()\n",
    "        print(\"üí° To fix:\")\n",
    "        print(\"   1. Run Cell 32 (Run Training) to create checkpoints\")\n",
    "        print(\"   2. Or run Cell 33 (Checkpoint Recovery) to find existing checkpoints\")\n",
    "        print(\"   3. Verify checkpoint directory path\")\n",
    "        print()\n",
    "        print(\"Searched locations:\")\n",
    "        for path in ['./checkpoints', './training_output/checkpoints', './tmp_training_output/checkpoints']:\n",
    "            exists = \"‚úì\" if os.path.exists(path) else \"‚úó\"\n",
    "            print(f\"   {exists} {path}\")\n",
    "        print()\n",
    "        print(\"=\" * 70)\n",
    "    \n",
    "    else:\n",
    "        # Determine which checkpoint to load\n",
    "        if 'results' in globals() and 'checkpoint_path' in results:\n",
    "            # Use checkpoint from Cell 33 (Checkpoint Recovery)\n",
    "            checkpoint_path = results['checkpoint_path']\n",
    "            selection_method = \"From Cell 33 (Checkpoint Recovery)\"\n",
    "        else:\n",
    "            # Auto-select best checkpoint (first in list = best val_loss)\n",
    "            checkpoint_path = checkpoints[0]['path']\n",
    "            selection_method = \"Auto-selected (Best val_loss)\"\n",
    "        \n",
    "        print(\"=\" * 70)\n",
    "        print(\"AVAILABLE CHECKPOINTS\")\n",
    "        print(\"=\" * 70)\n",
    "        print()\n",
    "        \n",
    "        # Display checkpoint list\n",
    "        for i, ckpt in enumerate(checkpoints[:10]):  # Show top 10\n",
    "            # Mark selected checkpoint\n",
    "            marker = \"‚Üí\" if ckpt['path'] == checkpoint_path else \" \"\n",
    "            \n",
    "            print(f\"{marker} [{i}] Epoch {ckpt['epoch']:2d} | \"\n",
    "                  f\"Step {ckpt['global_step']:5d} | \"\n",
    "                  f\"train_loss={ckpt['train_loss']:.4f} | \"\n",
    "                  f\"val_loss={ckpt['val_loss']:.4f}\")\n",
    "            print(f\"     {ckpt['filename']}\")\n",
    "            print()\n",
    "        \n",
    "        if len(checkpoints) > 10:\n",
    "            print(f\"... and {len(checkpoints) - 10} more checkpoints\")\n",
    "            print()\n",
    "        \n",
    "        print(f\"üìÇ Selected: {Path(checkpoint_path).name}\")\n",
    "        print(f\"üîç Selection Method: {selection_method}\")\n",
    "        print()\n",
    "        \n",
    "        # Manual override option (commented)\n",
    "        print(\"# Override: Uncomment and modify to load different checkpoint\")\n",
    "        print(\"# checkpoint_path = checkpoints[2]['path']  # Load epoch 7 checkpoint\")\n",
    "        print()\n",
    "        \n",
    "        # Load checkpoint and weights\n",
    "        try:\n",
    "            print(\"=\" * 70)\n",
    "            print(\"LOADING MODEL WEIGHTS\")\n",
    "            print(\"=\" * 70)\n",
    "            print()\n",
    "            \n",
    "            # Load checkpoint\n",
    "            print(f\"üìÇ Loading checkpoint: {Path(checkpoint_path).name}\")\n",
    "            checkpoint = torch.load(checkpoint_path, map_location='cpu', weights_only=False)\n",
    "            \n",
    "            # Extract model weights\n",
    "            model_state_dict = checkpoint['model_state_dict']\n",
    "            \n",
    "            # Load weights into model (strict=True ensures architecture match)\n",
    "            model.load_state_dict(model_state_dict, strict=True)\n",
    "            \n",
    "            print(\"‚úÖ Weights loaded successfully!\")\n",
    "            print()\n",
    "            \n",
    "            # Determine target device\n",
    "            device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "            \n",
    "            # Move model to device\n",
    "            model = model.to(device)\n",
    "            \n",
    "            # Set to evaluation mode (disables dropout, batchnorm updates)\n",
    "            model.eval()\n",
    "            \n",
    "            print(f\"üìç Device: {device}\")\n",
    "            print(f\"üéØ Mode: Evaluation (dropout/batchnorm frozen)\")\n",
    "            print()\n",
    "            \n",
    "            # Display checkpoint info\n",
    "            print(\"=\" * 70)\n",
    "            print(\"CHECKPOINT INFO\")\n",
    "            print(\"=\" * 70)\n",
    "            print()\n",
    "            \n",
    "            epoch = checkpoint.get('epoch', 'Unknown')\n",
    "            global_step = checkpoint.get('global_step', 'Unknown')\n",
    "            metrics = checkpoint.get('metrics', {})\n",
    "            timestamp = checkpoint.get('timestamp', 'Unknown')\n",
    "            \n",
    "            print(f\"üìä Training Progress:\")\n",
    "            print(f\"   Epoch: {epoch}\")\n",
    "            print(f\"   Global Step: {global_step}\")\n",
    "            print(f\"   Timestamp: {timestamp}\")\n",
    "            print()\n",
    "            \n",
    "            print(f\"üìà Metrics:\")\n",
    "            if 'train_loss' in metrics:\n",
    "                print(f\"   Train Loss: {metrics['train_loss']:.4f}\")\n",
    "            if 'val_loss' in metrics:\n",
    "                print(f\"   Val Loss: {metrics['val_loss']:.4f}\")\n",
    "            if 'learning_rate' in metrics:\n",
    "                print(f\"   Learning Rate: {metrics['learning_rate']:.6f}\")\n",
    "            print()\n",
    "            \n",
    "            # Display model info\n",
    "            print(\"=\" * 70)\n",
    "            print(\"MODEL INFO\")\n",
    "            print(\"=\" * 70)\n",
    "            print()\n",
    "            \n",
    "            # Count parameters\n",
    "            total_params = sum(p.numel() for p in model.parameters())\n",
    "            trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "            frozen_params = total_params - trainable_params\n",
    "            \n",
    "            print(f\"üß† Parameters:\")\n",
    "            print(f\"   Total: {total_params:,}\")\n",
    "            print(f\"   Trainable: {trainable_params:,}\")\n",
    "            print(f\"   Frozen: {frozen_params:,}\")\n",
    "            print()\n",
    "            \n",
    "            print(f\"üíæ Memory:\")\n",
    "            print(f\"   Model Size: {total_params * 4 / 1024**2:.2f} MB (FP32)\")\n",
    "            print()\n",
    "            \n",
    "            # Display architecture preview\n",
    "            print(\"=\" * 70)\n",
    "            print(\"ARCHITECTURE PREVIEW\")\n",
    "            print(\"=\" * 70)\n",
    "            print()\n",
    "            \n",
    "            print(\"üìê First 5 layers:\")\n",
    "            for i, (name, param) in enumerate(model.named_parameters()):\n",
    "                if i >= 5:\n",
    "                    break\n",
    "                print(f\"   {i+1}. {name}\")\n",
    "                print(f\"      Shape: {list(param.shape)}\")\n",
    "                print(f\"      Device: {param.device}\")\n",
    "                print()\n",
    "            \n",
    "            total_layers = sum(1 for _ in model.named_parameters())\n",
    "            if total_layers > 5:\n",
    "                print(f\"   ... and {total_layers - 5} more layers\")\n",
    "                print()\n",
    "            \n",
    "            # Next steps guidance\n",
    "            print(\"=\" * 70)\n",
    "            print(\"NEXT STEPS\")\n",
    "            print(\"=\" * 70)\n",
    "            print()\n",
    "            print(\"üí° Model is ready for:\")\n",
    "            print(\"   ‚Üí Inference on test data\")\n",
    "            print(\"   ‚Üí Evaluation/benchmarking\")\n",
    "            print(\"   ‚Üí Feature extraction\")\n",
    "            print()\n",
    "            print(\"üîÑ To resume training:\")\n",
    "            print(\"   model.train()  # Switch to training mode\")\n",
    "            print(\"   # Then run training loop\")\n",
    "            print()\n",
    "            print(\"=\" * 70)\n",
    "            \n",
    "        except RuntimeError as e:\n",
    "            if \"size mismatch\" in str(e) or \"Missing key\" in str(e) or \"Unexpected key\" in str(e):\n",
    "                print(\"‚ùå ERROR: Model architecture mismatch!\")\n",
    "                print()\n",
    "                print(\"üí° Possible causes:\")\n",
    "                print(\"   1. Model config in Cell 13 differs from training config\")\n",
    "                print(\"   2. Checkpoint is from a different model architecture\")\n",
    "                print(\"   3. Model definition was modified after training\")\n",
    "                print()\n",
    "                print(\"üîß To fix:\")\n",
    "                print(\"   1. Verify config in Cell 13 matches training config\")\n",
    "                print(\"   2. Check model definition hasn't changed\")\n",
    "                print(\"   3. Try loading a different checkpoint\")\n",
    "                print()\n",
    "                print(f\"üìã Technical details: {e}\")\n",
    "                print()\n",
    "                print(\"=\" * 70)\n",
    "            else:\n",
    "                # Re-raise unexpected RuntimeError\n",
    "                raise\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå ERROR: Failed to load checkpoint!\")\n",
    "            print()\n",
    "            print(\"üí° Possible causes:\")\n",
    "            print(\"   1. Checkpoint file is corrupted\")\n",
    "            print(\"   2. Incompatible PyTorch versions\")\n",
    "            print(\"   3. Insufficient memory\")\n",
    "            print()\n",
    "            print(\"üîß To fix:\")\n",
    "            print(\"   1. Try loading a different checkpoint\")\n",
    "            print(\"   2. Verify checkpoint file is not corrupted\")\n",
    "            print(\"   3. Restart runtime and try again\")\n",
    "            print()\n",
    "            print(f\"üìã Technical details: {e}\")\n",
    "            print()\n",
    "            print(\"=\" * 70)\n",
]

# Read notebook
with open(NOTEBOOK_PATH, 'r') as f:
    nb = json.load(f)

# Update Cell 34 source
nb['cells'][CELL_INDEX]['source'] = UPDATED_SOURCE

# Save notebook
with open(NOTEBOOK_PATH, 'w') as f:
    json.dump(nb, f, indent=1)

print(f"‚úÖ Updated Cell {CELL_INDEX} with intelligent checkpoint discovery")
print(f"   New source lines: {len(UPDATED_SOURCE)}")
print(f"   Key improvements:")
print(f"   - Reuses ckpt_dir from Cell 33 if available")
print(f"   - Falls back to multi-location search")
print(f"   - Shows which directory was found")
print(f"   - Lists searched locations in error message")
